\input{preamble}

% OK, start here.
%
\begin{document}

\title{Structure of finite-dimensional Lie algebras}


\maketitle

\phantomsection
\label{section-phantom}

\tableofcontents

Good references for the structure of Lie algebras include Humphreys' book \cite{Humphreys-Lie}, Kirillov's book \cite{Kirillov-Lie}, and Sternberg's notes \cite{Sternberg}.

\section{Nilpotency, solvability, semisimplicity}
\label{section-nilpotent-solvable}


In this chapter, all Lie algebras are taken to be \emph{finite-dimensional} over a field $k$.

\subsection{Definitions}
\label{subsection-definitions-nilpotent-solvable}

\begin{definition}
 \label{definition-ideal}
An {\it ideal} of a Lie algebra $\mathfrak g$ is an $\text{ad}(\mathfrak g)$-stable subspace (automatically a Lie subalgebra) of $\mathfrak g$.

The {\it quotient} of a Lie algebra $\mathfrak g$ by an ideal $\mathfrak h$ is the vector space $\mathfrak g/\mathfrak h$, equipped with the Lie algebra structure descending from $\mathfrak g$.
\end{definition}



\begin{definition}
 \label{definition-nilpotent-solvable-semisimple}
The {\it lower central series} of a Lie algebra $\mathfrak g$ is the descending sequence of ideals defined by
$$ C^0\mathfrak g = \mathfrak g,$$
$$ C^{i+1}\mathfrak g = [\mathfrak g, C^i\mathfrak g].$$
 
 
A Lie algebra is called {\it nilpotent} if its lower central series terminates, i.e., if $C^n\mathfrak g=0$ for some $n$.


The {\it derived series} of a Lie algebra $\mathfrak g$ is the descending sequence of ideals
$$ D^0\mathfrak g = \mathfrak g,$$
$$ D^{i+1}\mathfrak g = [D^i\mathfrak g, D^i\mathfrak g].$$

A Lie algebra is called {\it solvable} if its derived series terminates, i.e., if $D^n\mathfrak g=0$ for some $n$.

A Lie algebra is {\it semisimple} if it does not have any nonzero solvable ideals, and {\it simple} if it is non-abelian, and has no nonzero proper ideals.
\end{definition}

\begin{example}
 \label{example-nilpotent-solvable}
The Lie algebra of strictly upper triangular $n\times n$ matrices (i.e., with zeroes on the diagonal) is nilpotent. The Lie algebra of upper triangular $n\times n$ matrices is solvable.
\end{example}

\begin{lemma}
 \label{lemma-nilpotent-center}
 The center of a (nontrivial) nilpotent Lie algebra is always nontrivial.
\end{lemma}
\begin{proof}
 The last nontrivial element of its lower central series belongs to the center.
\end{proof}




\begin{lemma}
 \label{lemma-solvable-operations}
A Lie algebra $\mathfrak g$ is nilpotent if and only if there exists a finite decreasing filtration by ideals 
$$ \mathfrak g = \mathfrak g^0 \supset \mathfrak g^1 \dots \supset \mathfrak g^n=0$$
such that $[\mathfrak g, \mathfrak g^i]\subset [\mathfrak g^{i+1}]$.

The sum of two nilpotent ideals in a Lie algebra $\mathfrak g$ is also a nilpotent ideal.
 
Subalgebras, quotient algebras, and extensions of solvable Lie algebras by solvable Lie algebras are solvable.
  
A Lie algebra $\mathfrak g$ is solvable if and only if there exists a finite decreasing filtration by subalgebras
$$ \mathfrak g = \mathfrak g^0 \supset \mathfrak g^1 \supset \dots \supset \mathfrak g^n =0$$
such that $\mathfrak g^{i+1}$ is an ideal in $\mathfrak g^i$, and the quotient algebra $\mathfrak g^i/\mathfrak g^{i+1}$ is abelian.
\end{lemma}

\begin{proof}
 Left to the reader.
\end{proof}



\begin{definition}
 \label{definition-radical}
The {\it radical} of a Lie algebra is its largest solvable ideal.

The {\it nilradical}, or {\it nilpotent radical}, of a Lie algebra is its largest nilpotent ideal.
\end{definition}

The definition of the nilradical and radical makes sense in view of Lemma \ref{lemma-solvable-operations}: For the nilradical, the lemma ensures that the sum of all nilpotent ideals is a nilpotent ideal. For the radical, if $\mathfrak a, \mathfrak b$ are solvable ideals, then $\mathfrak a + \mathfrak b$ is an ideal, and it is isomorphic as a Lie algebra to $(\mathfrak a \oplus \mathfrak b)/(\mathfrak a\cap \mathfrak b)$, which is solvable by Lemma \ref{lemma-solvable-operations}.

Thus, any Lie algebra $\mathfrak g$ admits a canonical filtration
\begin{equation}
 \label{equation-filtration-solvable-semisimple}
0 \to R(\mathfrak g) \to \mathfrak g \to \mathfrak g_{ss} \to 0,
\end{equation}
where $R(\mathfrak g)$ is the radical of $\mathfrak g$, and $\mathfrak g_{ss}$ is semisimple. Indeed, the preimage of any solvable ideal in $\mathfrak g_{ss}$ is a solvable ideal in $\mathfrak g$, and therefore has to equal $R(\mathfrak g)$.


Note that the definition of nilradical given here does not coincide with Bourbaki's, who wants to avoid calling an abelian Lie algebra its own nilradical, but is quite standard in other references.

\begin{example}
 \label{example-radical}
 In $\mathfrak{gl}_{2n}$, let $\mathfrak g$ be the subalgebra of matrices whose lower left $n\times n$-block is zero. The radical of $\mathfrak g$ consists of matrices of the form
 $$ \begin{pmatrix}
     aI & * \\ 0 & bI
    \end{pmatrix}$$
 while its nilpotent radical consists of matrices of the form 
 $$ \begin{pmatrix}
     0 & * \\ 0 & 0
    \end{pmatrix}$$
 (all blocks $n\times n$).  

\end{example}

\subsection{Engel's theorem}
\label{subsection-Engel-theorem}

\begin{theorem}[Engel's theorem]
 \label{theorem-Engel}
If $V$ is a nonzero finite-dimensional vector space, and $\mathfrak g\subset \mathfrak{gl}(V)$ is a Lie subalgebra consisting of nilpotent operators, then there is a nonzero $v\in V$ with $Xv = 0$ for all $X\in \mathfrak g$.
 
A finite-dimensional Lie algebra $\mathfrak g$ is nilpotent if and only if $\text{ad}(X)$ is a nilpotent operator, for every $X\in \mathfrak g$. 
\end{theorem}

\begin{proof}
 
We proceed by induction on the dimension of $\mathfrak g$, the case of dimension $1$ being trivial.
 
In higher dimension, let us consider, besides the given representation $V$, the adjoint representation of $\mathfrak g$ on itself, as well. We claim that $\text{ad}(X) \in \text{End}(\mathfrak g)$ is a nilpotent operator, for every $X$. Indeed, $\text{ad}(X)$ is the restriction to $\mathfrak g$ of the operator on $\text{End}(V)$: 
$$ \text{ad}(X) = L_X - R_X,$$
where $L_X(Y) = XY$ and $R_X(Y) = YX \in \text{End}(V)$. Left and right multiplication commute, and there is, by assumption, an $n$ such that $X^n=0$, so by the binomial formula:
$$\text{ad}(X)^{2n} = (L_X - R_X)^{2n} = \sum_{k=0}^{2n} \binom{2n}{k} L_X^k R_X^{2n-k} = 0.$$

Now, take any nontrivial proper subalgebra $\mathfrak h \subset \mathfrak g$. Since $\mathfrak h$ is $\text{ad}(\mathfrak h)$-stable, we get an action of $\mathfrak h$ on the vector space $\mathfrak g/\mathfrak h$, i.e., a morphism of Lie algebras
 $$ \mathfrak h \to \mathfrak{gl}(\mathfrak g/\mathfrak h).$$
 
Let $\bar{\mathfrak h}$ denote its image. Since $\text{ad}(X)$ is nilpotent for every $X\in \mathfrak h$, the same will hold for $\bar{\mathfrak h}$. By the induction hypothesis, there is a nontrivial subspace of $\mathfrak g/\mathfrak h$ which is killed by $\text{ad}(h)$ or, equivalently, \emph{the normalizer of $\mathfrak h$ in $\mathfrak g$ is strictly larger than $\mathfrak h$}. By successively replacing $\mathfrak h$ by its normalizer, we arrive at a proper Lie subalgebra $\mathfrak h$ whose normalizer is $\mathfrak g$, i.e., $\mathfrak h$ is an ideal in $\mathfrak g$.

By the induction hypothesis, the kernel $V_0$ of $\mathfrak h$ acting on $V$ is nontrivial. But this kernel is acted by the quotient Lie algebra $\mathfrak g/\mathfrak h$, and by the induction hypothesis again, it contains a nonzero vector killed by $\mathfrak g$. 

 


For the second statement, take $V=\mathfrak g$. If $\text{ad}(X)$ is nilpotent for every $X \in \mathfrak g$, the first statement implies that the center $Z(\mathfrak g)$ is nontrivial. Replacing $\mathfrak g$ by $\mathfrak g/Z(\mathfrak g)$, we get a sequence of ideals 
$$ \mathfrak g = \mathfrak g^0 \supset \mathfrak g^1 \dots \supset \mathfrak g^n=0$$
such that $[\mathfrak g, \mathfrak g^i]\subset [\mathfrak g^{i+1}]$. By Lemma \ref{lemma-solvable-operations}, $\mathfrak g$ is nilpotent. The other direction is immediate from the definitions: If $\mathfrak g$ is nilpotent, then there is an $n$ such that $\text{ad}(X)^n = 0$ for every $X\in \mathfrak g$.
 
\end{proof}




\subsection{Lie's theorem}
\label{subsection-Lie-theorem}

\begin{theorem}
\label{theorem-Lie}
 If $V$ is a finite-dimensional vector space over an algebraically closed field $k$ in characteristic zero, any solvable Lie subalgebra $\mathfrak g$ of $\mathfrak{gl}(V)$ has a nonzero eigenvector, and hence a full flag
 $$ 0=V_0 \subset V_1 \subset \dots \subset V_n=V,$$
 where $V_i$ has dimension $i$ and is stable under $\mathfrak g$.
\end{theorem}

\begin{proof}
 As in the proof of Engel's theorem \ref{theorem-Engel}, we argue by induction on the dimension of $\mathfrak g$, with the case $\dim \mathfrak g=0$ being trivial. Let, now, $\mathfrak h\subset \mathfrak g$ be an ideal of codimension one (which exists because $\mathfrak g$ is solvable); by induction, $\mathfrak h$ has a non-trivial eigenspace $V_\lambda$ for some linear functional $\lambda: \mathfrak h \to k$. Clearly, $\lambda$ factors through the abelianization 
 $ \mathfrak h^{\text{ab}} = \mathfrak h/[\mathfrak h,\mathfrak h]$.
 
 Now, we claim that $V_\lambda$ is $\mathfrak g$-stable, i.e., if $x\in \mathfrak g$ and $y\in \mathfrak h$ then $yx v = \lambda(y) xv$ for all $v\in V_\lambda$. We have $yx v = xy v -[x,y]v = \lambda(y) xv - [x,y]v$, so we need to prove that $[x,y]v=0$. Consider the flag $0=W_0\subset W_1\subset \dots$ where $W_i$ is spanned by $v, xv, \dots, x^i v$. It is easy to see that $y$ stabilizes this flag, and acts on $W_i/W_{i-1}$ by $\lambda(y)$. Therefore, if $W\subset V$ denotes the maximal subspace of this flag, and $\dim W=n$, the trace of $y$ acting on $W$ is $n\lambda(y)$. This holds for every element of $\mathfrak h$, hence also for the element $[x,y]$. Since this is a commutator of two operators, we get
 $$ 0 = \text{tr}([x,y]) = n \lambda([x,y]),$$
 and since we are in characteristic zero, $\lambda([x,y]) = 0$. 
 
 Thus, $V_\lambda$ is $\mathfrak g$-stable, and because the field is algebraically closed, we can find an eigenvector of $x \in \mathfrak g - \mathfrak h$ on $V_\lambda$, proving the existence of an eigenvector.
 
 The existence of the flag now follows by induction, starting with $V_0=0$ and considering the representation of $\mathfrak g$ on the quotient spaces $V/V_i$.
\end{proof}


\begin{remark}
 \label{remark-Lie-positive-characteristic}
The assumption on the characteristic is really necessary; for example, the Lie algebra $\mathfrak{sl}_2$ is solvable in characteristic $2$, but its standard representation does not have an eigenspace.
\end{remark}

\subsection{Cartan subalgebras}
\label{subsection-CSA}

\begin{definition}
 \label{definition-CSA}
A {\it Cartan subalgebra} of a Lie algebra is a nilpotent, self-normalizing subalgebra. The {\it rank} of a Lie algebra is the dimension of a Cartan subalgebra.
\end{definition}

We will construct Cartan subalgebras as nilspaces (generalized eigenspaces of zero under the adjoint representation) of \emph{s-regular} elements. Then we will show that they are all conjugate to each other; in particular, the rank is uniquely defined.

\begin{definition}
\label{definition-regular}
 A {\it regular element}  of a Lie algebra $\mathfrak g$ is an element whose centralizer is of minimal dimension. 
 An {\it s-regular element} $X\in\mathfrak g$ is an element whose generalized centralizer (i.e., $0$-generalized eigenspace under $\text{ad}$) is of minimal dimension. A {\it regular semisimple} element is a regular element which is also semisimple; equivalently, an $s$-regular element which is also semisimple.
\end{definition}

This terminology ``$s$-regular'' is not standard: in many books on Lie algebras, the word ``regular'' is used for ``s-regular''. However, the standard use of ``regular'' nowadays, at least in the case of semisimple Lie algebras, is to refer to elements with minimal \emph{zero eigenspace} (i.e., centralizer), instead of generalized eigenspace. This includes non-semisimple elements, while s-regular, in the case of semisimple Lie algebras in characteristic zero, is equivalent to \emph{regular semisimple}, see Proposition \ref{proposition-CSA-semisimple}.



\begin{lemma}
\label{lemma-sregular-exist}
$s$-regular elements form a nonempty Zariski open subset of $\mathfrak g$. 
\end{lemma}

\begin{proof}
The dimension of the zero generalized eigenspace is the highest power of $t$ which divides the characteristic polynomial of $\text{ad}(X)$, and therefore having a minimal such dimension is a Zariski open condition.
\end{proof}


\begin{proposition}
\label{proposition-CSA-centralizer}
 The generalized nilspace (under the adjoint representation) of an s-regular element is a Cartan subalgebra.
\end{proposition}

\begin{proof}
 Let $X$ be the s-regular element and $\mathfrak h$ its generalized nilspace. We will prove that $\mathfrak h$ is nilpotent; equivalently, by Engel's theorem, that the restriction of $\text{ad}(Y)$ to $\mathfrak h$, for any $Y\in\mathfrak h$, is nilpotent. Let $U\subset\mathfrak h$ be the subset of elements which fail to satisfy this; it is a Zariski open subset (again by considerations of the characteristic polynomial). Let $V\subset\mathfrak h$ be the subset of elements which act invertibly on $\mathfrak g/\mathfrak h$. It is again a Zariski open subset, and non-empty since $X\in V$. If $U\ne\emptyset$ then $U\cap V\ne\emptyset$, i.e.\ there exists an element $Y\in\mathfrak h$ such that the dimension of the zero generalized eigenspace for $Y$ is less than the dimension of $\mathfrak h$, a contradiction by the s-regularity of $X$. Thus, $\mathfrak h$ is nilpotent.

 If $Z$ normalizes $\mathfrak h$ then $[Z,X]\in\mathfrak h$ which implies that $Z$ is in the generalized nilspace of $X$, i.e.\ in $\mathfrak h$.
\end{proof}

Hence, every Lie algebra has Cartan subalgebras. We will eventually prove that any two Cartan subalgebras are conjugate (over the algebraic closure) by the group of inner automorphisms of $\mathfrak g$ and, in particular, equal to nilspaces of s-regular elements.




\subsection{Derivations and semidirect products}
\label{subsection-derivations-semidirect}

\begin{definition}
\label{definition-derivation-Liealgebra}
 A \emph{derivation} of a Lie algebra $\mathfrak g$ is a linear map $D:\mathfrak g\to\mathfrak g$ satisfying $D([X,Y])=[X,D(Y)]+[D(X),Y]$.
\end{definition}

Let 
$$0 \to  \mathfrak a \to \mathfrak g \to \mathfrak h \to 0$$ be a split short exact sequence of Lie algebras, i.e., $\mathfrak h$ embeds in $\mathfrak g$ as a Lie subalgebra. Then, $\mathfrak h$ acts on $\mathfrak a$ by derivations, i.e., through a morphism $\mathfrak h\to \text{Der}(\mathfrak a)$. Vice versa, given such a morphism, it defines a split extension of $\mathfrak h$ by $\mathfrak a$ in Lie algebras. This is the {\it semidirect product} of $\mathfrak a$ and $\mathfrak h$.



\begin{remarks}
\label{remarks-derivations}
 \begin{enumerate}
  \item This is a very natural extension of the definition of derivation for an associative algebra, since such a derivation induces a derivation as above on the associated Lie algebra. Vice versa, a derivation of a Lie algebra induces a derivation of its universal enveloping algebra.
  \item Derivations form a Lie subalgebra of $\text{End}(\mathfrak g)$.
  \item The adjoint representation $\text{ad}:\mathfrak g\to \text{End}(\mathfrak g)$ has image in $\text{Der}(\mathfrak g)$. 
 \end{enumerate}
\end{remarks}

\begin{definition}
 \label{definition-inner-derivation}
 The derivations in the image of the adjoint map $\text{ad}: \mathfrak g\to \text{Der}(\mathfrak g)$ are called {\it inner derivations}.
\end{definition}



\subsection{Jordan decomposition of endomorphisms}
\label{subsection-Jordan-endomorphisms}

In this subsection, we prove that every endomorphism $x$ of a finite-dimensional vector space $V$ has a unique decomposition $x=x_s+x_n$, where $x_s$ is semisimple, $x_n$ is nilpotent, and $x_s, x_n$ commute. We will see later (\ref{subsection-derivations-Jordan}) that such a decomposition also exists, and is unique, for \emph{semisimple} Lie algebras, at least in characteristic zero, when the ``semisimple'' and ``nilpotent'' parts of an element are defined in terms of the adjoint representation.

\begin{proposition}
\label{proposition-Jordan-endomorphisms}
 Let $V$ be a finite-dimensional vector space over $k$, and $x\in \text{End}(V)$. If $k$ is algebraically closed, there is a unique pair of commuting elements $(x_s, x_n)$ with $x_s$ semisimple, $x_n$ nilpotent, and $x=x_s+x_n$. Moreover, $x_s$ and $x_n$ belong to the subalgebra of operators generated by $x$.
 
 For general $k$, the elements $x_s$ and $x_n$ are defined over a purely inseparable algebraic extension of $k$. 
\end{proposition}

\begin{proof}
 First of all, the statement over an algebraically closed field implies the general statement: The uniqueness of $x_s, x_n$ implies that they are fixed under the Galois group of an algebraic closure of $k$, hence defined over a purely inseparable subextension.
 
 Hence, we may assume that $k$ is algebraically closed, so $V$ decomposes as a direct sum of generalized eigenspaces $V_{\lambda_i}$ for $x$. If such a decomposition exists, since the elements $x_s, x_n$ commute with each other, hence with $x$, they must preserve the generalized eigenspaces $V_{\lambda_i}$. Thus, it is enough to prove existence and uniqueness when $V$ itself is a generalized eigenspace, with eigenvalue $\lambda$. But then, we can take $x_s=\lambda I$, and $x_n = x - \lambda_I$. For any other choice $x=x_s'+x_n'$, the nilpotent element $x_n=x-\lambda I$ would have a Jordan decomposition $(x_s'-\lambda_I) + x_n'$, and since commuting nilpotent or semisimple elements have nilpotent, resp.\ semisimple sum, we would get an equality between the semisimple element $x_s'-\lambda I$ and the nilpotent element $x_n-x_n'$, which means that both are zero.
 
 The element $\lambda I$ is (trivially) in the subalgebra generated by any operator, hence both $x_s, x_n$ are in the subalgebra generated by $x$, when $V$ is a generalized eigenspace. In the general case, if the characteristic polynomial of $x$ is $\prod_i (T-\lambda_i)^{m_i}$, by the Chinese remainder theorem there are is a polynomial $p\in k[T]$ with $p\equiv \lambda_i \mod (T-\lambda_i)^{m_i}$, and then $p(x)=x_s$. 
\end{proof}

The following tiny improvement of the proposition above will be useful in what follows:

\begin{lemma}
\label{lemma-Jordan-extension}
In the setting of \ref{proposition-Jordan-endomorphisms}, $x_s$ can be written as a polynomial of $x$ with zero constant coefficient. For any field automorphism $\phi$ of $k$, if $\phi(x_s)$ denotes the semisimple element which acts on the $\lambda$-eigenspace of $x_s$ by $\phi(\lambda)$, then $\phi(x_s)$ can also be written as such a polynomial of $x$. Finally, for any pair of subspaces $W_1\subset W_2\subset V$ with $xW_2\subset W_1$, we also have $yW_2\subset W_1$, where $y$ is any of $x_s, x_n, \phi(x_s)$.
\end{lemma}

\begin{proof}
 In the proof of Proposition \ref{proposition-Jordan-endomorphisms}, we could have taken the polynomial $p$ to satisfy the additional congruence $p = 0 \mod T$, if $0$ is not among the eigenvalues. (If it is, this condition is among the ones imposed.) This proves the first claim.
 
 For the second, we can similarly find a polynomial $q$ with $q\equiv \phi(\lambda_i) \mod (T-\lambda_i)^{m_i}$ and zero constant coefficient. 
 
 For the last claim, if $xW_2\subset W_1$ then the same is true when $x$ is replaced by $p(x)$, for every polynomial with zero constant coefficient.
\end{proof}


The Jordan decomposition is preserved under tensor operations on the category of representations. (This will be generalized later, Theorem \ref{theorem-Jordan-Chevalley}, for arbitrary morphisms of semisimple Lie algebras.)

Notice that for two representations $V, W$ of a Lie algebra $\mathfrak g$, the tensor product $V\otimes W$ is a representation under 
$$ x \cdot (v\otimes w) = (xv)\otimes w + v\otimes (xw).$$
The dual representation on $V^*$ is defined so that the defining pairing
$$ V\otimes V^*\to k$$ 
is invariant, i.e., 
\begin{equation}
 \label{equation-dual-representation-Liealgebra}
\left< xv, v^*\right> + \left < v, xv^*\right> =0.
\end{equation}

\begin{lemma}
\label{lemma-Jordan-tensors}
Let $V$ be a finite-dimensional vector space, and $W = V^{\otimes^a}\otimes (V^*)^{\otimes^b}$, for some $a, b$. For $x\in \text{End}(V)$, denote by $x'$ the corresponding endomorphism of $W$.

If $x=x_s + x_n$ is the Jordan decomposition of $x$, then $(x_s)'+(x_n)'$ is the Jordan decomposition of $x'$. 
\end{lemma}


\begin{proof}
 It is clear that $x'=(x_s)'+(x_n)'$, with $(x_s)'$ and $(x_n)'$ commuting. It is also clear that $(x_s)'$ is semisimple. To see that $(x_n)'$ is nilpotent, it is enough to show that, if $y\in \text{End}(V_1)$, $z\in \text{End}(V_2)$ are nilpotent endomorphisms of two vector spaces, then the endomorphm $v_1\otimes v_2\mapsto (yv_1) \otimes v_2 + v_1 \otimes (zv_2)$ of $V_1\otimes V_2$ is nilpotent, which is clear by raising it to a sufficiently high power.
\end{proof}





\subsection{Cartan's criterion for solvability}
\label{subsection-Cartan-criterion}

\begin{theorem}[Cartan's criterion]
\label{theorem-Cartans-criterion}
 Let $\mathfrak g\subset \text{End}(V)$ be a Lie subalgebra, where $V$ is a finite-dimensional vector space over a field $k$ in characteristic zero. The Lie algebra $\mathfrak g$ is solvable if and only if $\text{tr}(xy)=0$ for all $x\in \mathfrak g$, $y\in [\mathfrak g, \mathfrak g]$.
 \end{theorem}

\begin{proof}
We may assume that the field is algebraically closed, and then by Lie's theorem \ref{theorem-Lie}, if $\mathfrak g$ is solvable stabilizes a flag $V_0\subset V_1\subset \dots \subset V_n=V$ with $\dim V_i=i$. Then, every $y\in [\mathfrak g,\mathfrak g]$ maps $V_i \to V_{i-1}$, hence so does any product $xy$ with $x\in \mathfrak g$, so $\text{tr}(xy)=0$.

Vice versa, assume that $\text{tr}(xy)=0$ for all $x\in \mathfrak g$, $y\in [\mathfrak g, \mathfrak g]$. To prove that $\mathfrak g$ is solvable, it is enough to prove that $[\mathfrak g,\mathfrak g]$ is nilpotent. By Engel's theorem \ref{theorem-Engel}, this is equivalent to showing that any $y\in [\mathfrak g,\mathfrak g]$ is nilpotent. 

The rest of the proof is written under the assumption that $k=\mathbb C$, so that complex conjugate of a semisimple endomorphism makes sense, as in Lemma \ref{lemma-Jordan-extension}. For a general field in characteristic zero, complex conjugation should be replaced by other field automorphisms. 

Use the Jordan decomposition $y=y_s + y_n$, and observe that $y_s=0$ iff $\text{tr}(y\cdot \overline{y_s})=0$, since the generalized eigenvalues of $y \cdot \overline{y_s}$ are the absolute values of the squares of those of $y_s$. Now, the element $\overline{y_s}$ does not necessarily belong to $\mathfrak g$, so we argue as follows: writing $y$ as a linear combination of commutators in $\mathfrak g$:
$$ y = \sum_i [x_i, z_i],$$
we easily see that 
$$ \text{tr} (y \cdot \overline{y_s}) = \sum_i \text{tr} z_i [\overline{y_s}, x_i],$$
and it is enough to show that, even though $\overline{y_s}$ may not be in $\mathfrak g$, the operator $\text{ad}(\overline{y_s})$ maps $\mathfrak g\to [\mathfrak g,\mathfrak g]$. By Lemma \ref{lemma-Jordan-tensors}, and using the fact that for the Lie algebra $\mathfrak{gl}(V)$, the adjoint representation coincides with $V\otimes V^*$, we have $\text{ad}(\overline{y_s}) = \overline{(\text{ad}(y))_s}$. Since $\text{ad}(y)$ maps $\mathfrak g$ into $[\mathfrak g,\mathfrak g]$, by Lemma \ref{lemma-Jordan-extension} the same is true for $\overline{(\text{ad}(y))_s}$.




\end{proof}

\begin{definition}
\label{definition-Killing-form}
The {\it Killing form} on a Lie algebra $\mathfrak g$ is the symmetric bilinear form 
$$B:S^2 \mathfrak g\to k$$
given by 
$$ B(x,y) = \text{tr}(\text{ad}(x)\text{ad}(y)).$$
\end{definition}

\begin{lemma}
\label{lemma-Killing-invariant}
The Killing form is invariant under the adjoint representation, i.e., for all $x, y, z\in \mathfrak g$,
$$ B(\text{ad}(x)(y), z) + B(y, \text{ad}(x)(z)) = 0.$$
\end{lemma}

\begin{proof}
 Easy consequence of the Jacobi identity.
\end{proof}


\begin{theorem}
 \label{theorem-Killing-semisimplicity}
If the Killing form of a Lie algebra is nondegenerate, the Lie algebra is semisimple. The converse holds in characteristic zero.
\end{theorem}

\begin{proof}
 If $\mathfrak g$ has a non-trivial solvable ideal, then it has a non-trivial abelian ideal $\mathfrak a$, and then the adjoint action of any $x\in \mathfrak a$ maps $\mathfrak g\to\mathfrak a$ and $\mathfrak a\to 0$. Moreover, any $y\in \mathfrak g$ preserves $a$, so 
 $\text{tr}(x) \text{tr}(y)$ maps $\mathfrak g\to\mathfrak a$ and $\mathfrak a\to 0$, and therefore has trace zero. Thus, $x$ is in the radical of the Killing form.
 
 Vice versa, in characteristic zero, if $\mathfrak h\subset \mathfrak g$ is the radical of the Killing form $B_{\mathfrak g}$, it is easy to see from its invariance that $\mathfrak h$ is an ideal of $\mathfrak g$. For every ideal $\mathfrak h\subset \mathfrak g$ the Killing form $B_{\mathfrak g}$ of $\mathfrak g$, restricted to $\mathfrak h$, coincides with the Killing form $B_{\mathfrak h}$ of $\mathfrak h$: indeed, $\text{ad}(x)$ maps $\mathfrak g\to \mathfrak h$ for $x\in \mathfrak h$, so the quotient space $\mathfrak g/\mathfrak h$ does not contribute to the trace of any product of such endomorphisms. Hence, by Cartan's criterion, Theorem \ref{theorem-Cartans-criterion}, $\mathfrak h$ is solvable, which implies that $\mathfrak g$ is not semisimple.
\end{proof}

\begin{remark}
 \label{remark-Killing-positivechar}
 The converse fails in positive characteristic, e.g., the Lie algebra $\mathfrak{sl}_p$ is semisimple if $p\ne 2$ is the characteristic of the field, but its Killing form vanishes.
\end{remark}





\section{Semisimple Lie algebras}
\label{section-semisimple}

In this section, all Lie algebras and vector spaces are finite-dimensional, unless otherwise noted. We will mostly be working in characteristic zero, except for some counterexamples that we give in positive characteristic.

\begin{proposition}
\label{proposition-sum-of-simple}
 Every finite-dimensional, semisimple Lie algebra $\mathfrak g$ in characteristic zero is a direct sum of simple Lie algebras in a unique way:
 $$\mathfrak g = \bigoplus_i \mathfrak g_i.$$
 Its derived Lie algebra $[\mathfrak g, \mathfrak g]$ is equal to $\mathfrak g$, and its ideals are precisely the subsums of the simple summands $\mathfrak g_i$.
\end{proposition}

\begin{proof}
 Let $B$ be the Killing form. Since it is invariant and non-degenerate (by Theorem \ref{theorem-Killing-semisimplicity}, the orthogonal complement of any ideal $\mathfrak h\subset \mathfrak g$ is also an ideal, and $\mathfrak g = \mathfrak h \oplus \mathfrak h^\perp$. By induction on dimension, $\mathfrak g$ is a direct sum of simple Lie algebras.
  
 On every simple summand $\mathfrak h$, $[\mathfrak h, \mathfrak h]$ is an ideal, and since $\mathfrak h$ is simple, we must have $[\mathfrak h, \mathfrak h]=\mathfrak h$, hence the same is true for (the direct sum of simple summands) $\mathfrak g$.
 
 Fixing a direct sum decomposition $\mathfrak g = \bigoplus_i \mathfrak g_i$, the image of the projection of any ideal $I$ to the summand $\mathfrak g_i$ is an ideal, hence the projection is onto or zero. If it is onto, we have $[\mathfrak g_i, I] = \mathfrak g_i$ by what was just proven, therefore $\mathfrak g_i\subset I$. This shows that ideals are precisely the direct summands $\mathfrak g_i$, which implies the uniqueness of the decomposition. 
\end{proof}

\begin{remark}
 \label{remark-notsimplesum-positivechar}
Over a field $k$ in positive characteristic $p$, this theorem does not need to hold. For example (see \cite[\S 2.4]{Rumynin}), there is a nonsplit extension 
$$ 0 \to \mathfrak h = \mathfrak{sl}_2(k[z]/z^p) \to \mathfrak g \to k \to 0$$
where, for a vector space identification $\mathfrak g = \mathfrak h \oplus k$, the summand $k$ acts by a certain derivation:
$$ [(X,x), (Y,y)] = ([X,Y] - x \partial Y + y\partial X),$$
where, for $X = \begin{pmatrix} f(z) & g(z) \\ h(z) & -f(z)\end{pmatrix}$, we have $\partial X = \begin{pmatrix} f'(z) & g'(z) \\ h'(z) & -f'(z)\end{pmatrix}$. (This is the \emph{semidirect product} of $\mathfrak h$ and $k\cdot \partial$, see \ref{subsection-derivations-semidirect}.) 

The derived Lie algebra $[\mathfrak g, \mathfrak g]$ is equal to $\mathfrak h$, which is also the unique minimal ideal.
\end{remark}




\subsection{The Casimir element} 
\label{subsection-Casimir}

The universal enveloping algebra $U(\mathfrak g)$ typically has a large center, even if $\mathfrak g$ does not (e.g., is semisimple). This is a very important reason for invoking the enveloping algebra. The structure of the center, over an algebraically closed field in characteristic zero, is described by the \emph{Harish--Chandra isomorphism}, to be discussed later. For now, we focus on producing some elements in the center. 

Let $(\pi, V)$ be a finite-dimensional representation of a Lie algebra $\mathfrak g$, and assume that the trace pairing 
$$ (X, Y)_\pi = \text{tr}(\pi(X)\pi(Y))$$
is nondegenerate. (In particular, the representation is faithful.)

It is immediate to see that the trace pairing is symmetric and invariant, hence defines a $\mathfrak g$-equivariant isomorphism 
$$ T^2\mathfrak g = \mathfrak g \otimes \mathfrak g \simeq \mathfrak g^*\otimes \mathfrak g.$$



\begin{proposition}
\label{proposition-Casimir}
If  $(\pi, V)$ is a finite-dimensional representation of $\mathfrak g$ with a nondegenerate trace pairing, used to identify $T^2\mathfrak g$ with $\text{End}(\mathfrak g)$, the element $C_\pi \in U(\mathfrak g)$ which is the image of the identity operator $I\in \text{End}(\mathfrak g)$ under the quotient $T\mathfrak g \to U(\mathfrak g)$ lies in the center of $U(\mathfrak g)$.

If $(\pi, V)$ is irreducible and $k$ is algebraically closed, $C_\pi$ acts by a scalar on $V$; that scalar is equal to $\text{dim}(\mathfrak g)/\text{dim}(V)$, if the denominator is prime to the characteristic of $k$.
\end{proposition}

Explicitly, if $(X_i)_i$ is a basis for $\mathfrak g$, and $(Y_i)_i$ is the dual basis with respect to the trace pairing of $\pi$, we have 
$$C_\pi=\sum_i X_i Y_i.$$
Its definition, which does not make use of the basis, makes it clear that this element is independent of the basis.


\begin{proof}
Because of the invariance of the trace form, the adjoint representation of $\mathfrak g$ on the second graded piece $T^2\mathfrak g$ of the tensor algebra coincides with the representation of $\mathfrak g$ on $\mathfrak g^*\otimes \mathfrak g = \text{End}(\mathfrak g)$. Since the element $I\in \text{End}(\mathfrak g)$ is invariant, i.e., $\text{ad}(X)(I) = 0$ for every $X \in \mathfrak g$, we have $\text{ad}(X)(C_\pi) = 0$ for every $X \in \mathfrak g$, hence $C_\pi$ is in the center of $U(\mathfrak g)$.

If $(\pi,V)$ is irreducible, since $C_\pi$ is central, any eigenspace of $C_\pi$ is fixed under $\mathfrak g$; thus, if the representation is irreducible and $k$ is algebraically closed, $C_\pi$ must act by a scalar. If the characteristic of $k$ does not divide $\text{dim}(V)$, that scalar can be computed as $\text{tr}(\pi(C_\pi))/\text{dim}(V)$, and using a dual basis $(X_i)_i$, $(Y_i)_i$, we have
$$ \text{tr}(\pi(C_\pi)) = \sum_i \text{tr}(\pi(X_i)\pi(Y_i)) = \text{dim}(\mathfrak g).$$

(Notice that the representation is automatically faithful, since the trace form is nondegenerate.)
\end{proof}

The following is a useful observation:

\begin{lemma}
\label{lemma-tracepairing-nondegenerate}
 Let $\pi:\mathfrak g \to \mathfrak{gl}(V)$ be a faithful, finite-dimensional representation of a semisimple Lie algebra in characteristic zero. The trace pairing  $(\, , \, )_\pi$ is nondegenerate, and different simple summands of $\mathfrak g$ (Proposition \ref{proposition-sum-of-simple}) are orthogonal with respect to it.
\end{lemma}


\begin{proof}
 By Cartan's criterion \ref{theorem-Cartans-criterion}, the trace pairing is nonzero on each simple summand of $\mathfrak g$; since the radical of an invariant symmetric form is an ideal, it is nondegenerate on each simple summand. The form is invariant, hence the orthogonal complement of each simple summand is $\mathfrak g$-stable, and by induction it decomposes into the direct sum of simple ideals in $\mathfrak g$ (which is unique, by Proposition \ref{proposition-sum-of-simple}).
\end{proof}




\begin{definition}
 \label{definition-Casimir}
Let $\mathfrak g$ be a semisimple Lie algebra in characteristic zero, and use the Killing form, which is nondegenerate by Theorem \ref{theorem-Killing-semisimplicity}, to identify $T^2\mathfrak g = \mathfrak g^*\otimes \mathfrak g = \text{End}(\mathfrak g)$. The element $C$ in the center of $U(\mathfrak g)$ (by Proposition \ref{proposition-Casimir} applied to the adjoint representation), which is the image of the identity operator 
$ I \in \text{End}(\mathfrak g) = T^2 \mathfrak g$ in $U(\mathfrak g)$,
is called the {\it Casimir element} of $U(\mathfrak g)$.
\end{definition}

For example, when $\mathfrak g = \mathfrak{sl}_2$ with generators $(h,e,f)$ and bracket $[h,e]=2e$, $[h,f]=-2f$, $[e,f]=h$, the Casimir element is 
$$ C = \frac{1}{8} h^2 + \frac{1}{4} ef + \frac{1}{4} fe = \frac{1}{8} h^2 - \frac{1}{4} h + \frac{1}{2} ef = \frac{1}{8} h^2 + \frac{1}{4} h + \frac{1}{2} fe.$$



\subsection{Lie algebra cohomology and complete reducibility}
\label{subsection-complete-reducibility}

We will examine the question of whether a short exact sequence of $\mathfrak g$-representations 
\begin{equation}
\label{equation-extension-representations}
0\to A\to B\to C\to 0 
\end{equation}
admits a splitting: $B\simeq A\oplus C$. 

The answer is given in terms of Lie algebra cohomology, which describes isomorphism classes of extensions $B$ as in \eqref{equation-extension-representations} in terms of a cohomology group.

Notice that any exact sequence of $k$-vector spaces splits (as vector spaces). That is, there is an element of $\Hom_k(C,B)$ which lifts the identity element in $\Hom_k(C,C)$. We would like to know that there is a $\mathfrak g$-invariant such element. Thus, it suffices to show that if we apply the functor of ``$\mathfrak g$-invariants'' to the exact sequence:
$$0\to \Hom_k(C,A)\to \Hom_k(C,B) \to \Hom_k(C,C) \to 0,$$
it remains exact. (Notice that, in the context of Lie algebras, $\mathfrak g$-invariants---equivalently, the trivial representation of $\mathfrak g$---simply means that $\mathfrak g$ acts by zero.)

This is a problem is cohomology. The functor of $\mathfrak g$-invariants is left-exact, and it admits right derived functors $H^n(\mathfrak g, \bullet)$ which, in particular, turn any short exact sequence of $\mathfrak g$-modules $0\to U\to V\to W\to 0$ (think of the above $\Hom$ spaces here) to a long exact sequence:
$$0\to U^{\mathfrak g}\to V^{\mathfrak g}\to W^{\mathfrak g}\to H^1(\mathfrak g, U)\to H^1(\mathfrak g, V)\to H^1(\mathfrak g, W)\to \dots.$$

The groups $H^n(\mathfrak g, V)$ can also be thought of as $\text{Ext}^n_{\mathfrak g}(k, V)$, which are the derived functors of $\text{Hom}_{\mathfrak g}(\bullet , \bullet)$ in either argument. The group $\text{Ext}^1(C,A)$, in particular, describes isomorphism classes of extensions \eqref{equation-extension-representations}. 


%The right derived functor $H^1$ can be explicitly described, it turns out, as follows:
%$$H^1(\mathfrak g, V) = Z^1(\mathfrak g, V)/C^1(\mathfrak g, V),$$
%where the cocycles $Z^1(\mathfrak g, V)$ are maps $f:\mathfrak g\to V$ satisfying:
%$$ f([X,Y]) = Xf(Y)-Yf(X),$$
%and the coboundaries are those of the form: $f(X)=Xv$ (for some $v\in V$).

%We will prove that, if $\mathfrak g$ is semisimple and $k$ is of characteristic zero, $H^1(\mathfrak g,V)=0$ for any finite-dimensional $\mathfrak g$-module. 


\begin{theorem}
\label{theorem-complete-reducibility}
 If $\mathfrak g$ is a semisimple Lie algebra in characteristic zero, for any finite-dimensional $\mathfrak g$-module $V$ we have $H^1(\mathfrak g,V)=0$.
 
 Every finite-dimensional representation of $\mathfrak g$ is semisimple.
\end{theorem}

The statement on semisimplicity (complete reducibility) is due to Weyl, and referred to Weyl's theorem.

\begin{proof}
 First, we reduce to simple $\mathfrak g$-modules by induction. Suppose that we have a short exact sequence:
$$0\to U\to V\to W\to 0,$$
and that the first cohomology groups of $U$ and $W$ are trivial, then the long exact sequence shows that $H^1(\mathfrak g, V)=0$, as well.

Now assume that $V$ is irreducible. By the interpretation of $H^1(\mathfrak g, V)$ in terms of isomorphism classes of extensions 
$$ 0 \to V \to W \to k\to 0,$$
it is enough to show that any such extension splits (as $\mathfrak g$-modules).

We will work separately on the cases where $V$ is the trivial representation, and $V$ is nontrivial.

If $V\ne k$, then we first reduce to the case where $\mathfrak g$ acts faithfully on $V$: Let $\mathfrak h$ be the kernel of the map $\mathfrak g\to \mathfrak{gl}(V)$ (it is an ideal of $\mathfrak g$). We claim that $\mathfrak h$ also acts trivially on $W$. Indeed, $\mathfrak g$ maps $W\to V$, and $\mathfrak h$ maps $V\to 0$, so $[\mathfrak h,\mathfrak h]$ acts trivially on $W$. But $\mathfrak g$ is semisimple in characteristic zero, and by Proposition \ref{proposition-sum-of-simple}, it is a sum of simple Lie algebras, hence $\mathfrak h$ is a subsum of those, hence semisimple. Again by the same proposition, $[\mathfrak h,\mathfrak h] = \mathfrak h$. So, the representation $W$ factors through $\mathfrak g/\mathfrak h$, and we may replace $\mathfrak g$ by that to assume that $\mathfrak g$ acts faithfully.

Consider, then, the trace pairing $(X,Y)_\pi\mapsto \text{tr}(\pi(X)\pi(Y))$, where $\pi$ is the representation of $\mathfrak g$ on $V$. By Lemma \ref{lemma-tracepairing-nondegenerate}, it is nondegenerate, hence the central element $C_\pi$ of Proposition \ref{proposition-Casimir} is defined. By the same proposition, $C_\pi$ acts on $V$ by a nonzero scalar; on the other hand, it acts on $k$ by zero. Thus, the short exact sequence can be split $W=V\oplus k$, according to the eigenspaces of $C_\pi$. 

If $V=k$, that means that the image of $\mathfrak g$ in $\text{End}(W)$ consists of nilpotent operators, hence is a nilpotent Lie algebra by Engel's theorem \ref{theorem-Engel}. Being a direct sum of simple Lie algebras by Proposition \ref{proposition-sum-of-simple}, $\mathfrak g$ has no nontrivial nilpotent quotients, hence $W$ is the trivial representation. This completes the proof that $H^1(\mathfrak g, V)=0$ for any finite-dimensional representation $V$. 

Finally, for a short exact sequence of $\mathfrak g$-modules $0\to A \to B\to C \to 0$, applying the vanishing of cohomology to the modules $\Hom_k(C, \bullet)$, we get a short exact sequence
$$ 0\to \Hom_{\mathfrak g}(C,A)\to \Hom_{\mathfrak g}(C,B) \to \Hom_{\mathfrak g}(C,C) \to 0,$$
hence the identity element in $\Hom_{\mathfrak g}(C,C)$ can be lifted to a $\mathfrak g$-morphism $C\to B$. This proves complete reducibility.
\end{proof}


\begin{remarks}
 \label{remarks-complete-reducibility}
 \begin{enumerate}
  \item Complete reducibility fails for infinite-dimensional representations; in fact, in our study of the category $O$, we will construct the finite-dimensional representations as quotients of infinite-dimensional, non-semisimple representations.
  \item Complete reducibility fails in positive characteristic $p$. For example, the Lie algebra $\mathfrak g=\mathfrak{sl}_2$ is semisimple if $p\ne 2$, but the $p$-th symmetric power of its standard representation is not semisimple. Indeed, the space of polynomials of degree $p$ in two variables $(x,y)$ contains the invariant subspace generated by $x^p$ and $y^p$ (with trivial action of $\mathfrak g$), but the $\mathfrak g$-span of any other nonzero vector $v=\sum_{i=0}^p a_i x^{p-i} y^i$ meets that subspace, because if $m$ is the maximal $i$ with $i\ne p$ such that $a_i\ne 0$, and $e= x \frac{\partial}{\partial y} \in \mathfrak g$, we have $e^m v = m! a_m x^m$. 
 \end{enumerate}

\end{remarks}


\subsection{Derivations and the Jordan decomposition}
\label{subsection-derivations-Jordan}



\begin{proposition}
\label{proposition-derivations-inner}
 Every derivation of a semisimple Lie algebra in characteristic zero is inner (Definition \ref{definition-inner-derivation}).
\end{proposition}

\begin{proof}
 The formula $[D,\text{ad}(X)]=\text{ad}(DX)$ shows that the image of $\text{ad}$ is an ideal in $\text{Der}(\mathfrak g)$. Since the image is a semisimple Lie algebra, there is a complementary ideal $I$ (namely, its orthogonal complement under the Killing form on $\text{Der}(\mathfrak g)$). But if $D\in I$, and $I$ is an ideal, the same formula shows that $\text{ad}(DX)\in I\cap \text{ad}(\mathfrak g)=0$, which since $\text{ad}$ is injective means that $DX=0$, i.e.\ $D=0$.
\end{proof}

\begin{remark}
 \label{remark-failure-inner}
 We already saw in Remark \ref{remark-notsimplesum-positivechar} that Proposition \ref{proposition-derivations-inner} fails in positive characteristic.
\end{remark}



\begin{proposition}
\label{proposition-Jordan-derivations}
 If $D\in \text{Der}(\mathfrak g)\subset \text{End}(\mathfrak g)$ then $D_s,D_n\in\text{Der}(\mathfrak g)$.
\end{proposition}

\begin{proof}
We may assume that the field is algebraically closed. 
 If $X$ is in the generalized $\lambda$-eigenspace and $Y$ is in the generalized $\mu$-eigenspace for $D$, then it can be shown by induction that:
$$ (D-(\lambda+\mu))^n([X,Y]) = \sum_{r=0}^n \binom{n}{r} [(D-\lambda)^r(X),(D-\mu)^{n-r}(Y)],$$
hence $[X,Y]$ is in the generalized $\mu+\lambda$-eigenspace. This shows that $D_s$ is a derivation, and then $D_n=D-D_s$ is a derivation.
\end{proof}


\begin{definition}
\label{definition-nilpotent-semisimple-element}
Let $\mathfrak g$ be a Lie algebra. An element $X\in \mathfrak g$ is called \emph{semisimple} if $\text{ad}(X)$ is a semisimple operator, and \emph{nilpotent} if $\text{ad}(X)$ is nilpotent.
\end{definition}

\begin{theorem}[Jordan--Chevalley decomposition]
\label{theorem-Jordan-Chevalley}
Let $\mathfrak g$ be a semisimple Lie algebra in characteristic zero. Every $X\in \mathfrak g$ admits a unique decomposition $X=X_s + X_n$, with $X_s$ semisimple, $X_n$ nilpotent, and $[X_s,X_n]=0$.

Moreover, for any finite-dimensional representation $\rho:\mathfrak g \to \mathfrak{gl}(V)$, and any $X\in \mathfrak g$, we have
$\rho(X_s) = \rho(X)_s$, $\rho(X_n)=\rho(X)_n$, where $\rho(X)=\rho(X)_s+\rho(X)_n$ is the Jordan decomposition of $\rho(X)$.

For any morphism $\pi: \mathfrak g_1 \to \mathfrak g_2$ of semisimple Lie algebras in characteristic zero, and any $X\in \mathfrak g_1$, we have $\pi(X_s) = \pi(X)_s$, $\pi(X_n)=\pi(X)_n$.
\end{theorem}


\begin{proof}
By the Propositions \ref{proposition-Jordan-derivations}, $\text{ad}(X)_s$ and $\text{ad}(X)_n$ are derivations in $\text{End}(\mathfrak g)$. By Proposition \ref{proposition-derivations-inner}, they belong to the image of $\text{ad}$. Since the adjoint representation is faithful, this proves the existence and uniqueness of $X_s$ and $X_n$. 

By complete reducibility of $\text{End}(V)$ under the adjoint $\mathfrak g$-action, we have:
$$\text{End}(V)= \rho(\mathfrak g)\oplus\mathfrak m,$$
where $\mathfrak m$ is an $\text{ad}(\rho(\mathfrak g))$-invariant subspace. (Notice that in Proposition \ref{proposition-derivations-inner} we were able to obtain a similar decomposition in $\text{Der}(\mathfrak g)$ by using the Killing form, so we did not need to know reducibility.)

Since $\rho(X)_s,\rho(X)_n$ are polynomials in $\rho(X)$, their adjoint action preserves both $\rho(\mathfrak g)$ and $\mathfrak m$. Let $\rho(X)_n = \rho(a) + b$ with $a\in \mathfrak g,b\in \mathfrak m$. Since $[\rho(\mathfrak g),b]=0$,  $b\in \text{End}(V)$ is a $\mathfrak g$-endomorphism. If $V=\oplus V_i$ is a decomposition into irreducibles, $b$ acts by a scalar on each one of them, by Schur's lemma. On the other hand, we know that $\rho(X)_n$ is nilpotent, $\rho(a)$ and $b$ commute, and $\text{tr}_{V_i}(\rho(a)) =0$ because $a$ (like every element of $\mathfrak g$) is a sum of commutators. Therefore, $\text{tr}_{V_i}(b)=0$, hence $b$ acts by zero on all $V_i$, i.e.\ $b=0$. 

Now, $\rho(X)_n=\rho(a)$ acts nilpotently on $V$, hence it acts nilpotently on $\text{End}(V)$ under the adjoint representation. By the decomposition $\text{End}(V)=\mathfrak g\oplus \mathfrak m$ it follows that it acts nilpotently on $\mathfrak g$. By the uniqueness of the Jordan decomposition we can now infer that $\rho(X)_n= \rho(X_n)$. 

Finally, for any morphism $\pi: \mathfrak g_1 \to \mathfrak g_2$, setting $\rho=\text{ad}\circ\pi$ and applying the previous statement, we obtain the last statement.
\end{proof}



\section{Root systems and the structure of semisimple Lie algebras}
\label{section-root-decomposition}

In this section, the underlying field is of characteristic zero, and we keep assuming that all vector spaces are finite dimensional.

\subsection{Representations of $\mathfrak{sl}_2$.}
\label{subsection-representations-sl2}

The Lie algebra of $\mathfrak{sl}_2$ is generated over the underlying field by three elements $H, E, F$ with bracket relations:
$$[H,E]=2E,$$
$$[H,F]=-2F,$$
$$[E,F] = H.$$

Let $\Delta = 8 C = 4FE + (H+2) H$ in the center of $U(\mathfrak g)$. (It turns out---see the Harish-Chandra isomorphism, Theorem \ref{vermamodules-theorem-HC-isomorphism}--- that $Z(U\mathfrak g)$ is a polynomial ring generated by this element.)

Given a representation $V$ of $\mathfrak{sl}_2$ (recall that all spaces are assumed finite-dimensional in this chapter), and $\lambda\in k$, let $V_\lambda$ denote the $\lambda$-eigenspace of $H$. We don't know yet that $H$ acts semisimply, so a priori $V$ is not the direct sum of the $V_\lambda$'s. 

\begin{lemma}
\label{lemma-shift-eigenspaces}
 $E\cdot V_\lambda\subset V_{\lambda+2}$; $F\cdot V_\lambda\subset V_{\lambda-2}$.

There is a non-zero vector $v\in V$ which is an eigenvector for $H$ and such that $Ev=0$. 
\end{lemma}

\begin{proof}
The first statement is clear from the bracket relations. From the finite-dimensionality of $V$, there must be a nonzero $H$-eigenvector annihilated by $E$.
\end{proof}

\begin{definition}
\label{definition-highest-weight}
A {\it highest weight vector of an $\mathfrak{sl}_2$-module} is a nonzero vector annihilated by $E$. A {\it lowest weight vector of an $\mathfrak{sl}_2$-module} is a nonzero vector annihilated by $F$. 
\end{definition}



\begin{proposition}
\label{proposition-sl2-irreducibles}
 Fix a heighest weight vector $v\in V_\lambda$, and let $V'$ be the span of $\{F^iv\}_{i\in\mathbb N}$. Then $V'$ is $\mathfrak{sl}_2$-stable, irreducible, and $\Delta$ acts by $\lambda(\lambda + 2)$. The highest weight $\lambda$ is a non-negative integer, and $V'$ is the sum of one-dimensional weight spaces $V'_{\mu}$ for $\mu = \lambda, \lambda-2,\lambda-4, \dots, -\lambda$.

\end{proposition}

\begin{proof}
 It is clearly stable under $F$ and $H$. We easily compute:
$$ EF^nv_\lambda = n(\lambda-(n-1))F^{n-1}v_\lambda.$$
Hence, the space is $E$-stable. 

Moreover, since it is finite-dimensional, we must have $n(\lambda-(n-1))=0$ for some $n\ge 1$, hence $\lambda$ is a non-negative integer. In that case, $n=\lambda+1$, and $F^n v_\lambda$ must be zero (because it is a highest weight vector of weight $-\lambda-2$ and, by the same argument, it cannot generate a finite-dimensional representation). On the other hand, for $n<\lambda+1$ $EF^nv_\lambda\ne 0$, hence $F^nv_\lambda\ne 0$. The statement about the weight spaces of $V'$ follows.

We have: $\Delta v = 4FEv+(H+2)Hv = 0+ \lambda(\lambda+2)v$. Since $\Delta$ commutes with the action of $\mathfrak{sl}_2$ and is generated by $v$, all elements of $V'$ have the same $\Delta$-eigenvalue.

On the other hand, $V'$ has at most one eigenvector for each $H$-eigenvalue. If $V'$ was reducible, there would be some highest weight vector with eigenvalue $\ne $
\end{proof}




\begin{theorem}
\label{theorem-reps-sl2}
For every nonnegative integer $n$ there is a unique, up to isomorphism, irreducible finite-dimensional representation $V_n$ of $\mathfrak{sl}_2$ of heighest weight $n$ (in characteristic zero). It has dimension $n+1$, and eigenvalue $n(n+2)$ under the operator $\Delta$.

All finite-dimensional representations of $\mathfrak{sl}_2$ are $H$-semisimple, and direct sums of the modules $V_n$.
\end{theorem}


\begin{proof}
If $V$ denotes the standard, $2$-dimensional representation, then it is easy to see that $S^n V$ has a unique highest weight vector with weight $n+1$, hence is irreducible. Uniqueness follows from the explicit description of the action of $E, F$ and $H$ above, and the rest follow from complete reducibility (Theorem \ref{theorem-complete-reducibility}) and Proposition \ref{proposition-sl2-irreducibles}.
\end{proof}

This existence statement will require a lot more work in the general case.

\subsection{Cartan subalgebras of semisimple Lie algebras}
\label{subsection-CSA-semisimple}

\begin{proposition}
\label{proposition-CSA-semisimple}
 Assume that $\mathfrak g$ is a semisimple  Lie algebra in characteristic zero, and let $\mathfrak h$ be the generalized nilspace of an s-regular element (hence\footnote{Eventually, since they are conjugate, all Cartan subalgebras are of this form}, by Proposition \ref{proposition-CSA-centralizer}, a Cartan subalgebra). Then:
\begin{enumerate}
 \item $\mathfrak h$ is a maximal abelian subalgebra.
 \item The centralizer of $\mathfrak h$ is $\mathfrak h$.
 \item Every element of $\mathfrak h$ is semisimple. Every s-regular element of $\mathfrak g$ is semisimple.
 \item \label{Killingrestriction} The restriction of the Killing form (or any non-degenerate invariant symmetric bilinear form) of $\mathfrak g$ to $\mathfrak h$ is non-degenerate.
\end{enumerate}
\end{proposition}

\begin{proof}
If we prove \eqref{Killingrestriction}, the rest of the statements will follow; let us see how: 

Cartan's criterion says that a Lie subalgebra $\mathfrak a$ of $\text{End}(V)$ is solvable if and only if $\text{tr}(XY)=0$ for every $X\in \mathfrak a, Y\in [\mathfrak a,\mathfrak a]$. Applying this to $\text{ad}(\mathfrak h)\subset \text{End}(\mathfrak g)$ (which is nilpotent, hence solvable), we get that $B(X,Y)=0$ for all $X\in \mathfrak h, Y\in[\mathfrak h,\mathfrak h]$ (where $B$ is the Killing form for $\mathfrak g$). Therefore, the radical of the restriction of $B$ to $\mathfrak h$ contains the commutator, which means that $[\mathfrak h,\mathfrak h]=0$. Thus, $\mathfrak h$ is abelian.

The centralizer is contained in the normalizer, which is $\mathfrak h$, but since $\mathfrak h$ is abelian it coincides with it. Thus, $\mathfrak h$ is maximal abelian.

Finally, let $X\in\mathfrak h$ and let $X=X_s+X_n$ be its Jordan decomposition. Since $X_s, X_n$ commute with the centralizer of $X$, which contains $\mathfrak h$, it follows that $X_s, X_n$ are in the centralizer of $\mathfrak h$, which is $\mathfrak h$. Thus, if $Y\in\mathfrak h$, $\text{ad}(Y)\text{ad}(X_n)$ is nilpotent, which implies that $\text{ad}(X_n)$ is orthogonal to $\mathfrak h$ under the Killing form. By non-degeneracy of the Killing form on $\mathfrak h$, $X_n=0$. Every s-regular element of $\mathfrak g$ is contained in its generalized nilspace $\mathfrak h$, hence is semisimple.

We come to the proof of \eqref{Killingrestriction}: if $X$ is an $s$-regular element such that $\mathfrak h$ is the generalized nilspace of $X$, let $\mathfrak g = \bigoplus_\lambda \mathfrak g_\lambda$ be a decomposition of $\mathfrak g$ into generalized $\text{ad}(X)$-eigenspaces. As we saw in the proof of Proposition \ref{proposition-Jordan-derivations}, $[\mathfrak g_\lambda,\mathfrak g_\mu]\subset \mathfrak g_{\lambda+\mu}$, which implies that $\mathfrak g_\lambda \perp \mathfrak g_\mu$ (under the Killing form), unless $\lambda+\mu=0$. Therefore, the decomposition:
$$ \mathfrak g = \mathfrak g_0 \oplus \bigoplus (\mathfrak g_{\lambda}\oplus \mathfrak g_{-\lambda})$$
is orthogonal, and since $B$ is nondegenerate, it has to be non-degenerate on each of the summands, in particular on $\mathfrak h=\mathfrak g_0$.
\end{proof}




\subsection{The root system of a semisimple Lie algebra}
\label{subsection-root-systems}

Let $\mathfrak g$ be a semisimple Lie algebra over an algebraically closed field $k$ in characteristic zero. Fix $\mathfrak h\subset \mathfrak g$ a Cartan subalgebra. All constructions that follow depend, a priori, on $\mathfrak h$. In Section \ref{section-conjugacy-Borel-Cartan} we will see that all Cartan subalgebras are conjugate, and this will establish independence of the root system of $\mathfrak g$ from the choice of $\mathfrak h$. Recall that, by Proposition \ref{proposition-CSA-semisimple}, $\mathfrak h$ is abelian. It


By Proposition \ref{proposition-CSA-semisimple}, the restriction of the adjoint representation to a Cartan subalgebra $\mathfrak h$ reads:
\begin{equation}
 \label{equation-root-decomposition}\mathfrak g = \mathfrak h \oplus \bigoplus_{\alpha}  \mathfrak g_\alpha,
\end{equation}
where the $\mathfrak g_\alpha$'s are eigenspaces with \emph{nonzero} eigencharacter $\alpha \in \mathfrak h^*$.


\begin{definition}
 \label{definition-roots}
The set $\Phi$ of nonzero elements $\alpha \in \mathfrak h^*$ such that $\mathfrak g_\alpha\ne 0$ in the decomposition \eqref{equation-root-decomposition} is called the set of {\it roots} of $\mathfrak g$.
\end{definition}

\begin{theorem}
 \label{theorem-root-system}
The following hold for the set of roots $\Phi$ of a semisimple Lie algebra $\mathfrak g$: 
\begin{enumerate}
 \item $\Phi$ spans $\mathfrak h^*$.
 \item If $\alpha\in \Phi$, then $-\alpha\in \Phi$.
 \item If $\alpha\in\Phi$, let $\mathfrak t_\alpha \in \mathfrak h$ be the image of $\alpha$ under the isomorphism: $\mathfrak h^*\to\mathfrak h$ defined by a non-degenerate invariant symmetric form $(\,,\,)$ on $\mathfrak g$. Then, for all $X\in \mathfrak g_\alpha, Y\in\mathfrak g_{-\alpha}$ we have: $[X,Y] = (X,Y) t_\alpha$. 
 \item $(t_\alpha,t_\alpha)\ne 0$.
 \item The sum $\mathfrak h_\alpha+ \mathfrak g_\alpha + \mathfrak g_{-\alpha}$ is a subalgebra isomorphic to $\mathfrak{sl}_2$; denote it by $\mathfrak{sl}_{2,\alpha}$.
 \item  If $\alpha, c\alpha\in \Phi$ then $c = \pm 1$.
 \item For any $\alpha, \beta\in \Phi$ and non-proportional, the $\mathfrak{sl}_{2,\alpha}$-stable subspace $\mathfrak g_{\beta + \mathbb Z \alpha}$ is an irreducible representation of $\mathfrak{sl}_{2,\alpha}$.
 \item For any $\alpha\in \Phi$, let $w_\alpha$ be the linear transformation $\lambda\mapsto \lambda - \left< \lambda, h_\alpha\right>$ on $\mathfrak h^*$. Then, $w_\alpha$ fixes $\Phi$.
\end{enumerate}
\end{theorem}

\begin{remark}
 \label{remark-indep-of-form}
For the last statement of Theorem \ref{theorem-root-system}, we could have used any positive definite invariant inner product; indeed, on the simple summands of $\mathfrak g$ (see Proposition \ref{proposition-sum-of-simple}) any two of them are equal up to a scalar, and the different summands are orthogonal, so the reflections do not depend on the choice of invariant inner product. 
\end{remark}


\begin{proof}

\begin{enumerate}
 \item Any $x\in \mathfrak h$ in the kernel of $\Phi$ is central in $\mathfrak g$, hence zero since $\mathfrak g$ is semisimple.
 \item Choose a non-degenerate invariant symmetric form $(\,,\,)$. For $\alpha$, $\beta$ in $\Phi$ (or zero),  $x \in \mathfrak g_\alpha$, $y\in \mathfrak g_\beta$ and any $z\in \mathfrak h$, by invariance we have 
 $$ \alpha(z) (x,y) = ([z,x],y) = - (x, [z,y]) = -\beta(z) (x,y).$$
 Thus, $(x,y)=0$ unless $\alpha+\beta=0$. Since the form is nondegenerate, for every $x$ there must be a $y$ with $(x,y)\ne 0$, thus if $\alpha\in\Phi$, so is $-\alpha$. 
 \item Notice first that $[\mathfrak g_\alpha,\mathfrak g_\beta]\subset \mathfrak g_{\alpha+\beta}$, so $[x,y]$ must belong to $\mathfrak h$. For all $z\in \mathfrak h$, $x\in \mathfrak g_\alpha, y\in\mathfrak g_{-\alpha}$ we have: $(z,[x,y]) = ([z,x],y) = \alpha(z) (x,y) = (z, (x,y) t_\alpha)$. Since the form is nondegenerate on $\mathfrak h$, by Proposition \ref{proposition-CSA-semisimple}, we deduce that $[x,y] = (x,y) t_\alpha$. 
 \item Notice that the pairing $(\,,\,)$ between $\mathfrak g_\alpha$ and $\mathfrak g_{-\alpha}$ is nonzero because otherwise it would be degenerate on $\mathfrak g$. It follows that $\mathfrak h_\alpha:= [\mathfrak g_\alpha,\mathfrak g_{-\alpha}]$ is one-dimensional, spanned by the element $t_\alpha$. If $(t_\alpha, t_\alpha)=0$ then $(t_\alpha, [x,y])=0$ (for $x,y$ as before), which implies that $[t_\alpha, x]=[t_\alpha,y]=0$, and the elements $x, y, t_\alpha$ span a solvable Lie algebra. Thus, its image under the adjoint representation stabilizes a full flag, and since $t_\alpha$ is in its commutator, $\text{ad}(t_\alpha)$ is nilpotent. But by Proposition \ref{proposition-CSA-semisimple}, $\text{ad}(t_\alpha)$ is also semisimple, so it has to be zero, which means that $t_\alpha$ is a central element in $\mathfrak g$, a contradiction.
 \item Let $h_\alpha \in\mathfrak h_\alpha$ be the element characterized by $\alpha(h_\alpha)=2$, that is, $h_\alpha = \frac{2}{(t_\alpha,t_\alpha)} t_\alpha$. Choose any nonzero element $x=e \in \mathfrak g_\alpha$, and then choose $y=f\in\mathfrak g_{-\alpha}$ with $(e,f) = \frac{2}{(t_\alpha,t_\alpha)}$. Then, $(h,e,f)$ is an $\mathfrak{sl}_2$-triple, and we denote its span by $\mathfrak{sl}_{2,\alpha}$. The subspace
 $$ \mathfrak m = \mathfrak h_\alpha \oplus \bigoplus_{n\in \mathbb Z, n \ne 0} \mathfrak g_{n\alpha}$$ decomposes, as an $\mathfrak{sl}_{2,\alpha}$-module, into finite-dimensional irreducible representations with even weights (for $h_\alpha$). Since the zero weight space is one-dimensional, this implies (from the classification of irreducible, finite-dimensional representations of $\mathfrak{sl}_2$) that it is irreducible. It contains the adjoint representation of $\mathfrak{sl}_2$, therefore $\mathfrak m = \mathfrak{sl}_{2,\alpha}$. 
 \item The previous point proves that there are no integral multiples of $\alpha$ in $\Phi$, other than $\pm \alpha$. Similarly, again by the classification of irreducible, finite-dimensional representations of $\mathfrak{sl}_2$, the only other multiples are half-integral, and if one of them appears, then $\frac{\alpha}{2}$ must appear; indeed, the weights for $h_\alpha$ have to be integers, and if an odd integer appears, then so must the weight $1$. But, repeating this argument with $\frac{\alpha}{2}$ in place of $\alpha$, we get that $2\frac{\alpha}{2}$ cannot appear, a contradiction. Hence, $\frac{\alpha}{2}\notin \Phi$.
 \item  For any $\beta\in \Phi$ which is non-proportional to $\alpha$, consider the subspace
 $$\mathfrak n = \mathfrak g_{\beta + \mathbb Z \alpha}.$$
 It is a $\mathfrak{sl}_{2,\alpha}$-stable subspace with weights (for $h_\alpha$) of the same parity, and each nonzero-weight space is one-dimensional, therefore it is an irreducible representation of $\mathfrak{sl}_{2,\alpha}$.
 \item By the classification of irreducible representation of $\mathfrak{sl}_2$, the subspace $\mathfrak n$
 must include a range of weights differing by $2$; therefore, 
 $$\Phi \cap (\beta + \mathbb Z \alpha) = \left\{\beta+ n\alpha\right\}_{n=-r}^q$$
 for some nonnegative integers $r, q$. This has $r+q+1$ weights, therefore the lowest weight must be $-(r+q)$, the heighest weight must be $(r+q)$. Therefore, 
\begin{equation}
 \label{equation-pairing-roots}
\left< \beta, h_\alpha\right> = r-q,
\end{equation}
and we get 
 $$ w_\alpha(\beta) = \beta - \left< \beta, h_\alpha\right> \alpha = \beta - (r-q)\alpha \in \Phi.$$
\end{enumerate}
\end{proof}


\begin{definition}
 \label{definition-root-system}
A (crystallographic) {\it root system} is a triple $(E,\Phi, W)$, where 
\begin{itemize} \item $E$ be a finite-dimensional real vector space;
 \item $\Phi$ is a finite subset of $E$ not containing zero;
 \item $W \subset \text{GL}(E)$ is a (necessarily finite) group of automorphisms preserving $\Phi$,
 generated by elements $w_\alpha$, $\alpha\in \Phi$, which fix a hyperplane and send the root $\alpha$ to $-\alpha$. 
\end{itemize}

The group $W$ is called the {\it Weyl group} of the root system.

The root system is said to be {\it reduced} if $\Phi\cap \mathbb R\alpha = \{\pm \alpha\}$. 
\end{definition}

\begin{definition}
 \label{definition-rootsystem-ofLiealgebra}
The {\it root system of a semisimple Lie algebra} $\mathfrak g$, with respect to a Cartan subalgebra $\mathfrak h$, is the triple $(E,\Phi,W)$, where $\Phi\subset \mathfrak h^*$, $E$ is the $\mathbb R$-span of $\Phi$, and $W$ is the group generated by the reflections $w_\alpha$, $\alpha\in \Phi$.
\end{definition}


\begin{remark}
 \label{remark-definition-rootsystem}
In many references, a root system is defined with $W$ replaced by an inner product on $E$, such that the elements $w_\alpha$ are orthogonal reflections on the hyperplanes perpendicular to the roots. Clearly, such an inner product determines the Weyl group $W$; vice versa, any finite-dimensional representation of a finite group is unitarizable, so for any root system in the sense of Definition \ref{definition-root-system}, there is an inner product with respect to which the $w_\alpha$'s are orthogonal reflections. Moreover, up to the obvious freedom of rescaling the inner product on each \emph{irreducible} summand of the root system (i.e., a summand that cannot be further decomposed as a direct sum of two root systems), the inner product is unique.

The following proposition shows a way to produce such an inner product for a given Lie algebra.
\end{remark}

\begin{lemma}
\label{lemma-Killing-positivedefinite} 
Let $(\, , \,)$ be the Killing form, and use it to identify $\mathfrak h^*=\mathfrak h$. Let $E$ be the $\mathbb R$-span of the roots. Then, the Killing form is positive definite on the span of roots.
\end{lemma}

\begin{proof}
Let $t_\lambda\in \mathfrak h$ be the element that corresponds to $\lambda\in \mathfrak h^*$ under the identification. We compute:
$$(\lambda,\lambda)=(t_\lambda,t_\lambda) = \text{tr}((\text{ad}(t_\lambda))^2) = \sum_{\alpha\in\Phi} \alpha(t_\lambda)^2.$$ 
If we can show that $(\alpha,\beta)=\alpha(t_\beta)\in \mathbb R$ for every root $\beta$, that would imply positivity (since we already know, from Theorem \ref{theorem-root-system}, that $\alpha(t_\alpha) = (t_\alpha, t_\alpha)\ne 0$.

From \eqref{equation-pairing-roots}, we have that $(\alpha,\beta) =  \alpha(t_\beta) = \frac{\alpha(h_\beta)}{2} (\beta,\beta) \in \mathbb Q\cdot (\beta,\beta)$, and therefore
$$(\beta,\beta) = \sum_{\alpha\in\Phi} (\alpha,\beta)^2 \in \mathbb Q\cdot (\beta,\beta)^2,$$
therefore $(\beta,\beta) \in \mathbb Q$ and $(\alpha,\beta)\in \mathbb Q$.
\end{proof}



\begin{definition}
 \label{definition-coroots}
Given a Cartan algebra $\mathfrak h\subset \mathfrak g$, the element $h_\alpha\in\mathfrak h$ of any $\mathfrak{sl}_2$-triple $(h_\alpha, e, f)$ with $e\in\mathfrak g_\alpha$, $f\in\mathfrak g_{-\alpha}$ is called the {\it coroot} associated to the root $\alpha$, and denoted by $\check\alpha$. 
\end{definition}

Notice that $\mathfrak h_\alpha$ does not depend on the choice of $e$ and $f$. We will denote the set of coroots by $\check\Phi$. Hence, the simple reflection $w_\alpha$ on $\mathfrak h^*$ associated to the root $\alpha$ can be written:
\begin{equation}
 \label{equation-reflection-coroot}
 w_\alpha(x) = x - \left< x, \check\alpha\right> \alpha.
\end{equation}

\begin{lemma}
 \label{lemma-dualrootsystem}
If $(E,\Phi, W)$ is a root system, then $(E^*,\check\Phi, W)$ is also a root system, where $W$ acts on $E^*$ by the dual representation to $E$.
\end{lemma}

\begin{proof}
 Obvious.
\end{proof}


\begin{definition}
 \label{definition-dual-rootsystem}
If $(E,\Phi, W)$ is a root system, the {\it dual root system} is the triple $(E^*,\check\Phi, W)$ of Lemma \ref{lemma-dualrootsystem}.
\end{definition}

We will need the classification of root systems of rank two, and a corollary of that.

\begin{proposition}
\label{proposition-ranktwo}
 The only root systems of rank two are the root systems $A_1\times A_1$, $A_2$, $B_2$ and $G_2$. If $\alpha,\beta$ are two non-proportional roots in a root system $\Phi$ with $\left< \alpha, \check\beta\right> < 0$, then 
$\alpha+\beta \in \Phi$.
\end{proposition}

\begin{proof}

[Definitions and proofs for the first statement to be added later---easy to look up!]

If $\alpha,\beta$ are non-proportional roots in a root system, the intersection of the set of roots with their linear span, together with the subgroup of the Weyl group generated by the reflections $w_\alpha$, $w_\beta$, form a root system of rank two. The classification shows that if $\left<\alpha, \check\beta\right> <0$, then $\alpha+\beta$ is also a root. 

\end{proof}



\section{Parabolic subalgebras}
\label{section-parabolic-subalgebras}

\begin{definition}
\label{definition-based-root-system}
 A {\it based root system} is a quadruple $(E,\Phi \supset \Phi^+, W)$ consisting of a root system, and a subset $\Phi^+$ which consisting of the elements of $\Phi$ on one side of a hyperplane not meeting $\Phi$ (that is, $\Phi^+ = \{\alpha\in\Phi| t(\alpha)>0\}$ for some linear functional $t\in E^*$ such that $\ker(t)$ does not contain any roots).
 
 The {\it simple roots} of a based root system are those elements of $\Phi^+$ which cannot be written (non-trivially) as a nonnegative integral linear combination of other elements of $\Phi^+$. The set $\Delta$ of simple roots is called a {\it basis} of the root system.
\end{definition}

The name is due to the following:

\begin{proposition}
\label{proposition-basis-rootsystem}
Given a based root system $(E,\Phi \supset \Phi^+, W)$ with set of simple roots $\Delta$,
the \emph{root lattice} $R=\left< \Phi \right>_{\mathbb Z}$ (the subgroup of $E$ generated by $\Phi$) is freely generated by $\Delta$; in particular, the elements of $\Delta$ are linearly independent.
\end{proposition}

\begin{proof}
Choose an inner product $(\, , \, )$ with respect to which the elements of $W$ are orthogonal. 

By Proposition \ref{proposition-ranktwo}, we have $(\alpha,\beta)\le 0$ for all $\alpha,\beta\in\Delta$, because otherwise $\alpha-\beta$ or $\beta-\alpha$ would belong to $\Phi^+$, contradicting the fact that they are indecomposable.

Consider a nontrivial zero linear combination
$$ \sum_{\alpha\in \Delta} c_\alpha \alpha = 0.$$
 Since all elements of $\Delta$ belong to the same open half-plane, some of the coefficients are positive and some are negative, so we can write
 $$ \lambda:= \sum_{\alpha\in \Delta, c_\alpha>0} c_\alpha \alpha = \sum_{\alpha\in \Delta, c_\alpha< 0} (-c_\alpha)\alpha,$$
 with none of the two sums being empty. Then, 
 $$(\lambda,\lambda) = \left(\sum_{\alpha\in \Delta, c_\alpha>0} c_\alpha \alpha, \sum_{\alpha\in \Delta, c_\alpha< 0} (-c_\alpha)\alpha\right) \le 0,$$
contradicting the positivity of the inner product. 

Thus, the elements of $\Delta$ are linearly independent, and since by definition every other element of $\Phi^+$ belongs to their $\mathbb Z$-span, they are a free basis for the root lattice.
\end{proof}





\begin{definition}
\label{definition-Borel-parabolic}
 A {\it Borel subalgebra} of a Lie algebra is a maximal solvable subalgebra. A {\it parabolic subalgebra} is a subalgebra containing a Borel subalgebra.
\end{definition}

Obviously, every Cartan subalgebra is contained in a Borel subalgebra. 

\begin{lemma}
 \label{lemma-BSA-self-normalizing}
A Borel subalgebra $\mathfrak b$ of a Lie algebra $\mathfrak g$ is self-normalizing.
\end{lemma}

\begin{proof}
 If $x\in \mathfrak g$ normalizes $\mathfrak b$, then the subalgebra $\mathfrak b'$ generated by $\mathfrak b$ and $x$ is solvable. By the maximality of $\mathfrak b$, $\mathfrak b' = \mathfrak b$.
\end{proof}




The following will be useful for the results that follow:

\begin{lemma}
\label{lemma-closed-subset}
Any Lie subalgebra of $\mathfrak g$ containing the Cartan subalgebra $\mathfrak h$ is of the form  
$$ \mathfrak g = \mathfrak h \oplus \bigoplus_{\alpha\in P} \mathfrak g_\alpha,$$
for some \emph{closed} subset $P\subset \Phi$, in the sense that if $\alpha,\beta\in P$ and $\alpha+\beta\in \Phi$, then $\alpha+\beta\in P$.
\end{lemma}

\begin{proof}
Any Lie subalgebra containing $\mathfrak h$ is an $\mathfrak h$-submodule, therefore a sum of $\mathfrak h$ with some of the (one-dimensional) root spaces.

The fact that the subset $P$ of roots appearing is closed follows from Theorem \ref{theorem-root-system}: for $\alpha$, $\beta$ non-proportional, the subspace $\mathfrak g_{\beta+\mathbb Z\alpha}$ is an irreducible $\mathfrak{sl}_{2,\alpha}$-representation; therefore, a nonzero element $e\in \mathfrak g_\alpha$ does not kill $\mathfrak g_\beta$, unless this is the highest weight space, that is, unless $\alpha+\beta\notin \Phi$. 
\end{proof}


\begin{proposition}
\label{proposition-roots-parabolics}
 Given a Cartan subalgebra $\mathfrak h$ in a semisimple Lie algebra $\mathfrak g$, the set of Borel subalgebras containing $\mathfrak h$ is in bijection with the set of bases on the root system $(E, \Phi,W)$ associated to $\mathfrak h$, where a choice $\Phi^+\subset \Phi$ of positive roots corresponds to the Borel subalgebra
 $$ \mathfrak b = \mathfrak h + \bigoplus_{\alpha\in\Phi^+} \mathfrak g_\alpha.$$
 The parabolic subalgebras containing this Borel subalgebra are determined by subsets of the set $\Delta$ of simple roots, with $I\subset\Delta$ corresponding to the parabolic subalgebra
 $$ \mathfrak p_I = \mathfrak b + \bigoplus_{\alpha\in \Phi_I^+} \mathfrak g_{-\alpha},$$
 where $\Phi_I^+$ is the set of elements of $\Phi^+$ in the span of $I$.
\end{proposition}

\begin{proof}
 Any Lie subalgebra containing $\mathfrak h$ must be a sum of root spaces, and if it is solvable it cannot contain $\mathfrak g_\alpha$ and $\mathfrak g_{-\alpha}$ at the same time, because then it would contain a copy of $\mathfrak{sl}_2$. Thus, if $P$ is the set of roots whose root spaces are contained in $\mathfrak b$, we have $P\cap (-P)=\emptyset$. We will prove that this implies that $P$ lies in a half-space. 
 
 We claim that no nontrivial sum $\alpha_1+\dots+\alpha_n$ of elements of $P$ is zero; indeed, if this is the case, then $(\alpha_1, \alpha_j) <0$ for some $j$ (for a chosen invariant inner product), therefore $\alpha_1+\alpha_j\in \Phi$ by Proposition \ref{proposition-ranktwo}, and therefore $\alpha_1+\alpha_j\in P$, by Lemma \ref{lemma-closed-subset}. This reduces the claim to a sum of $n-1$ elements, and the claim follows by induction. 
 
 Now we claim that there exists an $\beta\in P$ with $(\alpha,\beta)\ge 0$ for all $\alpha\in P$. If not, we would be able to choose an infinite sequence $\alpha_\bullet: \mathbb N \to P$ with $\beta_n=\alpha_1 + \alpha_2+\dots+\alpha_n \in P$ for all $n$; indeed, having chosen the first $n$ elements of this sequence, by assumption $(\alpha,\beta_n)$ is not $\ge 0$ for all $\alpha\in P$, but then choosing $\alpha_{n+1}$ with $(\alpha_{n+1},\beta_n)<0$, again by Proposition \ref{proposition-ranktwo} and Lemma \ref{lemma-closed-subset}, we would get that $\beta_n+\alpha_{n+1} \in P$. Now, the finiteness of $P$ implies that $\beta_i = \beta_j$ for some $i< j$, implying that $\alpha_{i+1} + \dots + \alpha_j=0$, a contradiction. 
 
 This proves that $P$ lies in a half-space (open, since no opposite elements of $\Phi$ are in $P$), and it is clear that a Lie algebra of the form $\mathfrak h + \bigoplus_{\alpha\in\Phi^+} \mathfrak g_\alpha$ is solvable, therefore a maximal solvable Lie algebra containing $\mathfrak h$ has to be of this form.
 
 For a parabolic subalgebra $\mathfrak p$ properly containing $\mathfrak b$, if now $P$ denotes the set of roots in the weight decomposition of $\mathfrak p$, if $-\beta\in P$ for some positive root $\beta$, and if $\beta = \alpha_1+\dots+\alpha_n$ is its decomposition as a sum of elements of $\Delta$, we will prove by induction on $n$ that all $-\alpha_i \in P$. We have $(\beta,\beta)>0$, therefore $(-\beta, \alpha_i)<0$ for some $i$, hence $\gamma:=-\beta+\alpha_i \in P$ (or is zero), by the same argument as before. If $\gamma\ne 0$, then $-\gamma \in P$, and again by Lemma \ref{lemma-closed-subset}, $-\alpha_i = -\beta +(-\gamma)\in P$.  By the induction hypothesis, for all elements $\alpha\in \Delta$ in the decomposition of $-\gamma$, $-\alpha\in P$, and the claim is proven.
 
 Vice versa, if $I= \Delta \cap (-P)$, and $\beta\in \Phi^+$ is in the linear span of $I$, then $\beta$ can be written as a sum $\alpha_1+\dots+\alpha_n$ of elements of $I$, and  we will prove by induction on $n$ that $-\beta\in P$. Again, $(-\beta,\alpha_i)<0$ for some $i$, so $-\beta+\alpha_1$, if nonzero, is in $P$, by the induction hypothesis. Since $-\alpha_1\in P$, by Lemma \ref{lemma-closed-subset}, $-\beta\in P$, as well.
\end{proof}




\section{Conjugacy of Borel and Cartan subalgebras}
\label{section-conjugacy-Borel-Cartan}

In this section, $\mathfrak g$ is a finite-dimensional Lie algebra over an algebraically closed field $k$ of characteristic zero.

\begin{definition}
 \label{definition-Eg}
Given a Lie algebra $\mathfrak g$, let $N(\mathfrak g)  = \{ X\in\mathfrak g| \exists Y\in \mathfrak g, a\ne 0 \mbox{ with } [X,Y] = a X\}$, i.e., all elements which belong to a nonzero eigenspace under the adjoint action of some other element. The group {\it $\mathcal E(\mathfrak g)$} is the subgroup of all automorphisms of $\mathfrak g$ generated by the automorphisms $\exp(\text{ad}(X))$, $X\in N(\mathfrak g)$. 
\end{definition}

The following lemma shows that the automorphisms of Definition \ref{definition-Eg} are well-defined:
\begin{lemma}
 \label{Eg-nilpotent}
 The elements of the set $N(\mathfrak g)$ of Definition \ref{definition-Eg} are nilpotent.
\end{lemma}

\begin{proof}
 The relation $[X,Y] = a X$ means that $X$ takes the $\lambda$-generalized eigenspace of $Y$ to the $(\lambda-a)$-generalized eigenspace. Since we are in characteristic zero, all $\lambda-na$, $n\in \mathbb Z$, are distinct, and by finite-dimensionality, the $\lambda-na$-eigenspace has to be zero for large $n$.
\end{proof}


\begin{remark}
 \label{remark-Eg}
In semisimple Lie algebras, it turns out that $\mathcal E(\mathfrak g)$ is the entire group of \emph{inner automorphisms}, i.e., automorphisms generated by nilpotent elements. On the opposite end, if $\mathfrak g$ is nilpotent, then $\mathcal E(\mathfrak g)$ is trivial.
\end{remark}

\begin{theorem}
\label{theorem-conjugacy-Borel-Cartan}
 Let $k$ be algebraically closed, in characteristic zero. Any two Borel subalgebras of $\mathfrak g$ are conjugate under $\mathcal E(\mathfrak g)$, and any two Cartan subalgebras of $\mathfrak g$ are conjugate under $\mathcal E(\mathfrak g)$.
\end{theorem}

\begin{proof}
 Omitted, for now. See \cite{Humphreys-Lie} or \cite{Sternberg}. The analog of this theorem for algebraic groups appears in Section \ref{section-Cartan-Borel-group}.
\end{proof}




\section{Jacobson--Morosov}
\label{section-Jacobson-Morosov}

\section{Ado's theorem}
\label{section-Ado}


\section{Diagonalizable groups}
\label{section-diagonalizable-groups}

We pass to the study of linear algebraic groups, over a general field $k$. The definitions will follow a different order than in the case of Lie algebras, because we want to distinguish between the additive group $\mathbf G_a = \text{Spec} k[T]$ and the multiplicative group $\mathbf G_m = \text{Spec} k[T,T^{-1}]$, whose Lie algebras are the same. It is easy to see that \emph{there are no non-trivial morphisms between these two groups}. 


\begin{definition}
\label{definition-characters-diagonalizable-group} 
The {\it character group} $X^\bullet(G)$ of a linear algebraic group $G$ is the group of morphisms $G\to \mathbf G_m$. 
A linear algebraic group $G$ over an field $k$ is called \emph{diagonalizable} if $\bar k[G]$ is spanned, as a vector space, by the $\bar k$-rational characters: $\bar k[G] = \bar k[X_\bullet(G_{\bar k})]$. A {\it torus} is a connected diagonalizable group. A diagonalizable group $G$ is said to be {\it split} if $X^\bullet(G) = X^\bullet(G_{\bar k})$.
\end{definition}

\begin{theorem}
\label{theorem-diagonalizable-equivalence}
Any character of a diagonalizable group $G$ over the algebraic closure $\bar k$ is defined over the separable closure $k^s$. If $\Gamma$ denotes the Galois group of $k^s$ over $k$, the contravariant functor that assigns to any group its $\bar k$-character group gives rise to a contravariant equivalence of categories:
$$\{\mbox{diagonalizable $k$-groups}\} \leftrightarrow $$
$$\{\mbox{finitely generated abelian groups without $p$-torsion, with a $\Gamma$-action}\},$$
where $p$ is the characteristic exponent of $k$.
Under this equivalence, tori correspond to torsion-free abelian groups.
\end{theorem}

\begin{proof}
 Choose any embedding $G\subset \text{GL}(V)$, for a finite-dimensional vector space $V$. For the first statement, it is enough to show that $G$ can be diagonalized over $k^s$. By functoriality of the Jordan decomposition, the image of $G$ consists of semisimple elements. Therefore, the minimal polynomial of every $g\in G(k)$ has distinct roots, which are therefore defined over $k^s$. Therefore, $G$ can be diagonalized over $k^s$.
 
 The rest of the statements are left to the reader.
\end{proof}

\section{Unipotent, solvable, semisimple, and reductive groups}
\label{section-groups}

A main goal in our discussion of linear algebraic groups will be to recover some of the structure of semisimple Lie algebras that holds in characteristic zero but fails in positive characteristic. The action of the group on its coordinate ring allows us to recover, e.g., the Jordan decomposition. We define notions of semisimplicity etc with respect to this action. We denote by $L$, resp.\ $R$, the left, resp.\ right action of $G$ on $k[G]$; recall that this is a locally finite action, so for every $v\in k[G]$ there is a finite-dimensional stable subspace $V\subset k[G]$ containing $v$, such that $L$ (or $R$) is a morphism of algebraic groups $G\to \text{GL}(V)$.

\begin{definition}
\label{definition-semisimple-unipotent-group}
 Let $G$ be a linear algebraic group over a field $k$. An element $g\in G(k)$ is called \emph{semisimple} if $R(g)$ is semisimple, and unipotent if $R(g)$ is unipotent. 
\end{definition}

\begin{theorem}[Jordan decomposition]
\label{theorem-Jordan-group}
 Let $G$ be a linear algebraic group over a field $k$ in characteristic $p\ge 0$. 
 
 Every element $g\in G(k)$ admits a unique decomposition $g = g_s g_u$ in $G(k^{p^{-\infty}})$, with $g_s$ semisimple and $g_u$ unipotent, commuting with each other.
 
 Moreover, every element $X\in \mathfrak g(k)$ admits a unique decomposition $X = X_s + X_n$ in $\mathfrak g(k^{p^{-\infty}})$, with $R(X_s)$ semisimple and $R(X_n)$ nilpotent, commuting with each other.
 
 If $G\to G'$ is a morphism of linear algebraic groups, the Jordan decompositions of elements in the group or the Lie algebra are preserved.
\end{theorem}

Notice, in particular, that for $\mathfrak g$ semisimple in characteristic zero, the Jordan decomposition in $\mathfrak g$ is the same as the one defined by the adjoint representation in Theorem \ref{theorem-Jordan-Chevalley}.

\begin{proof}
 Assume first that $k$ is algebraically closed. The right action being locally finite, hence a sum of finite-dimensional representations $G\to \text{GL}(V)$, we can apply the Jordan decomposition for $\text{GL}(V)$, to conclude that $R(g) = R(g)_s R(g)_u$ for unique semisimple, resp.\ unipotent $R(g)_s$, $R(g)_u$ which are \emph{polynomials in $R(g)$} (in $\text{End}(V)$). The image of $G$ in $\text{GL}(V)$ is closed [General fact about morphisms of algebraic groups, to be added]. If $B\subset k[\text{GL}(V)]$ is the ideal defining its image, it is stable under the right action of $G$, hence of $R(g)_s$ and $R(g)_u$ (since they are polynomial in $R(g)$). But the subgroup of elements in $\text{GL}(V)(k)$ stabilizing this ideal is equal to $G(k)$, since any other right coset of $G$ is a different closed subvariety of $\text{GL}(V)$. Thus, $R(g)_s$ and $R(g)_u$ are the images of unique elements $g_s$, $g_u$ of $G(k)$.
 
 If $k$ is not algebraically closed, by uniqueness of the Jordan decomposition these elements are fixed under the Galois group, and therefore defined over the maximal inseparable extension $k^{-p^\infty}$.   
 
 The statements on Lie algebras follow similarly. 
\end{proof}


\begin{definition}
 \label{definition-solvable-unipotent}
The {\it derived series} of an algebraic group $G$ is the series of normal subgroups 
$$ \mathcal D^0(G) = G$$
$$ \mathcal D^{i+1}(G) = \mathcal D(\mathcal D^iG),$$
where $\mathcal D$ denotes the commutator subgroup. 

An algebraic group $G$ is called \emph{solvable} if $\mathcal D^n G=1$ for some $n$. 

A linar algebraic group $G$ is called \emph{unipotent} if $g = g_u$ in terms of the Jordan decomposition of Theorem \ref{theorem-Jordan-group}, for every $g\in G(\bar k)$.
\end{definition}

\begin{theorem}
\label{theorem-representations-unipotent}
Let $G$ be a unipotent algebraic group over a field $k$. The only (algebraic) irreducible representation of $G$ is the trivial one. For any representation $\rho:G \to \text{GL}(V)$, there is a full flag in $V$ with respect to which $V$ is upper triangular. Any unipotent group is solvable.
\end{theorem}

This is the group analog of Engel's theorem \ref{theorem-Engel}.

\begin{proof}
Let $V^G$ be the subspace of $G$-fixed vectors: By definition, this is the maximal $G$-stable subspace of $V$ with the property that the action morphism $G\times V\to V$ coincides with the projection to $V$. It is clearly defined over $k$, so if we show that $V^G(\bar k) \ne 0$ then $V^G\ne 0$. But $V^G(\bar k)$ is easily seen to be equal to $V(\bar k)^{G(\bar k)}$, so it is enough to assume that $k$ is algebraically closed. 

By the functoriality of the Jordan decomposition, $\rho(g)$ is unipotent, for every representation $\rho$ and any $g\in G(k)$. If the representation is irreducible and $k = \bar k$, by Burnside's irreducibility criterion, $\text{End}_k(V)$ is generated as an algebra by $\rho(G(k))$. Since $\rho(g)$ is unipotent, we have $\rho(g) = 1+x$ for some nilpotent endomorphism $x$. For every $g'\in G(k)$ we have 
$$ \text{tr}(x\rho(g')) =\text{tr}((\rho(g)-1)\rho(g'))= \text{tr}(\rho(gg'))-\text{tr}(\rho(g')) = \dim(V)-\dim(V)=0,$$
since both $\rho(gg')$ and $\rho(g')$ are unipotent. But the trace pairing is nondegenerate on $\text{End}_k(V)$, hence $x=0$, and the representation is trivial.

By induction on the dimension, for any representation $(\rho,V)$ of $G$ there is a filtration $F^i V$ such that $G$ acts trivially on $\text{gr}^i(V)$, i.e., there is a flag with respect to which $\rho(G)$ is upper triangular.

If we consider any faithful representation $G\to \text{End}(\mathfrak g)$, the image is upper triangular, hence solvable.
\end{proof}

\begin{definition}
\label{definition-split-solvable}
 A solvable algebraic group over a field $k$ is said to be {\it split} if it has a filtration over $k$ whose graded pieces are isomorphic to $\mathbf G_m$ or $\mathbf G_a$.
\end{definition}

\begin{lemma}
\label{lemma-connected-solvable-split}
 If $k$ is algebraically closed, every connected solvable group is split.
\end{lemma}

\begin{proof}
 Omitted.
\end{proof}

\begin{proposition}
 \label{proposition-Levi-solvable}
If $G$ is a split solvable linear algebraic group over a field $k$, all maximal tori in $G$ are $G(k)$-conjugate. If $T$ is a maximal torus, then $G$ is the semidirect product $G=T\mathcal U(G)$, and any semisimple element in $G$ is conjugate to an element of $T$. 
\end{proposition}

\begin{proof}
 This is a delicate argument using induction on the dimension of $G$, see \cite[Theorem 10.6]{Borel-LAG}. 
\end{proof}





The analog of Lie's theorem \ref{theorem-Lie} is 
\begin{theorem}[Borel's fixed point theorem]
\label{theorem-Borel-fixed-point}
 If $G$ is a split, solvable, connected algebraic group over field $k$, acting on a proper $k$-scheme $X$ with $X(k)\ne \emptyset$, then $X(k)^G\ne \emptyset$. 
\end{theorem}

The reason that this is the analog of Lie's theorem is that, if $G$ acts on a vector space $V$, and $X$ is the flag variety classifying full flags in $G$, then the fixed point corresponds to a flag fixed by $G$. Notice that, unlike the Lie algebra version, there is not requirement of characteristic zero here.

\begin{proof}
 By induction on the dimension $d$ of $G$, the case $d=0$ being trivial. Let $G'\subset G$ be normal of codimension one with $G/G'\simeq \mathbf G_m$ or $\mathbf G_a$, then, by induction, the fixed-point subvariety $X^{G'}$ has a nonempty set of $k$-points, so we may replace $X$ by $X^{G'}$ and $G$ by $G/G'$, reducing us to the case where $G=\mathbf G_m$ or $\mathbf G_a$. Choose $x\in X(k)$, obtaining an orbit map $G\ni g\mapsto gx\in X$.  Then, thinking of $G$ as embedded inside of $\mathbf P^1$, by the valuative criterion for properness the map extends to a map $\varphi:\mathbf P^1\to X$. This extension is $G$-equivariant, because $X$ is proper, hence separated, hence ``limits are unique'', i.e., writing $\lim \gamma$ for specialization of the extension to the spectrum of a valuation ring $\mathfrak o$ of a map $\gamma$ from the spectrum of its quotient field $K$, if $\gamma: \text{Spec K} \to G$ then $\varphi(\lim \gamma) = \lim (\varphi \circ \gamma)$. Therefore, for every $g\in G$ we have $g\cdot \varphi(\lim \gamma) = g\cdot \lim (\varphi\circ\gamma) = \lim( g\cdot \varphi\circ\gamma) = \lim(\varphi(g\cdot \gamma))$ (because $\varphi$ is equivariant on $G$) $= \varphi(\lim (g\cdot\gamma))$. 
 
 The image of $\infty\in \mathbf P^1$ will be the desired $G$-fixed point on $X(k)$.
\end{proof}




\begin{definition}
\label{definition-reductive}
The {\it radical} $\mathcal R(G)$ of an algebraic group $G$ is its maximal connected solvable normal subgroup. The {\it unipotent radical} $\mathcal U(G)$ of a linear algebraic group $G$ is its maximal connected unipotent normal subgroup. A group is {\it reductive} if its unipotent radical over the algebraic closure, $\mathcal U(G_{\bar k})$, is trivial, and {\it semisimple} if $\mathcal R(G)=1$.
\end{definition}

\begin{remark}
 \label{remark-unipotent-radical}
If $k$ is perfect, then $\mathcal U(G_{\bar k}) = \mathcal U(G)_{\bar k}$. However, for non-perfect fields, the absolute unipotent radical could be larger; for example, consider a purely inseparable extension $k'/k$, and let $G = \text{Res}_{k'/k}\text{GL}_1$. Its $k$-unipotent radical is trivial, but its $k'$-unipotent radical is not. [Exercise!]
\end{remark}



\section{One-parameter subgroups and the associated parabolics}
\label{section-one-parameter}

Let $\lambda:\mathbf{G}_m \to G$ be a cocharacter --- also called a ``one-parameter subgroup''. We let it $\mathbf G_m$ act on $G$ by conjugation via this character: $^{\lambda(a)}g:= \lambda(a) g \lambda(a)^{-1}$.

We let 
$$P(\lambda)=\{g\in G| \lim_{t\to 0} {^{\lambda(t)}g} \mbox{ exists}\},$$  
$$U(\lambda)=\{g\in G| \lim_{t\to 0} {^{\lambda(t)}g} =1\},$$
$$L(\lambda)= G^{\lambda(\mathbf G_m)},\mbox{ the centralizer of }\lambda.$$

A priori, these groups could be non-reduced, but the following proposition states that this is not the case:

\begin{proposition}
 \label{proposition-cocharacters-parabolics}
The groups $P(\lambda)$, $U(\lambda)$, $L(\lambda)$ are smooth, connected if $G$ is, and $P(\lambda)=L(\lambda)U(\lambda)$ is a semidirect product decomposition of $P(\lambda)$. The multiplication map 
$$ U(\lambda^{-1})\times P(\lambda)\to G$$
is an open immersion (embedding).
\end{proposition}

\begin{proof}
 For the proof, including a careful discussion of the definitions of these groups, see \S 24, 25 of the course notes of \cite{Conrad-AG1}.
\end{proof}


\begin{definition}
 \label{definition-Levi-decomposition}
The decomposition $P(\lambda)=L(\lambda)U(\lambda)$ of Proposition \ref{proposition-cocharacters-parabolics} is called a \emph{Levi decomposition} of the parabolic $P(\lambda)$. 
\end{definition}

\begin{remark}
 \label{remark-general-Levi}
 More generally, a Levi decomposition of a connected linear group $G$ is a semidirect decomposition $G=L\cdot \mathcal U(G)$, where $\mathcal U(G)$ is the unipotent radical of $G$. Levi decompositions always exist in characteristic zero, but not in positive characteristic.
\end{remark}




This implies:

\begin{proposition}
\label{proposition-centralizers-tori-connected}
 If $G$ is a connected linear algebraic group, the centralizer of any torus is connected. 
\end{proposition}

\begin{proof}
 We may assume that $k=\bar k$. If $T=T_1T_2$, where the $T_i$'s are tori of smaller dimension, then the centralizer of $T$ in $G$ is equal to the centralizer of $T_1$ inside of the centralizer of $T_2$. This way, the problem reduces to $\text{dim}(T)=1$. Let $\lambda:\mathbf G_m\to G$ be a nontrivial cocharacter, whose image is $T$. Then the claim follows from Proposition \ref{proposition-cocharacters-parabolics}.
\end{proof}






\section{Density of points; Borel and Cartan subgroups}
\label{section-Cartan-Borel-group}

For the definitions that follow, there are slight variants in the literature, e.g., allowing Cartan subgroups to be disconnected when the group is disconnected. To avoid confusion, establish an easy-to-remember principle, and stay close to the theory of Lie algebras, we are imposing connectedness in our definitions.


\begin{definition}
\label{definition-Cartan-Borel-subgroup}
A {\it Borel subgroup} of a linear algebraic group over an algebraically closed field is a maximal connected solvable subgroup. A {\it Cartan subgroup} is the identity component of the centralizer of a maximal torus. 
\end{definition}

\begin{remark}
 \label{remark-Cartan-connected}
If $G$ is connected then, by Proposition \ref{proposition-centralizers-tori-connected}, the centralizer of any torus is connected, so the word ``connected'' in the definition of Cartan subgroups is superfluous.
\end{remark}



\begin{theorem}
\label{theorem-Borel-subgroups-conjugate}
A connected solvable subgroup is Borel (i.e., maximal) if and only if the quotient $G/B$ is projective. All Borel subgroups are conjugate over the algebraic closure.
\end{theorem}

We will eventually see that all Borel subgroups defined over the base field $k$ (if there are any) are conjugate under $G(k)$.

\begin{proof}
 

 We first prove that if $B$ is of maximal dimension among connected solvable subgroups, then $G/B$ is projective. We may and will assume that the field of definition $k$ is algebraically closed. By Theorem \ref{liegroups-general-theorem-quotients}, there is a linear representation $V$ of $G$ such that $B$ is the stabilizer of a line $L$. Applying the Borel fixed point theorem \ref{theorem-Borel-fixed-point} on the flag variety of $V/L$, $B$ stabilizes a full flag $f$ in $V$ whose first element is $L$; hence it is the stabilizer of that flag in $G$. Any other stabilizer of a flag in $V$ is also solvable, and by the maximality of $\text{dim}(B)$, the dimension of $G/B = G\cdot f$ is minimal among the dimensions of $G$-orbits on the flag variety of $V$. Hence, $G\cdot f = G/B$ is closed in the flag variety, hence projective. 
 
 Given that $G/B$ is projective, if $P$ is any other solvable connected subgroup of $G$, again by Borel's fixed point theorem it fixes a point on $G/B$, i.e., $P\subset B'$ for some conjugate $B'$ of $B$. Thus, if $P$ is maximal, it is also of maximal dimension, and $G/P$ is projective, as already proven. 
 
 
 Vice versa, if $G/P$ is projective, and choosing a maximal solvable connected $B$, Borel's fixed point theorem implies that $B$ fixes a point on $G/P$, hence $P\supset B'$ for a conjugate $B'$ of $B$. If $P$ is solvable and connected, by the maximality of $B$, $P=B'$.
 
 The above show that any two Borel subgroups are conjugate over an algebraically closed field. 
\end{proof}

\begin{proposition}
\label{proposition-unipotent-torus}
If $G$ is a connected linear algebraic group that is not unipotent, over an algebraically closed field $k$, then $G$ contains a nontrivial torus. Any Cartan subgroup $C$ of $G$ is a direct product $T\times U$, with $T$ a torus and $U$ unipotent, and is equal to the identity component of its normalizer. Its Lie algebra is a Cartan subalgebra of $\mathfrak g$.
\end{proposition}

We will see in Theorem \ref{theorem-maximal-tori-exist} that, even if the field is not algebraically closed, tori exist over $k$.

\begin{proof}
 Assume $k=\bar k$, and let $B$ be a Borel subgroup; then, by Proposition \ref{proposition-Levi-solvable}, it has a Levi decomposition as a semidirect product  $B=T N$, with $T$ a maximal torus and $N$ its unipotent radical. Assume that $T$ is trivial. If $G\to \text{GL}(V)$ is a representation where $N$ stabilizes a line $L$, because there are no nontrivial homomorphisms $N\to\mathbf{G}_m$, $N$ stabilizes every point on the line, and we get an embedding $G/N\hookrightarrow V$. Since $G/N$ is projective, by Theorem \ref{theorem-Borel-subgroups-conjugate}, and $V$ is affine, $G/N$ must be a point, i.e., $G$ is unipotent.
 
 For the second claim, if $C$ is the connected centralizer of $T$, $C/T$ cannot contain nontrivial tori (this would contradict the maximality of $T$), and therefore is unipotent. By the Levi decomposition of Proposition \ref{proposition-Levi-solvable}, $C=TU$ is a semidirect product of $T$ with the unipotent radical, but $T$ is in the center, so the product is direct. If $N$ is the connected normalizer of $C$, then $T$ is normal in $N$, hence $N/T$ acts on $T$ by automorphisms; but the automorphism group of $T$ is discrete, and $N$ is connected, so $N$ centralizes $T$, hence is equal to $C$. The same argument proves that its Lie algebra is self-normalizing, hence (since it is nilpotent) a Cartan subalgebra.
\end{proof}



We prove a result on the existence of regular semisimple elements:

\begin{lemma}
 \label{lemma-regular-semisimple-exist}
Assume that $\mathfrak g$ is the Lie algebra of an algebraic group over an infinite field $k$. Then, $\mathfrak g(k)$ contains regular semisimple elements. 
\end{lemma}

\begin{proof}
 Since $k$ is infinite, $\mathfrak g(k)$ is Zariski dense, hence meets the Zariski open subset of $s$-regular elements (Lemma \ref{lemma-sregular-exist}) nontrivially. If $X=X_s+X_n$ is the Jordan decomposition (Theorem \ref{theorem-Jordan-group}) of an $s$-regular element, then, if $k$ is perfect, $X_s$ and $X_n$ are defined over $k$, in which case $X_s$ is the regular semisimple element we seek. Otherwise, $\text{char}(k)=p>0$, in which case $\mathfrak g$ has the structure of a restricted Lie algebra (Definition \ref{liegroups-general-definition-restricted-Lie-algebra} and Example \ref{liegroups-general-example-restricted-Lie-algebra}), and then for some $r>0$ we have $X_n^{[p]^r}=0$, and $X^{[p]^r}=X_s^{[p]^r}$ is the regular semisimple element that we seek.
\end{proof}


\begin{theorem}
\label{theorem-Cartan-tori-conjugate}
If $G$ is a linear algebraic group over an algebraically closed field $k$, all maximal tori of $G$, and all Cartan subgroups, are $G(k)$-conjugate.
\end{theorem}


\begin{proof}
We first show that Cartan subgroups are centralizers of regular semisimple elements: Let $T$ be a maximal torus, and $C$ its connected centralizer, a Cartan subgroup. It is smooth, by Proposition \ref{proposition-cocharacters-parabolics}. Since $T$ consists of semisimple elements, the adjoint action of $T$ on $\mathfrak g$ decomposes into a direct sum of eigenspaces (whose nontrivial eigencharacters are called \emph{roots}), and $\text{Lie}(C)$ is the zero-eigenspace. Since $k$ is infinite, there is an element $s\in T(k)$ with $\alpha(s)\ne 1$ for all roots $\alpha$. 

By Proposition \ref{proposition-Levi-solvable}, any semisimple element $s'\in G(k)$ is conjugate to an element of $T(k)$. Thus, all Cartan subgroups are conjugate. 

This reduces the statement on tori to the case $C=G$, i.e., the case where $T$ is central in $G$. But then, $T$ is the \emph{unique} maximal torus in $G$, for any nontrivial torus $T'$ not contained in $T$ would lead to a larger torus $TT'$, contradicting the maximality of $T$.
\end{proof}





\begin{theorem}
\label{theorem-maximal-tori-exist}
If $G$ is a connected linear algebraic group over a field $k$, then maximal $k$-tori $T\subset G$ remain maximal after passing to the algebraic closure. In particular, there exist maximal $k$-tori of $G_{\bar k}$ that are defined over $k$.
\end{theorem}

\begin{proof}
 [Omitted, for now]
\end{proof}




\begin{proposition}
\label{proposition-Cartan-reductive}
If $G$ is reductive, the centralizer of any torus is reductive, and Cartan subgroups are the maximal tori. 
\end{proposition}

\begin{proof}
See \cite[\S 13.17, Corollary 2]{Borel-LAG} or the handout ``Basics of reductivity and semisimplicity'' in \cite{Conrad-AG2}. The second claim follows from the first, given that Cartan subgroups are of the form $T\times U$.
\end{proof}


\section{The (universal) Cartan, and the scheme of Borel subgroups}
\label{section-universal-Cartan}



An important feature of Borel subgroups is that they are self-normalizing. At the level of Lie algebras, this was an easy corollary of the definition, see Lemma \ref{lemma-BSA-self-normalizing}. At the level of algebraic groups, one needs to be more careful, because the normalizer is a group scheme, not guaranteed to be smooth (in positive characteristic). [Definitions of normalizers, centralizers, etc.\ are the natural ones, and left to the reader, for now.]


\begin{theorem}
 \label{theorem-Borel-self-normalizing}
Let $B$ be a Borel subgroup of a reductive group $G$ over a field $k$. The normalizer subgroup scheme $\mathcal N_G(B)$ is equal to $B$. 
\end{theorem}

\begin{proof}
 We have an embedding $B\hookrightarrow \mathcal N_G(B)$, so we need to show that it is an isomorphism. For that, it is enough to assume that $k$ is algebraically closed. 
 
 First, we show that $B(k) = N_G(B)(k)$ (which is equal to $N_{G(k)}(B(k))$). 
 Choose a maximal torus $T\subset B$. Since all maximal tori inside of $B$ are conjugate (Proposition \ref{proposition-Levi-solvable}), if $g\in G(k)$ normalizes $B$, then $gTg^{-1}=bTb^{-1}$ for some $b\in B$, hence, replacing $g$ by $b^{-1}g$, we may assume that $g$ normalizes $T$.
  
The commutator map $t\mapsto g t g^{-1} t^{-1}$ is a homomorphism $T\to T$. There are two cases:
\begin{enumerate}
 \item The kernel of this map, i.e., the fixed-point set $S=T^g$, is finite. Then, for dimension reasons, the commutator map is surjective. In particular, if $B'$ is the group generated by $B$ and $g$, any character $B'\to \mathbf G_m$ is trivial on $B$ (because $B=TU$, where $U$ is its unipotent radical, and characters are trivial on unipotent groups and commutators). By \ref{liegroups-general-theorem-quotients}, there is a representation $G\to \text{GL}(V)$ where $B'$ is the stabilizer of a line, acting it via a character $B'\to \mathbf G_m$. Since that character is trivial on $B$, we obtain a map $G/B\to V$, which has to be constant because $G/B$ is projective (Theorem \ref{theorem-Borel-subgroups-conjugate}). Therefore, $G\subset B'$, which means that $g\in G = B$. 
 
 \item The fixed-point set $S=T^g$ is infinite. Then we can replace $G$ by a group of smaller dimension, which is either $G/S^\circ$ (if $S^\circ$ is central) or the centralizer of $S^\circ$ (if $S^\circ$ is not central), which is connected by Proposition \ref{proposition-centralizers-tori-connected}. By an inductive argument, the proof is complete.
\end{enumerate}

 We have proved that $B(k) = N_G(B)(k)$, \emph{without using the assumption of reductivity}. To finish the proof, we need to show that $N_G(B)$ is reduced. [Omitted for now, as it requires a lot of material that has not been written.]
\end{proof}




Now we show that, for a reductive group $G$ over a field $k$, there is a smooth variety over $k$ which parametrizes the set of Borel subgroups (whether there are any, or not). The result is established over more general bases in \cite[XXII, Corollaire 5.8.3]{SGA3}, cf.\ \cite[Corollary 5.2.9]{Conrad-RGS}. 

\begin{theorem}
 \label{theorem-variety-of-Borels}
Let $G$ be a connected reductive group over a field $k$. The functor that assigns to any scheme $S/k$ the set of Borel subgroups of $G_S$ is representable by a smooth projective variety $\mathcal B$ over $k$. It comes equipped with a canonical line bundle $L$, described as follows: If $\mathbf B\to \mathcal B$ is the universal Borel subgroup, i.e., the subgroup scheme of $G\times \mathcal B$ whose pullback over any $S$-point $S\to \mathcal B$ is the parametrized Borel subgroup of $G_S$, then $L=\det(\text{Lie}(\mathbf B))^*$.
\end{theorem}

By definition, a Borel subgroup of $G_S$ is a smooth affine subgroup scheme over $S$ whose geometric fibers are Borel subgroups. 

\begin{proof}[Sketch of proof]
 The proof requires extension to an arbitrary basis of two results that we have already proven over a field $k$: Assuming the existence of a split maximal torus $T$, Borel subgroups containing $T$ are in bijection with bases for the root system of $T$ in $G$ (Proposition \ref{dummy}), and Borel subgroups are self-normalizing (Theorem \ref{theorem-Borel-self-normalizing}). [Omitted for now.]
 
 Let $T$ be a maximal torus in $G$. By Theorem \ref{theorem-maximal-tori-exist}, it remains maximal over the algebraic closure, and by  Theorem \ref{theorem-diagonalizable-equivalence}, it splits over the separable closure $k^s$. By Proposition \ref{dummy}, there is a Borel subgroup $B$ over $k^s$ which contains $T_{k^s}$. By the conjugacy of Borel subgroups (Theorem \ref{theorem-Borel-subgroups-conjugate}), and their self-normalizing property (Theorem \ref{theorem-Borel-self-normalizing}), the quotient $\mathcal B^s:=G_{k^s}/B$ represents the functor of Borel subgroups over $k^s$. 
 
 We need to show that this scheme descends to $k$, which is where the ample line bundle will come into play. We first prove that the stated line bundle is ample: If $d$ is the dimension of a Borel subgroup, consider the map 
 $$ \mathcal B^s \to \text{Gr}(\mathfrak g_{k^s}, d)$$
 sending a Borel subgroup to its Lie algebra in the Grassmannian of $d$-dimensional subspaces of $\mathfrak g_{k^s}$. Then $L$ is the pullback of the dual of the determinant line bundle on $\text{Gr}(\mathfrak g_{k^s}, d)$, which is ample. Therefore, $L$ is ample.
 
 Finally, for the descent, we have an embedding $\mathcal B^s\to \mathbb P V^s$, where $V^s = H^0(\mathcal B^s, L^n)^*$ for some $n\gg 0$, and compatible semilinear actions of the Galois group $\Gamma$ of $k^s/k$ on $\mathcal B^s$ and on the $k^s$-vector space $V^s$. Therefore, $V^s = V \otimes_k k^s$, where $V = (V^s)^\Gamma$, and $\mathcal B^s$ is the base change of a closed subvariety $\mathcal B \subset \mathbb P V$.
\end{proof}


Now we pass to an important construction, which assigns, canonically, a torus $\mathbb A^G$ to every reductive group $G$. 

\begin{proposition}
 \label{proposition-universal-Cartan}
Let $G$ be a connected reductive group over a field $k$, $\mathbf B\to \mathcal B$ be the universal Borel over the variety of Borel subgroups (Theorem \ref{theorem-variety-of-Borels}), and $\mathbf A\to \mathcal B$ the variety of their reductive quotients (i.e., the fiber of $\mathbf A$ is the fiber of $\mathbf B$ divided by its unipotent radical --- hence, a torus). 

There is a torus $\mathbb A^G$ over $k$ such that $\mathbf A = \mathbb A^G\times \mathcal B $.
\end{proposition}

Notice that, given such a torus $\mathbb A^G$, it is unique up to unique isomorphism. Indeed, since $\mathbf B$ is projective and tori are affine, any isomorphism $\mathbb A_1^G \times \mathcal B \simeq \mathbb A_2^G \times \mathcal B$ over $\mathcal B$ arises from a unique isomorphism $\mathbb A_1^G \simeq \mathbb A_2^G$.

\begin{proof}
Is is enough to prove the proposition over the separable closure $k^s$. Indeed, if $\mathbf A_{k^s} = \mathbb A^s\times \mathcal B_{k^s} $ over $k^s$, where $\mathbb A^s$ is some torus over $k^s$, then the $k^s$-semilinear action of the Galois group $\Gamma$ on $\mathbf A_{k^s}$ is induced, necessarily, from its action on $\mathcal B_{k^s} $  and a $k^s$-semilinear action on $\mathbb A^s$ which, by the equivalence of categories between tori and abelian groups (Theorem \ref{theorem-diagonalizable-equivalence}), descends to a form $\mathbb A = \mathbb A^G$ over $k$.

Hence, assume that $k=k^s$. Let $B^s_1, B^s_2$ be two Borel subgroups, and $A_1^s, A_2^s$ their reductive quotients. There is a canonical isomorphism $A_1^s=A_2^s$, induced by the action of any $g\in G(k)$ with $g B^s_1 g^{-1} = B^s_2$. Indeed, such a $g$ exists since all Borel subgroups are conjugate (Theorem \ref{theorem-Borel-subgroups-conjugate}), and it is unique up to right multiplication by $B^s_1$, since Borel subgroups are self-normalizing (Theorem \ref{theorem-Borel-self-normalizing}). But conjugation by an element of $B^s_1$ is the identity on the reductive quotient $A^s_1$ (which is connected), hence all such elements $g$ induce the same isomorphism $A_1^s=A_2^s$. We can therefore set $\mathbb A^G = A_1^s$, and through these isomorphisms we get the isomorphism $\mathbf A = \mathbb A^G\times \mathcal B $ asserted in the proposition.
\end{proof}

Now let $\mathbb A^G$ be the torus of Proposition \ref{proposition-universal-Cartan}. It comes with a canonical quotient map $B\to \mathbb A^G$ for \emph{any} Borel subgroup of $G$.

\begin{lemma}
\label{lemma-Cartan-roots}
 Let $G$ be a connected reductive group over a field $k$, and $B$ a Borel subgroup. Let $T\subset B$ be any maximal torus in $B$. The composition $T\to B\to \mathbb A^G$ is an isomorphism of tori over $k$, inducing a $\Gamma$-equivariant isomorphism of their absolute character groups $X^*(T_{\bar k})\simeq X^*(\mathbb A^G_{\bar k})$. If we use this isomorphism to transfer the subsets $\Phi^+\subset \Phi$ of $B$-positive roots, resp.\ roots, of $T$ to $\mathbb A^G$, the resulting subsets $\Phi^+\subset \Phi\subset X^*(\mathbb A^G_{\bar k})$ do not depend on the choices of $B$ or $T$.
\end{lemma}

\begin{proof}
 Easy, and left to the reader.
\end{proof}




\begin{definition}
 \label{definition-universal-Cartan}
Given a connected reductive group $G$ over a field $k$, the torus $\mathbb A^G$ of Proposition \ref{proposition-universal-Cartan} is called the {\it universal Cartan group}, or {\it abstract Cartan group}, or simply {\it the Cartan group}\footnote{But not \emph{subgroup!}} of $G$. The sets $\Phi^+\subset \Phi$ of Lemma \ref{lemma-Cartan-roots} are the {\it abstract (positive) roots} of $G$. 
\end{definition}






%***************************************************************************




\input{chapters}


\bibliography{my}
\bibliographystyle{amsalpha}

\end{document}


We first discuss the existence of a torus that remains maximal over the algebraic closure. We follow \cite[Theorem 18.2]{Borel-LAG}, presenting the arguments only for the least degenerate cases.
 
 The existence of a maximal torus can be shown inductively on the dimension of $G$, by considering centralizers, under the adjoint representation, of semisimple elements in the Lie algebra $\mathfrak g$, but there are some complications that can appear in positive characteristic, that we will deal with in the end. Assume the theorem to be proven for all dimensions smaller than the dimension of $G$ (the case $\text{dim}(G)=0$ being trivial).
 
 Assume at first that $k$ is infinite, and the Lie algebra $\mathfrak g$ is not nilpotent.
  Recall from Lemma \ref{lemma-regular-semisimple-exist} that $\mathfrak g(k)$ contains a regular semisimple element $Y$. The centralizer $G_Y$ of $Y$ in $G$ is reduced (exercise, or see the proof of this theorem in \cite[Theorem 18.2]{Borel-LAG}), and of smaller dimension than $G$, since $\mathfrak g$ is not nilpotent. We claim that $G_{Y,\bar k}$ contains a maximal torus of $G_{\bar k}$. It is enough to show that $Y$ is contained in the Lie algebra of some torus $T'\subset G_{Y,\bar k}$, because then $T'$ is contained in a maximal torus, which centralizes $Y$. If $T'$ is a maximal torus in $G_{Y,\bar k}$, its centralizer $C$ is a Cartan subgroup, whose Lie algebra $\mathfrak c$ is the centralizer of $\mathfrak t'$, hence $Y\in \mathfrak c$. But $C^\circ=T'\times N'$ for some unipotent group $N'$ by Proposition \ref{proposition-unipotent-torus}, and since $Y$ is semisimple, it has to lie in the Lie algebra of $T'$. Thus, by induction, there is a maximal torus $T\subset G_Y$ which remains maximal over the algebraic closure, and such a torus is maximal in $G_{\bar k}$, by the conjugacy of maximal tori, Theorem \ref{theorem-Cartan-tori-conjugate}.
 

 Now let us assume that $k$ is infinite, but the Lie algebra $\mathfrak g$ is nilpotent. [WRONG:] If $k$ is perfect, then that means that $G$ is unipotent, and contains no tori, so there is nothing to prove. Otherwise, see \cite[17.8 and 18.2]{Borel-LAG}.
 
 Finally, assume that $k$ is finite, with $q$ elements. The relative Frobenius $F_q:G\ni g \mapsto g^{(q)} \to G$ is the morphism over $\text{Spec}(k)$ which, when $G$ is realized as a subscheme of affine space, corresponds to raising the coordinates to the $q$-th power; precisely, when $G=\text{Spec}(R)$, with $R$ a $k$-algebra, $F_q$ is induced by raising elements of $r$ to the $q$-th power. 
 
 By the conjugacy of all maximal tori under the algebraic closure, for any maximal torus $T\subset G_{\bar k}$ there is an element $g\in G(\bar k)$ such that $g T^{(q)} g^{-1} = T$. By Lang's theorem, $g=a^{-1} a^{(q)}$ for some element $a$, and then the torus $T' = aTa^{-1}$ is stable under the Frobenius morphism, hence defined over $k$.
 
 This proves the existence of a maximal torus over $k$. To prove that any maximal $k$-torus of $G$ remains maximal over $\bar k$, we proceed by induction on the dimension of $G$. Given any $k$-torus $S\subset G$, now, its centralizer is connected by Proposition \ref{proposition-centralizers-tori-connected}, and therefore either $S$ is central, or we are done by induction, replacing $G$ by the centralizer. On the other hand, if $S$ is central, proceed by induction on 
