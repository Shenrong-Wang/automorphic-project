\input{preamble}

% OK, start here.
%
\begin{document}

\title{Structure of finite-dimensional Lie algebras}


\maketitle

\phantomsection
\label{section-phantom}

\tableofcontents

Good references for the structure of Lie algebras include Humphreys' book \cite{Humphreys-Lie}, Kirillov's book \cite{Kirillov-Lie}, and Sternberg's notes \cite{Sternberg}.

\section{Nilpotency, solvability, semisimplicity}
\label{section-nilpotent-solvable}


In this chapter, all Lie algebras are taken to be \emph{finite-dimensional} over a field $k$.

\subsection{Definitions}
\label{subsection-definitions-nilpotent-solvable}

\begin{definition}
 \label{definition-ideal}
An {\it ideal} of a Lie algebra $\mathfrak g$ is an $\text{ad}(\mathfrak g)$-stable subspace (automatically a Lie subalgebra) of $\mathfrak g$.

The {\it quotient} of a Lie algebra $\mathfrak g$ by an ideal $\mathfrak h$ is the vector space $\mathfrak g/\mathfrak h$, equipped with the Lie algebra structure descending from $\mathfrak g$.
\end{definition}



\begin{definition}
 \label{definition-nilpotent-solvable-semisimple}
The {\it lower central series} of a Lie algebra $\mathfrak g$ is the descending sequence of ideals defined by
$$ C^0\mathfrak g = \mathfrak g,$$
$$ C^{i+1}\mathfrak g = [\mathfrak g, C^i\mathfrak g].$$
 
 
A Lie algebra is called {\it nilpotent} if its lower central series terminates, i.e., if $C^n\mathfrak g=0$ for some $n$.


The {\it derived series} of a Lie algebra $\mathfrak g$ is the descending sequence of ideals
$$ D^0\mathfrak g = \mathfrak g,$$
$$ D^{i+1}\mathfrak g = [D^i\mathfrak g, D^i\mathfrak g].$$

A Lie algebra is called {\it solvable} if its derived series terminates, i.e., if $D^n\mathfrak g=0$ for some $n$.

A Lie algebra is {\it semisimple} if it does not have any nonzero solvable ideals, and {\it simple} if it is non-abelian, and has no nonzero proper ideals.
\end{definition}

\begin{example}
 \label{example-nilpotent-solvable}
The Lie algebra of strictly upper triangular $n\times n$ matrices (i.e., with zeroes on the diagonal) is nilpotent. The Lie algebra of upper triangular $n\times n$ matrices is solvable.
\end{example}

\begin{lemma}
 \label{lemma-nilpotent-center}
 The center of a (nontrivial) nilpotent Lie algebra is always nontrivial.
\end{lemma}
\begin{proof}
 The last nontrivial element of its lower central series belongs to the center.
\end{proof}




\begin{lemma}
 \label{lemma-solvable-operations}
A Lie algebra $\mathfrak g$ is nilpotent if and only if there exists a finite decreasing filtration by ideals 
$$ \mathfrak g = \mathfrak g^0 \supset \mathfrak g^1 \dots \supset \mathfrak g^n=0$$
such that $[\mathfrak g, \mathfrak g^i]\subset [\mathfrak g^{i+1}]$.

The sum of two nilpotent ideals in a Lie algebra $\mathfrak g$ is also a nilpotent ideal.
 
Subalgebras, quotient algebras, and extensions of solvable Lie algebras by solvable Lie algebras are solvable.
  
A Lie algebra $\mathfrak g$ is solvable if and only if there exists a finite decreasing filtration by subalgebras
$$ \mathfrak g = \mathfrak g^0 \supset \mathfrak g^1 \supset \dots \supset \mathfrak g^n =0$$
such that $\mathfrak g^{i+1}$ is an ideal in $\mathfrak g^i$, and the quotient algebra $\mathfrak g^i/\mathfrak g^{i+1}$ is abelian.
\end{lemma}

\begin{proof}
 Left to the reader.
\end{proof}



\begin{definition}
 \label{definition-radical}
The {\it radical} of a Lie algebra is its largest solvable ideal.

The {\it nilradical}, or {\it nilpotent radical}, of a Lie algebra is its largest nilpotent ideal.
\end{definition}

The definition of the nilradical and radical makes sense in view of Lemma \ref{lemma-solvable-operations}: For the nilradical, the lemma ensures that the sum of all nilpotent ideals is a nilpotent ideal. For the radical, if $\mathfrak a, \mathfrak b$ are solvable ideals, then $\mathfrak a + \mathfrak b$ is an ideal, and it is isomorphic as a Lie algebra to $(\mathfrak a \oplus \mathfrak b)/(\mathfrak a\cap \mathfrak b)$, which is solvable by Lemma \ref{lemma-solvable-operations}.

Thus, any Lie algebra $\mathfrak g$ admits a canonical filtration
\begin{equation}
 \label{equation-filtration-solvable-semisimple}
0 \to R(\mathfrak g) \to \mathfrak g \to \mathfrak g_{ss} \to 0,
\end{equation}
where $R(\mathfrak g)$ is the radical of $\mathfrak g$, and $\mathfrak g_{ss}$ is semisimple. Indeed, the preimage of any solvable ideal in $\mathfrak g_{ss}$ is a solvable ideal in $\mathfrak g$, and therefore has to equal $R(\mathfrak g)$.


Note that the definition of nilradical given here does not coincide with Bourbaki's, who wants to avoid calling an abelian Lie algebra its own nilradical, but is quite standard in other references.

\begin{example}
 \label{example-radical}
 In $\mathfrak{gl}_{2n}$, let $\mathfrak g$ be the subalgebra of matrices whose lower left $n\times n$-block is zero. The radical of $\mathfrak g$ consists of matrices of the form
 $$ \begin{pmatrix}
     aI & * \\ 0 & bI
    \end{pmatrix}$$
 while its nilpotent radical consists of matrices of the form 
 $$ \begin{pmatrix}
     0 & * \\ 0 & 0
    \end{pmatrix}$$
 (all blocks $n\times n$).  

\end{example}

\subsection{Engel's theorem}
\label{subsection-Engel-theorem}

\begin{theorem}[Engel's theorem]
 \label{theorem-Engel}
If $V$ is a nonzero finite-dimensional vector space, and $\mathfrak g\subset \mathfrak{gl}(V)$ is a Lie subalgebra consisting of nilpotent operators, then there is a nonzero $v\in V$ with $Xv = 0$ for all $X\in \mathfrak g$.
 
A finite-dimensional Lie algebra $\mathfrak g$ is nilpotent if and only if $\text{ad}(X)$ is a nilpotent operator, for every $X\in \mathfrak g$. 
\end{theorem}

\begin{proof}
 
We proceed by induction on the dimension of $\mathfrak g$, the case of dimension $1$ being trivial.
 
In higher dimension, let us consider, besides the given representation $V$, the adjoint representation of $\mathfrak g$ on itself, as well. We claim that $\text{ad}(X) \in \text{End}(\mathfrak g)$ is a nilpotent operator, for every $X$. Indeed, $\text{ad}(X)$ is the restriction to $\mathfrak g$ of the operator on $\text{End}(V)$: 
$$ \text{ad}(X) = L_X - R_X,$$
where $L_X(Y) = XY$ and $R_X(Y) = YX \in \text{End}(V)$. Left and right multiplication commute, and there is, by assumption, an $n$ such that $X^n=0$, so by the binomial formula:
$$\text{ad}(X)^{2n} = (L_X - R_X)^{2n} = \sum_{k=0}^{2n} \binom{2n}{k} L_X^k R_X^{2n-k} = 0.$$

Now, take any nontrivial proper subalgebra $\mathfrak h \subset \mathfrak g$. Since $\mathfrak h$ is $\text{ad}(\mathfrak h)$-stable, we get an action of $\mathfrak h$ on the vector space $\mathfrak g/\mathfrak h$, i.e., a morphism of Lie algebras
 $$ \mathfrak h \to \mathfrak{gl}(\mathfrak g/\mathfrak h).$$
 
Let $\bar{\mathfrak h}$ denote its image. Since $\text{ad}(X)$ is nilpotent for every $X\in \mathfrak h$, the same will hold for $\bar{\mathfrak h}$. By the induction hypothesis, there is a nontrivial subspace of $\mathfrak g/\mathfrak h$ which is killed by $\text{ad}(h)$ or, equivalently, \emph{the normalizer of $\mathfrak h$ in $\mathfrak g$ is strictly larger than $\mathfrak h$}. By successively replacing $\mathfrak h$ by its normalizer, we arrive at a proper Lie subalgebra $\mathfrak h$ whose normalizer is $\mathfrak g$, i.e., $\mathfrak h$ is an ideal in $\mathfrak g$.

By the induction hypothesis, the kernel $V_0$ of $\mathfrak h$ acting on $V$ is nontrivial. But this kernel is acted by the quotient Lie algebra $\mathfrak g/\mathfrak h$, and by the induction hypothesis again, it contains a nonzero vector killed by $\mathfrak g$. 

 


For the second statement, take $V=\mathfrak g$. If $\text{ad}(X)$ is nilpotent for every $X \in \mathfrak g$, the first statement implies that the center $Z(\mathfrak g)$ is nontrivial. Replacing $\mathfrak g$ by $\mathfrak g/Z(\mathfrak g)$, we get a sequence of ideals 
$$ \mathfrak g = \mathfrak g^0 \supset \mathfrak g^1 \dots \supset \mathfrak g^n=0$$
such that $[\mathfrak g, \mathfrak g^i]\subset [\mathfrak g^{i+1}]$. By Lemma \ref{lemma-solvable-operations}, $\mathfrak g$ is nilpotent. The other direction is immediate from the definitions: If $\mathfrak g$ is nilpotent, then there is an $n$ such that $\text{ad}(X)^n = 0$ for every $X\in \mathfrak g$.
 
\end{proof}




\subsection{Lie's theorem}
\label{subsection-Lie-theorem}

\begin{theorem}
\label{theorem-Lie}
 If $V$ is a finite-dimensional vector space over an algebraically closed field $k$ in characteristic zero, any solvable Lie subalgebra $\mathfrak g$ of $\mathfrak{gl}(V)$ has a nonzero eigenvector, and hence a full flag
 $$ 0=V_0 \subset V_1 \subset \dots \subset V_n=V,$$
 where $V_i$ has dimension $i$ and is stable under $\mathfrak g$.
\end{theorem}

\begin{proof}
 As in the proof of Engel's theorem \ref{theorem-Engel}, we argue by induction on the dimension of $\mathfrak g$, with the case $\dim \mathfrak g=0$ being trivial. Let, now, $\mathfrak h\subset \mathfrak g$ be an ideal of codimension one (which exists because $\mathfrak g$ is solvable); by induction, $\mathfrak h$ has a non-trivial eigenspace $V_\lambda$ for some linear functional $\lambda: \mathfrak h \to k$. Clearly, $\lambda$ factors through the abelianization 
 $ \mathfrak h^{\text{ab}} = \mathfrak h/[\mathfrak h,\mathfrak h]$.
 
 Now, we claim that $V_\lambda$ is $\mathfrak g$-stable, i.e., if $x\in \mathfrak g$ and $y\in \mathfrak h$ then $yx v = \lambda(y) xv$ for all $v\in V_\lambda$. We have $yx v = xy v -[x,y]v = \lambda(y) xv - [x,y]v$, so we need to prove that $[x,y]v=0$. Consider the flag $0=W_0\subset W_1\subset \dots$ where $W_i$ is spanned by $v, xv, \dots, x^i v$. It is easy to see that $y$ stabilizes this flag, and acts on $W_i/W_{i-1}$ by $\lambda(y)$. Therefore, if $W\subset V$ denotes the maximal subspace of this flag, and $\dim W=n$, the trace of $y$ acting on $W$ is $n\lambda(y)$. This holds for every element of $\mathfrak h$, hence also for the element $[x,y]$. Since this is a commutator of two operators, we get
 $$ 0 = \text{tr}([x,y]) = n \lambda([x,y]),$$
 and since we are in characteristic zero, $\lambda([x,y]) = 0$. 
 
 Thus, $V_\lambda$ is $\mathfrak g$-stable, and because the field is algebraically closed, we can find an eigenvector of $x \in \mathfrak g - \mathfrak h$ on $V_\lambda$, proving the existence of an eigenvector.
 
 The existence of the flag now follows by induction, starting with $V_0=0$ and considering the representation of $\mathfrak g$ on the quotient spaces $V/V_i$.
\end{proof}


\begin{remark}
 \label{remark-Lie-positive-characteristic}
The assumption on the characteristic is really necessary; for example, the Lie algebra $\mathfrak{sl}_2$ is solvable in characteristic $2$, but its standard representation does not have an eigenspace.
\end{remark}

\subsection{Cartan subalgebras}
\label{subsection-CSA}

\begin{definition}
 \label{definition-CSA}
A {\it Cartan subalgebra} of a Lie algebra is a nilpotent, self-normalizing subalgebra. The {\it rank} of a Lie algebra is the dimension of a Cartan subalgebra.
\end{definition}

We will construct Cartan subalgebras as nilspaces (generalized eigenspaces of zero under the adjoint representation) of \emph{s-regular} elements. Then we will show that they are all conjugate to each other; in particular, the rank is uniquely defined.

\begin{definition}
\label{definition-s-regular}
 An s-regular element $X\in\mathfrak g$ is an element with minimal possible $0$-generalized eigenspace under $\text{ad}$.
\end{definition}

This terminology is not standard: in many books on Lie algebras, the word ``regular'' is used for ``s-regular''. However, the standard use of ``regular'' nowadays, in the case of semisimple Lie algebras, is to refer to elements with minimal \emph{zero eigenspace} (i.e., centralizer), instead of generalized eigenspace. This includes non-semisimple elements, while s-regular, in the case of semisimple Lie algebras in characteristic zero, is equivalent to \emph{regular semisimple}, see Proposition \ref{proposition-CSA-semisimple}.



\begin{lemma}
\label{lemma-sregular-exist}
$s$-regular elements form a nonempty Zariski open subset of $\mathfrak g$. 
\end{lemma}

\begin{proof}
The dimension of the zero generalized eigenspace is the highest power of $t$ which divides the characteristic polynomial of $\text{ad}(X)$, and therefore having a minimal such dimension is a Zariski open condition.
\end{proof}


\begin{proposition}
\label{proposition-CSA-centralizer}
 The generalized nilspace (under the adjoint representation) of a s-regular element is a Cartan subalgebra.
\end{proposition}

\begin{proof}
 Let $X$ be the s-regular element and $\mathfrak h$ its generalized nilspace. We will prove that $\mathfrak h$ is nilpotent; equivalently, by Engel's theorem, that the restriction of $\text{ad}(Y)$ to $\mathfrak h$, for any $Y\in\mathfrak h$, is nilpotent. Let $U\subset\mathfrak h$ be the subset of elements which fail to satisfy this; it is a Zariski open subset (again by considerations of the characteristic polynomial). Let $V\subset\mathfrak h$ be the subset of elements which act invertibly on $\mathfrak g/\mathfrak h$. It is again a Zariski open subset, and non-empty since $X\in V$. If $U\ne\emptyset$ then $U\cap V\ne\emptyset$, i.e.\ there exists an element $Y\in\mathfrak h$ such that the dimension of the zero generalized eigenspace for $Y$ is less than the dimension of $\mathfrak h$, a contradiction by the s-regularity of $X$. Thus, $\mathfrak h$ is nilpotent.

 If $Z$ normalizes $\mathfrak h$ then $[Z,X]\in\mathfrak h$ which implies that $Z$ is in the generalized nilspace of $X$, i.e.\ in $\mathfrak h$.
\end{proof}

Hence, every Lie algebra has Cartan subalgebras. We will eventually prove that any two Cartan subalgebras are conjugate (over the algebraic closure) by the group of inner automorphisms of $\mathfrak g$ and, in particular, equal to nilspaces of s-regular elements.



\subsection{Derivations and semidirect products}
\label{subsection-derivations-semidirect}

\begin{definition}
\label{definition-derivation-Liealgebra}
 A \emph{derivation} of a Lie algebra $\mathfrak g$ is a linear map $D:\mathfrak g\to\mathfrak g$ satisfying $D([X,Y])=[X,D(Y)]+[D(X),Y]$.
\end{definition}

Let 
$$0 \to  \mathfrak a \to \mathfrak g \to \mathfrak h \to 0$$ be a split short exact sequence of Lie algebras, i.e., $\mathfrak h$ embeds in $\mathfrak g$ as a Lie subalgebra. Then, $\mathfrak h$ acts on $\mathfrak a$ by derivations, i.e., through a morphism $\mathfrak h\to \text{Der}(\mathfrak a)$. Vice versa, given such a morphism, it defines a split extension of $\mathfrak h$ by $\mathfrak a$ in Lie algebras. This is the {\it semidirect product} of $\mathfrak a$ and $\mathfrak h$.



\begin{remarks}
\label{remarks-derivations}
 \begin{enumerate}
  \item This is a very natural extension of the definition of derivation for an associative algebra, since such a derivation induces a derivation as above on the associated Lie algebra. Vice versa, a derivation of a Lie algebra induces a derivation of its universal enveloping algebra.
  \item Derivations form a Lie subalgebra of $\text{End}(\mathfrak g)$.
  \item The adjoint representation $\text{ad}:\mathfrak g\to \text{End}(\mathfrak g)$ has image in $\text{Der}(\mathfrak g)$. 
 \end{enumerate}
\end{remarks}

\begin{definition}
 \label{definition-inner-derivation}
 The derivations in the image of the adjoint map $\text{ad}: \mathfrak g\to \text{Der}(\mathfrak g)$ are called {\it inner derivations}.
\end{definition}



\subsection{Jordan decomposition of endomorphisms}
\label{subsection-Jordan-endomorphisms}

In this subsection, we prove that every endomorphism $x$ of a finite-dimensional vector space $V$ has a unique decomposition $x=x_s+x_n$, where $x_s$ is semisimple, $x_n$ is nilpotent, and $x_s, x_n$ commute. We will see later (\ref{subsection-derivations-Jordan}) that such a decomposition also exists, and is unique, for \emph{semisimple} Lie algebras, at least in characteristic zero, when the ``semisimple'' and ``nilpotent'' parts of an element are defined in terms of the adjoint representation.

\begin{proposition}
\label{proposition-Jordan-endomorphisms}
 Let $V$ be a finite-dimensional vector space over $k$, and $x\in \text{End}(V)$. If $k$ is algebraically closed, there is a unique pair of commuting elements $(x_s, x_n)$ with $x_s$ semisimple, $x_n$ nilpotent, and $x=x_s+x_n$. Moreover, $x_s$ and $x_n$ belong to the subalgebra of operators generated by $x$.
 
 For general $k$, the elements $x_s$ and $x_n$ are defined over a purely inseparable algebraic extension of $k$. 
\end{proposition}

\begin{proof}
 First of all, the statement over an algebraically closed field implies the general statement: The uniqueness of $x_s, x_n$ implies that they are fixed under the Galois group of an algebraic closure of $k$, hence defined over a purely inseparable subextension.
 
 Hence, we may assume that $k$ is algebraically closed, so $V$ decomposes as a direct sum of generalized eigenspaces $V_{\lambda_i}$ for $x$. If such a decomposition exists, since the elements $x_s, x_n$ commute with each other, hence with $x$, they must preserve the generalized eigenspaces $V_{\lambda_i}$. Thus, it is enough to prove existence and uniqueness when $V$ itself is a generalized eigenspace, with eigenvalue $\lambda$. But then, we can take $x_s=\lambda I$, and $x_n = x - \lambda_I$. For any other choice $x=x_s'+x_n'$, the nilpotent element $x_n=x-\lambda I$ would have a Jordan decomposition $(x_s'-\lambda_I) + x_n'$, and since commuting nilpotent or semisimple elements have nilpotent, resp.\ semisimple sum, we would get an equality between the semisimple element $x_s'-\lambda I$ and the nilpotent element $x_n-x_n'$, which means that both are zero.
 
 The element $\lambda I$ is (trivially) in the subalgebra generated by any operator, hence both $x_s, x_n$ are in the subalgebra generated by $x$, when $V$ is a generalized eigenspace. In the general case, if the characteristic polynomial of $x$ is $\prod_i (T-\lambda_i)^{m_i}$, by the Chinese remainder theorem there are is a polynomial $p\in k[T]$ with $p\equiv \lambda_i \mod (T-\lambda_i)^{m_i}$, and then $p(x)=x_s$. 
\end{proof}

The following tiny improvement of the proposition above will be useful in what follows:

\begin{lemma}
\label{lemma-Jordan-extension}
In the setting of \ref{proposition-Jordan-endomorphisms}, $x_s$ can be written as a polynomial of $x$ with zero constant coefficient. For any field automorphism $\phi$ of $k$, if $\phi(x_s)$ denotes the semisimple element which acts on the $\lambda$-eigenspace of $x_s$ by $\phi(\lambda)$, then $\phi(x_s)$ can also be written as such a polynomial of $x$. Finally, for any pair of subspaces $W_1\subset W_2\subset V$ with $xW_2\subset W_1$, we also have $yW_2\subset W_1$, where $y$ is any of $x_s, x_n, \phi(x_s)$.
\end{lemma}

\begin{proof}
 In the proof of Proposition \ref{proposition-Jordan-endomorphisms}, we could have taken the polynomial $p$ to satisfy the additional congruence $p = 0 \mod T$, if $0$ is not among the eigenvalues. (If it is, this condition is among the ones imposed.) This proves the first claim.
 
 For the second, we can similarly find a polynomial $q$ with $q\equiv \phi(\lambda_i) \mod (T-\lambda_i)^{m_i}$ and zero constant coefficient. 
 
 For the last claim, if $xW_2\subset W_1$ then the same is true when $x$ is replaced by $p(x)$, for every polynomial with zero constant coefficient.
\end{proof}


The Jordan decomposition is preserved under tensor operations on the category of representations. (This will be generalized later, \ref{reference}, for arbitrary morphisms of semisimple Lie algebras.)

Notice that for two representations $V, W$ of a Lie algebra $\mathfrak g$, the tensor product $V\otimes W$ is a representation under 
$$ x \cdot (v\otimes w) = (xv)\otimes w + v\otimes (xw).$$
The dual representation on $V^*$ is defined so that the defining pairing
$$ V\otimes V^*\to k$$ 
is invariant, i.e., 
\begin{equation}
 \label{equation-dual-representation-Liealgebra}
\left< xv, v^*\right> + \left < v, xv^*\right> =0.
\end{equation}

\begin{lemma}
\label{lemma-Jordan-tensors}
Let $V$ be a finite-dimensional vector space, and $W = V^{\otimes^a}\otimes (V^*)^{\otimes^b}$, for some $a, b$. For $x\in \text{End}(V)$, denote by $x'$ the corresponding endomorphism of $W$.

If $x=x_s + x_n$ is the Jordan decomposition of $x$, then $(x_s)'+(x_n)'$ is the Jordan decomposition of $x'$. 
\end{lemma}


\begin{proof}
 It is clear that $x'=(x_s)'+(x_n)'$, with $(x_s)'$ and $(x_n)'$ commuting. It is also clear that $(x_s)'$ is semisimple. To see that $(x_n)'$ is nilpotent, it is enough to show that, if $y\in \text{End}(V_1)$, $z\in \text{End}(V_2)$ are nilpotent endomorphisms of two vector spaces, then the endomorphm $v_1\otimes v_2\mapsto (yv_1) \otimes v_2 + v_1 \otimes (zv_2)$ of $V_1\otimes V_2$ is nilpotent, which is clear by raising it to a sufficiently high power.
\end{proof}





\subsection{Cartan's criterion for solvability}
\label{subsection-Cartan-criterion}

\begin{theorem}[Cartan's criterion]
\label{theorem-Cartans-criterion}
 Let $\mathfrak g\subset \text{End}(V)$ be a Lie subalgebra, where $V$ is a finite-dimensional vector space over a field $k$ in characteristic zero. The Lie algebra $\mathfrak g$ is solvable if and only if $\text{tr}(xy)=0$ for all $x\in \mathfrak g$, $y\in [\mathfrak g, \mathfrak g]$.
 \end{theorem}

\begin{proof}
We may assume that the field is algebraically closed, and then by Lie's theorem \ref{theorem-Lie}, if $\mathfrak g$ is solvable stabilizes a flag $V_0\subset V_1\subset \dots \subset V_n=V$ with $\dim V_i=i$. Then, every $y\in [\mathfrak g,\mathfrak g]$ maps $V_i \to V_{i-1}$, hence so does any product $xy$ with $x\in \mathfrak g$, so $\text{tr}(xy)=0$.

Vice versa, assume that $\text{tr}(xy)=0$ for all $x\in \mathfrak g$, $y\in [\mathfrak g, \mathfrak g]$. To prove that $\mathfrak g$ is solvable, it is enough to prove that $[\mathfrak g,\mathfrak g]$ is nilpotent. By Engel's theorem \ref{theorem-Engel}, this is equivalent to showing that any $y\in [\mathfrak g,\mathfrak g]$ is nilpotent. 

The rest of the proof is written under the assumption that $k=\mathbb C$, so that complex conjugate of a semisimple endomorphism makes sense, as in Lemma \ref{lemma-Jordan-extension}. For a general field in characteristic zero, complex conjugation should be replaced by other field automorphisms. 

Use the Jordan decomposition $y=y_s + y_n$, and observe that $y_s=0$ iff $\text{tr}(y\cdot \overline{y_s})=0$, since the generalized eigenvalues of $y \cdot \overline{y_s}$ are the absolute values of the squares of those of $y_s$. Now, the element $\overline{y_s}$ does not necessarily belong to $\mathfrak g$, so we argue as follows: writing $y$ as a linear combination of commutators in $\mathfrak g$:
$$ y = \sum_i [x_i, z_i],$$
we easily see that 
$$ \text{tr} (y \cdot \overline{y_s}) = \sum_i \text{tr} z_i [\overline{y_s}, x_i],$$
and it is enough to show that, even though $\overline{y_s}$ may not be in $\mathfrak g$, the operator $\text{ad}(\overline{y_s})$ maps $\mathfrak g\to [\mathfrak g,\mathfrak g]$. By Lemma \ref{lemma-Jordan-tensors}, and using the fact that for the Lie algebra $\mathfrak{gl}(V)$, the adjoint representation coincides with $V\otimes V^*$, we have $\text{ad}(\overline{y_s}) = \overline{(\text{ad}(y))_s}$. Since $\text{ad}(y)$ maps $\mathfrak g$ into $[\mathfrak g,\mathfrak g]$, by Lemma \ref{lemma-Jordan-extension} the same is true for $\overline{(\text{ad}(y))_s}$.




\end{proof}

\begin{definition}
\label{definition-Killing-form}
The {\it Killing form} on a Lie algebra $\mathfrak g$ is the symmetric bilinear form 
$$B:S^2 \mathfrak g\to k$$
given by 
$$ B(x,y) = \text{tr}(\text{ad}(x)\text{ad}(y)).$$
\end{definition}

\begin{lemma}
\label{lemma-Killing-invariant}
The Killing form is invariant under the adjoint representation, i.e., for all $x, y, z\in \mathfrak g$,
$$ B(\text{ad}(x)(y), z) + B(y, \text{ad}(x)(z)) = 0.$$
\end{lemma}

\begin{proof}
 Easy consequence of the Jacobi identity.
\end{proof}


\begin{theorem}
 \label{theorem-Killing-semisimplicity}
If the Killing form of a Lie algebra is nondegenerate, the Lie algebra is semisimple. The converse holds in characteristic zero.
\end{theorem}

\begin{proof}
 If $\mathfrak g$ has a non-trivial solvable ideal, then it has a non-trivial abelian ideal $\mathfrak a$, and then the adjoint action of any $x\in \mathfrak a$ maps $\mathfrak g\to\mathfrak a$ and $\mathfrak a\to 0$. Moreover, any $y\in \mathfrak g$ preserves $a$, so 
 $\text{tr}(x) \text{tr}(y)$ maps $\mathfrak g\to\mathfrak a$ and $\mathfrak a\to 0$, and therefore has trace zero. Thus, $x$ is in the radical of the Killing form.
 
 Vice versa, in characteristic zero, if $\mathfrak h\subset \mathfrak g$ is the radical of the Killing form $B_{\mathfrak g}$, it is easy to see from its invariance that $\mathfrak h$ is an ideal of $\mathfrak g$. For every ideal $\mathfrak h\subset \mathfrak g$ the Killing form $B_{\mathfrak g}$ of $\mathfrak g$, restricted to $\mathfrak h$, coincides with the Killing form $B_{\mathfrak h}$ of $\mathfrak h$: indeed, $\text{ad}(x)$ maps $\mathfrak g\to \mathfrak h$ for $x\in \mathfrak h$, so the quotient space $\mathfrak g/\mathfrak h$ does not contribute to the trace of any product of such endomorphisms. Hence, by Cartan's criterion, Theorem \ref{theorem-Cartans-criterion}, $\mathfrak h$ is solvable, which implies that $\mathfrak g$ is not semisimple.
\end{proof}

\begin{remark}
 \label{remark-Killing-positivechar}
 The converse fails in positive characteristic, e.g., the Lie algebra $\mathfrak{sl}_p$ is semisimple if $p\ne 2$ is the characteristic of the field, but its Killing form vanishes.
\end{remark}





\section{Semisimple Lie algebras}
\label{section-semisimple}

In this section, all Lie algebras and vector spaces are finite-dimensional, unless otherwise noted. We will mostly be working in characteristic zero, except for some counterexamples that we give in positive characteristic.

\begin{proposition}
\label{proposition-sum-of-simple}
 Every finite-dimensional, semisimple Lie algebra $\mathfrak g$ in characteristic zero is a direct sum of simple Lie algebras in a unique way:
 $$\mathfrak g = \bigoplus_i \mathfrak g_i.$$
 Its derived Lie algebra $[\mathfrak g, \mathfrak g]$ is equal to $\mathfrak g$, and its ideals are precisely the subsums of the simple summands $\mathfrak g_i$.
\end{proposition}

\begin{proof}
 Let $B$ be the Killing form. Since it is invariant and non-degenerate (by Theorem \ref{theorem-Killing-semisimplicity}, the orthogonal complement of any ideal $\mathfrak h\subset \mathfrak g$ is also an ideal, and $\mathfrak g = \mathfrak h \oplus \mathfrak h^\perp$. By induction on dimension, $\mathfrak g$ is a direct sum of simple Lie algebras.
  
 On every simple summand $\mathfrak h$, $[\mathfrak h, \mathfrak h]$ is an ideal, and since $\mathfrak h$ is simple, we must have $[\mathfrak h, \mathfrak h]=\mathfrak h$, hence the same is true for (the direct sum of simple summands) $\mathfrak g$.
 
 Fixing a direct sum decomposition $\mathfrak g = \bigoplus_i \mathfrak g_i$, the image of the projection of any ideal $I$ to the summand $\mathfrak g_i$ is an ideal, hence the projection is onto or zero. If it is onto, we have $[\mathfrak g_i, I] = \mathfrak g_i$ by what was just proven, therefore $\mathfrak g_i\subset I$. This shows that ideals are precisely the direct summands $\mathfrak g_i$, which implies the uniqueness of the decomposition. 
\end{proof}

\begin{remark}
 \label{remark-notsimplesum-positivechar}
Over a field $k$ in positive characteristic $p$, this theorem does not need to hold. For example (see \cite[\S 2.4]{Rumynin}), there is a nonsplit extension 
$$ 0 \to \mathfrak h = \mathfrak{sl}_2(k[z]/z^p) \to \mathfrak g \to k \to 0$$
where, for a vector space identification $\mathfrak g = \mathfrak h \oplus k$, the summand $k$ acts by a certain derivation:
$$ [(X,x), (Y,y)] = ([X,Y] - x \partial Y + y\partial X),$$
where, for $X = \begin{pmatrix} f(z) & g(z) \\ h(z) & -f(z)\end{pmatrix}$, we have $\partial X = \begin{pmatrix} f'(z) & g'(z) \\ h'(z) & -f'(z)\end{pmatrix}$. (This is the \emph{semidirect product} of $\mathfrak h$ and $k\cdot \partial$, see \ref{subsection-derivations-semidirect}.) 

The derived Lie algebra $[\mathfrak g, \mathfrak g]$ is equal to $\mathfrak h$, which is also the unique minimal ideal.
\end{remark}




\subsection{The Casimir element} 
\label{subsection-Casimir}

The universal enveloping algebra $U(\mathfrak g)$ typically has a large center, even if $\mathfrak g$ does not (e.g., is semisimple). This is a very important reason for invoking the enveloping algebra. The structure of the center, over an algebraically closed field in characteristic zero, is described by the \emph{Harish--Chandra isomorphism}, to be discussed later. For now, we focus on producing some elements in the center. 

Let $(\pi, V)$ be a finite-dimensional representation of a Lie algebra $\mathfrak g$, and assume that the trace pairing 
$$ (X, Y)_\pi = \text{tr}(\pi(X)\pi(Y))$$
is nondegenerate. (In particular, the representation is faithful.)

It is immediate to see that the trace pairing is symmetric and invariant, hence defines a $\mathfrak g$-equivariant isomorphism 
$$ T^2\mathfrak g = \mathfrak g \otimes \mathfrak g \simeq \mathfrak g^*\otimes \mathfrak g.$$



\begin{proposition}
\label{proposition-Casimir}
If  $(\pi, V)$ is a finite-dimensional representation of $\mathfrak g$ with a nondegenerate trace pairing, used to identify $T^2\mathfrak g$ with $\text{End}(\mathfrak g)$, the element $C_\pi \in U(\mathfrak g)$ which is the image of the identity operator $I\in \text{End}(\mathfrak g)$ under the quotient $T\mathfrak g \to U(\mathfrak g)$ lies in the center of $U(\mathfrak g)$.

If $(\pi, V)$ is irreducible and $k$ is algebraically closed, $C_\pi$ acts by a scalar on $V$; that scalar is equal to $\text{dim}(\mathfrak g)/\text{dim}(V)$, if the denominator is prime to the characteristic of $k$.
\end{proposition}

Explicitly, if $(X_i)_i$ is a basis for $\mathfrak g$, and $(Y_i)_i$ is the dual basis with respect to the trace pairing of $\pi$, we have 
$$C_\pi=\sum_i X_i Y_i.$$
Its definition, which does not make use of the basis, makes it clear that this element is independent of the basis.


\begin{proof}
Because of the invariance of the trace form, the adjoint representation of $\mathfrak g$ on the second graded piece $T^2\mathfrak g$ of the tensor algebra coincides with the representation of $\mathfrak g$ on $\mathfrak g^*\otimes \mathfrak g = \text{End}(\mathfrak g)$. Since the element $I\in \text{End}(\mathfrak g)$ is invariant, i.e., $\text{ad}(X)(I) = 0$ for every $X \in \mathfrak g$, we have $\text{ad}(X)(C_\pi) = 0$ for every $X \in \mathfrak g$, hence $C_\pi$ is in the center of $U(\mathfrak g)$.

If $(\pi,V)$ is irreducible, since $C_\pi$ is central, any eigenspace of $C_\pi$ is fixed under $\mathfrak g$; thus, if the representation is irreducible and $k$ is algebraically closed, $C_\pi$ must act by a scalar. If the characteristic of $k$ does not divide $\text{dim}(V)$, that scalar can be computed as $\text{tr}(\pi(C_\pi))/\text{dim}(V)$, and using a dual basis $(X_i)_i$, $(Y_i)_i$, we have
$$ \text{tr}(\pi(C_\pi)) = \sum_i \text{tr}(\pi(X_i)\pi(Y_i)) = \text{dim}(\mathfrak g).$$

(Notice that the representation is automatically faithful, since the trace form is nondegenerate.)
\end{proof}

The following is a useful observation:

\begin{lemma}
\label{lemma-tracepairing-nondegenerate}
 Let $\pi:\mathfrak g \to \mathfrak{gl}(V)$ be a faithful, finite-dimensional representation of a semisimple Lie algebra in characteristic zero. The trace pairing  $(\, , \, )_\pi$ is nondegenerate, and different simple summands of $\mathfrak g$ (Proposition \ref{proposition-sum-of-simple}) are orthogonal with respect to it.
\end{lemma}


\begin{proof}
 By Cartan's criterion \ref{theorem-Cartans-criterion}, the trace pairing is nonzero on each simple summand of $\mathfrak g$; since the radical of an invariant symmetric form is an ideal, it is nondegenerate on each simple summand. The form is invariant, hence the orthogonal complement of each simple summand is $\mathfrak g$-stable, and by induction it decomposes into the direct sum of simple ideals in $\mathfrak g$ (which is unique, by Proposition \ref{proposition-sum-of-simple}).
\end{proof}




\begin{definition}
 \label{definition-Casimir}
Let $\mathfrak g$ be a semisimple Lie algebra in characteristic zero, and use the Killing form, which is nondegenerate by Theorem \ref{theorem-Killing-semisimplicity}, to identify $T^2\mathfrak g = \mathfrak g^*\otimes \mathfrak g = \text{End}(\mathfrak g)$. The element $C$ in the center of $U(\mathfrak g)$ (by Proposition \ref{proposition-Casimir} applied to the adjoint representation), which is the image of the identity operator 
$ I \in \text{End}(\mathfrak g) = T^2 \mathfrak g$ in $U(\mathfrak g)$,
is called the {\it Casimir element} of $U(\mathfrak g)$.
\end{definition}

For example, when $\mathfrak g = \mathfrak{sl}_2$ with generators $(h,e,f)$ and bracket $[h,e]=2e$, $[h,f]=-2f$, $[e,f]=h$, the Casimir element is 
$$ C = \frac{1}{8} h^2 + \frac{1}{4} ef + \frac{1}{4} fe = \frac{1}{8} h^2 - \frac{1}{4} h + \frac{1}{2} ef = \frac{1}{8} h^2 + \frac{1}{4} h + \frac{1}{2} fe.$$



\subsection{Lie algebra cohomology and complete reducibility}
\label{subsection-complete-reducibility}

We will examine the question of whether a short exact sequence of $\mathfrak g$-representations 
\begin{equation}
\label{equation-extension-representations}
0\to A\to B\to C\to 0 
\end{equation}
admits a splitting: $B\simeq A\oplus C$. 

The answer is given in terms of Lie algebra cohomology, which describes isomorphism classes of extensions $B$ as in \eqref{equation-extension-representations} in terms of a cohomology group.

Notice that any exact sequence of $k$-vector spaces splits (as vector spaces). That is, there is an element of $\Hom_k(C,B)$ which lifts the identity element in $\Hom_k(C,C)$. We would like to know that there is a $\mathfrak g$-invariant such element. Thus, it suffices to show that if we apply the functor of ``$\mathfrak g$-invariants'' to the exact sequence:
$$0\to \Hom_k(C,A)\to \Hom_k(C,B) \to \Hom_k(C,C) \to 0,$$
it remains exact. (Notice that, in the context of Lie algebras, $\mathfrak g$-invariants---equivalently, the trivial representation of $\mathfrak g$---simply means that $\mathfrak g$ acts by zero.)

This is a problem is cohomology. The functor of $\mathfrak g$-invariants is left-exact, and it admits right derived functors $H^n(\mathfrak g, \bullet)$ which, in particular, turn any short exact sequence of $\mathfrak g$-modules $0\to U\to V\to W\to 0$ (think of the above $\Hom$ spaces here) to a long exact sequence:
$$0\to U^{\mathfrak g}\to V^{\mathfrak g}\to W^{\mathfrak g}\to H^1(\mathfrak g, U)\to H^1(\mathfrak g, V)\to H^1(\mathfrak g, W)\to \dots.$$

The groups $H^n(\mathfrak g, V)$ can also be thought of as $\text{Ext}^n_{\mathfrak g}(k, V)$, which are the derived functors of $\text{Hom}_{\mathfrak g}(\bullet , \bullet)$ in either argument. The group $\text{Ext}^1(C,A)$, in particular, describes isomorphism classes of extensions \eqref{equation-extension-representations}. 


%The right derived functor $H^1$ can be explicitly described, it turns out, as follows:
%$$H^1(\mathfrak g, V) = Z^1(\mathfrak g, V)/C^1(\mathfrak g, V),$$
%where the cocycles $Z^1(\mathfrak g, V)$ are maps $f:\mathfrak g\to V$ satisfying:
%$$ f([X,Y]) = Xf(Y)-Yf(X),$$
%and the coboundaries are those of the form: $f(X)=Xv$ (for some $v\in V$).

%We will prove that, if $\mathfrak g$ is semisimple and $k$ is of characteristic zero, $H^1(\mathfrak g,V)=0$ for any finite-dimensional $\mathfrak g$-module. 


\begin{theorem}
\label{theorem-complete-reducibility}
 If $\mathfrak g$ is a semisimple Lie algebra in characteristic zero, for any finite-dimensional $\mathfrak g$-module $V$ we have $H^1(\mathfrak g,V)=0$.
 
 Every finite-dimensional representation of $\mathfrak g$ is semisimple.
\end{theorem}

The statement on semisimplicity (complete reducibility) is due to Weyl, and referred to Weyl's theorem.

\begin{proof}
 First, we reduce to simple $\mathfrak g$-modules by induction. Suppose that we have a short exact sequence:
$$0\to U\to V\to W\to 0,$$
and that the first cohomology groups of $U$ and $W$ are trivial, then the long exact sequence shows that $H^1(\mathfrak g, V)=0$, as well.

Now assume that $V$ is irreducible. By the interpretation of $H^1(\mathfrak g, V)$ in terms of isomorphism classes of extensions 
$$ 0 \to V \to W \to k\to 0,$$
it is enough to show that any such extension splits (as $\mathfrak g$-modules).

We will work separately on the cases where $V$ is the trivial representation, and $V$ is nontrivial.

If $V\ne k$, then we first reduce to the case where $\mathfrak g$ acts faithfully on $V$: Let $\mathfrak h$ be the kernel of the map $\mathfrak g\to \mathfrak{gl}(V)$ (it is an ideal of $\mathfrak g$). We claim that $\mathfrak h$ also acts trivially on $W$. Indeed, $\mathfrak g$ maps $W\to V$, and $\mathfrak h$ maps $V\to 0$, so $[\mathfrak h,\mathfrak h]$ acts trivially on $W$. But $\mathfrak g$ is semisimple in characteristic zero, and by Proposition \ref{proposition-sum-of-simple}, it is a sum of simple Lie algebras, hence $\mathfrak h$ is a subsum of those, hence semisimple. Again by the same proposition, $[\mathfrak h,\mathfrak h] = \mathfrak h$. So, the representation $W$ factors through $\mathfrak g/\mathfrak h$, and we may replace $\mathfrak g$ by that to assume that $\mathfrak g$ acts faithfully.

Consider, then, the trace pairing $(X,Y)_\pi\mapsto \text{tr}(\pi(X)\pi(Y))$, where $\pi$ is the representation of $\mathfrak g$ on $V$. By Lemma \ref{lemma-tracepairing-nondegenerate}, it is nondegenerate, hence the central element $C_\pi$ of Proposition \ref{proposition-Casimir} is defined. By the same proposition, $C_\pi$ acts on $V$ by a nonzero scalar; on the other hand, it acts on $k$ by zero. Thus, the short exact sequence can be split $W=V\oplus k$, according to the eigenspaces of $C_\pi$. 

If $V=k$, that means that the image of $\mathfrak g$ in $\text{End}(W)$ consists of nilpotent operators, hence is a nilpotent Lie algebra by Engel's theorem \ref{theorem-Engel}. Being a direct sum of simple Lie algebras by Proposition \ref{proposition-sum-of-simple}, $\mathfrak g$ has no nontrivial nilpotent quotients, hence $W$ is the trivial representation. This completes the proof that $H^1(\mathfrak g, V)=0$ for any finite-dimensional representation $V$. 

Finally, for a short exact sequence of $\mathfrak g$-modules $0\to A \to B\to C \to 0$, applying the vanishing of cohomology to the modules $\Hom_k(C, \bullet)$, we get a short exact sequence
$$ 0\to \Hom_{\mathfrak g}(C,A)\to \Hom_{\mathfrak g}(C,B) \to \Hom_{\mathfrak g}(C,C) \to 0,$$
hence the identity element in $\Hom_{\mathfrak g}(C,C)$ can be lifted to a $\mathfrak g$-morphism $C\to B$. This proves complete reducibility.
\end{proof}


\begin{remarks}
 \label{remarks-complete-reducibility}
 \begin{enumerate}
  \item Complete reducibility fails for infinite-dimensional representations; in fact, in our study of the category $O$, we will construct the finite-dimensional representations as quotients of infinite-dimensional, non-semisimple representations.
  \item Complete reducibility fails in positive characteristic $p$. For example, the Lie algebra $\mathfrak g=\mathfrak{sl}_2$ is semisimple if $p\ne 2$, but the $p$-th symmetric power of its standard representation is not semisimple. Indeed, the space of polynomials of degree $p$ in two variables $(x,y)$ contains the invariant subspace generated by $x^p$ and $y^p$ (with trivial action of $\mathfrak g$), but the $\mathfrak g$-span of any other nonzero vector $v=\sum_{i=0}^p a_i x^{p-i} y^i$ meets that subspace, because if $m$ is the maximal $i$ with $i\ne p$ such that $a_i\ne 0$, and $e= x \frac{\partial}{\partial y} \in \mathfrak g$, we have $e^m v = m! a_m x^m$. 
 \end{enumerate}

\end{remarks}


\subsection{Derivations and the Jordan decomposition}
\label{subsection-derivations-Jordan}



\begin{proposition}
\label{proposition-derivations-inner}
 Every derivation of a semisimple Lie algebra in characteristic zero is inner (Definition \ref{definition-inner-derivation}).
\end{proposition}

\begin{proof}
 The formula $[D,\text{ad}(X)]=\text{ad}(DX)$ shows that the image of $\text{ad}$ is an ideal in $\text{Der}(\mathfrak g)$. Since the image is a semisimple Lie algebra, there is a complementary ideal $I$ (namely, its orthogonal complement under the Killing form on $\text{Der}(\mathfrak g)$). But if $D\in I$, and $I$ is an ideal, the same formula shows that $\text{ad}(DX)\in I\cap \text{ad}(\mathfrak g)=0$, which since $\text{ad}$ is injective means that $DX=0$, i.e.\ $D=0$.
\end{proof}

\begin{remark}
 \label{remark-failure-inner}
 We already saw in Remark \ref{remark-notsimplesum-positivechar} that Proposition \ref{proposition-derivations-inner} fails in positive characteristic.
\end{remark}



\begin{proposition}
\label{proposition-Jordan-derivations}
 If $D\in \text{Der}(\mathfrak g)\subset \text{End}(\mathfrak g)$ then $D_s,D_n\in\text{Der}(\mathfrak g)$.
\end{proposition}

\begin{proof}
We may assume that the field is algebraically closed. 
 If $X$ is in the generalized $\lambda$-eigenspace and $Y$ is in the generalized $\mu$-eigenspace for $D$, then it can be shown by induction that:
$$ (D-(\lambda+\mu))^n([X,Y]) = \sum_{r=0}^n \binom{n}{r} [(D-\lambda)^r(X),(D-\mu)^{n-r}(Y)],$$
hence $[X,Y]$ is in the generalized $\mu+\lambda$-eigenspace. This shows that $D_s$ is a derivation, and then $D_n=D-D_s$ is a derivation.
\end{proof}


\begin{definition}
\label{definition-nilpotent-semisimple-element}
Let $\mathfrak g$ be a Lie algebra. An element $X\in \mathfrak g$ is called \emph{semisimple} if $\text{ad}(X)$ is a semisimple operator, and \emph{nilpotent} if $\text{ad}(X)$ is nilpotent.
\end{definition}

\begin{theorem}[Jordan--Chevalley decomposition]
\label{theorem-Jordan-Chevalley}
Let $\mathfrak g$ be a semisimple Lie algebra in characteristic zero. Every $X\in \mathfrak g$ admits a unique decomposition $X=X_s + X_n$, with $X_s$ semisimple, $X_n$ nilpotent, and $[X_s,X_n]=0$.

Moreover, for any finite-dimensional representation $\rho:\mathfrak g \to \mathfrak{gl}(V)$, and any $X\in \mathfrak g$, we have
$\rho(X_s) = \rho(X)_s$, $\rho(X_n)=\rho(X)_n$, where $\rho(X)=\rho(X)_s+\rho(X)_n$ is the Jordan decomposition of $\rho(X)$.

Finally, for any morphism $\pi: \mathfrak g_1 \to \mathfrak g_2$ of semisimple Lie algebras in characteristic zero, and any $X\in \mathfrak g_1$, we have $\pi(X_s) = \pi(X)_s$, $\pi(X_n)=\pi(X)_n$.
\end{theorem}


\begin{proof}
By the Propositions \ref{proposition-Jordan-derivations}, $\text{ad}(X)_s$ and $\text{ad}(X)_n$ are derivations in $\text{End}(\mathfrak g)$. By Proposition \ref{proposition-derivations-inner}, they belong to the image of $\text{ad}$. Since the adjoint representation is faithful, this proves the existence and uniqueness of $X_s$ and $X_n$. 

By complete reducibility of $\text{End}(V)$ under the adjoint $\mathfrak g$-action, we have:
$$\text{End}(V)= \rho(\mathfrak g)\oplus\mathfrak m,$$
where $\mathfrak m$ is an $\text{ad}(\rho(\mathfrak g))$-invariant subspace. (Notice that in Proposition \ref{proposition-derivations-inner} we were able to obtain a similar decomposition in $\text{Der}(\mathfrak g)$ by using the Killing form, so we did not need to know reducibility.)

Since $\rho(X)_s,\rho(X)_n$ are polynomials in $\rho(X)$, their adjoint action preserves both $\rho(\mathfrak g)$ and $\mathfrak m$. Let $\rho(X)_n = \rho(a) + b$ with $a\in \mathfrak g,b\in \mathfrak m$. Since $[\rho(\mathfrak g),b]=0$,  $b\in \text{End}(V)$ is a $\mathfrak g$-endomorphism. If $V=\oplus V_i$ is a decomposition into irreducibles, $b$ acts by a scalar on each one of them, by Schur's lemma. On the other hand, we know that $\rho(X)_n$ is nilpotent, $\rho(a)$ and $b$ commute, and $\text{tr}_{V_i}(\rho(a)) =0$ because $a$ (like every element of $\mathfrak g$) is a sum of commutators. Therefore, $\text{tr}_{V_i}(b)=0$, hence $b$ acts by zero on all $V_i$, i.e.\ $b=0$. 

Now, $\rho(X)_n=\rho(a)$ acts nilpotently on $V$, hence it acts nilpotently on $\text{End}(V)$ under the adjoint representation. By the decomposition $\text{End}(V)=\mathfrak g\oplus \mathfrak m$ it follows that it acts nilpotently on $\mathfrak g$. By the uniqueness of the Jordan decomposition we can now infer that $\rho(X)_n= \rho(X_n)$. 

Finally, for any morphism $\pi: \mathfrak g_1 \to \mathfrak g_2$, setting $\rho=\text{ad}\circ\pi$ and applying the previous statement, we obtain the last statement.
\end{proof}



\section{Root systems and the structure of semisimple Lie algebras}
\label{section-root-decomposition}

In this section, the underlying field is of characteristic zero, and we keep assuming that all vector spaces are finite dimensional.

\subsection{Representations of $\mathfrak{sl}_2$.}
\label{subsection-representations-sl2}

The Lie algebra of $\mathfrak{sl}_2$ is generated over the underlying field by three elements $H, E, F$ with bracket relations:
$$[H,E]=2E,$$
$$[H,F]=-2F,$$
$$[E,F] = H.$$

Let $\Delta = 8 C = 4FE + (H+2) H$ in the center of $U(\mathfrak g)$. (It turns out---see the Harish-Chandra isomorphism, Theorem \ref{vermamodules-theorem-HC-isomorphism}--- that $Z(U\mathfrak g)$ is a polynomial ring generated by this element.)

Given a representation $V$ of $\mathfrak{sl}_2$ (recall that all spaces are assumed finite-dimensional in this chapter), and $\lambda\in k$, let $V_\lambda$ denote the $\lambda$-eigenspace of $H$. We don't know yet that $H$ acts semisimply, so a priori $V$ is not the direct sum of the $V_\lambda$'s. 

\begin{lemma}
\label{lemma-shift-eigenspaces}
 $E\cdot V_\lambda\subset V_{\lambda+2}$; $F\cdot V_\lambda\subset V_{\lambda-2}$.

There is a non-zero vector $v\in V$ which is an eigenvector for $H$ and such that $Ev=0$. 
\end{lemma}

\begin{proof}
The first statement is clear from the bracket relations. From the finite-dimensionality of $V$, there must be a nonzero $H$-eigenvector annihilated by $E$.
\end{proof}

\begin{definition}
\label{definition-highest-weight}
A {\it highest weight vector of an $\mathfrak{sl}_2$-module} is a nonzero vector annihilated by $E$. A {\it lowest weight vector of an $\mathfrak{sl}_2$-module} is a nonzero vector annihilated by $F$. 
\end{definition}



\begin{proposition}
\label{proposition-sl2-irreducibles}
 Fix a heighest weight vector $v\in V_\lambda$, and let $V'$ be the span of $\{F^iv\}_{i\in\mathbb N}$. Then $V'$ is $\mathfrak{sl}_2$-stable, irreducible, and $\Delta$ acts by $\lambda(\lambda + 2)$. The highest weight $\lambda$ is a non-negative integer, and $V'$ is the sum of one-dimensional weight spaces $V'_{\mu}$ for $\mu = \lambda, \lambda-2,\lambda-4, \dots, -\lambda$.

\end{proposition}

\begin{proof}
 It is clearly stable under $F$ and $H$. We easily compute:
$$ EF^nv_\lambda = n(\lambda-(n-1))F^{n-1}v_\lambda.$$
Hence, the space is $E$-stable. 

Moreover, since it is finite-dimensional, we must have $n(\lambda-(n-1))=0$ for some $n\ge 1$, hence $\lambda$ is a non-negative integer. In that case, $n=\lambda+1$, and $F^n v_\lambda$ must be zero (because it is a highest weight vector of weight $-\lambda-2$ and, by the same argument, it cannot generate a finite-dimensional representation). On the other hand, for $n<\lambda+1$ $EF^nv_\lambda\ne 0$, hence $F^nv_\lambda\ne 0$. The statement about the weight spaces of $V'$ follows.

We have: $\Delta v = 4FEv+(H+2)Hv = 0+ \lambda(\lambda+2)v$. Since $\Delta$ commutes with the action of $\mathfrak{sl}_2$ and is generated by $v$, all elements of $V'$ have the same $\Delta$-eigenvalue.

On the other hand, $V'$ has at most one eigenvector for each $H$-eigenvalue. If $V'$ was reducible, there would be some highest weight vector with eigenvalue $\ne $
\end{proof}




\begin{theorem}
\label{theorem-reps-sl2}
For every nonnegative integer $n$ there is a unique, up to isomorphism, irreducible finite-dimensional representation $V_n$ of $\mathfrak{sl}_2$ of heighest weight $n$ (in characteristic zero). It has dimension $n+1$, and eigenvalue $n(n+2)$ under the operator $\Delta$.

All finite-dimensional representations of $\mathfrak{sl}_2$ are $H$-semisimple, and direct sums of the modules $V_n$.
\end{theorem}


\begin{proof}
If $V$ denotes the standard, $2$-dimensional representation, then it is easy to see that $S^n V$ has a unique highest weight vector with weight $n+1$, hence is irreducible. Uniqueness follows from the explicit description of the action of $E, F$ and $H$ above, and the rest follow from complete reducibility (Theorem \ref{theorem-complete-reducibility}) and Proposition \ref{proposition-sl2-irreducibles}.
\end{proof}

This existence statement will require a lot more work in the general case.

\subsection{Cartan subalgebras of semisimple Lie algebras}
\label{subsection-CSA-semisimple}

\begin{proposition}
\label{proposition-CSA-semisimple}
 Assume that $\mathfrak g$ is a semisimple  Lie algebra in characteristic zero, and let $\mathfrak h$ be the generalized nilspace of an s-regular element (hence\footnote{Eventually, since they are conjugate, all Cartan subalgebras are of this form}, by Proposition \ref{proposition-CSA-centralizer}, a Cartan subalgebra). Then:
\begin{enumerate}
 \item $\mathfrak h$ is a maximal abelian subalgebra.
 \item The centralizer of $\mathfrak h$ is $\mathfrak h$.
 \item Every element of $\mathfrak h$ is semisimple. Every s-regular element of $\mathfrak g$ is semisimple.
 \item \label{Killingrestriction} The restriction of the Killing form (or any non-degenerate invariant symmetric bilinear form) of $\mathfrak g$ to $\mathfrak h$ is non-degenerate.
\end{enumerate}
\end{proposition}

\begin{proof}
If we prove \eqref{Killingrestriction}, the rest of the statements will follow; let us see how: 

Cartan's criterion says that a Lie subalgebra $\mathfrak a$ of $\text{End}(V)$ is solvable if and only if $\text{tr}(XY)=0$ for every $X\in \mathfrak a, Y\in [\mathfrak a,\mathfrak a]$. Applying this to $\text{ad}(\mathfrak h)\subset \text{End}(\mathfrak g)$ (which is nilpotent, hence solvable), we get that $B(X,Y)=0$ for all $X\in \mathfrak h, Y\in[\mathfrak h,\mathfrak h]$ (where $B$ is the Killing form for $\mathfrak g$). Therefore, the radical of the restriction of $B$ to $\mathfrak h$ contains the commutator, which means that $[\mathfrak h,\mathfrak h]=0$. Thus, $\mathfrak h$ is abelian.

The centralizer is contained in the normalizer, which is $\mathfrak h$, but since $\mathfrak h$ is abelian it coincides with it. Thus, $\mathfrak h$ is maximal abelian.

Finally, let $X\in\mathfrak h$ and let $X=X_s+X_n$ be its Jordan decomposition. Since $X_s, X_n$ commute with the centralizer of $X$, which contains $\mathfrak h$, it follows that $X_s, X_n$ are in the centralizer of $\mathfrak h$, which is $\mathfrak h$. Thus, if $Y\in\mathfrak h$, $\text{ad}(Y)\text{ad}(X_n)$ is nilpotent, which implies that $\text{ad}(X_n)$ is orthogonal to $\mathfrak h$ under the Killing form. By non-degeneracy of the Killing form on $\mathfrak h$, $X_n=0$. Every s-regular element of $\mathfrak g$ is contained in its generalized nilspace $\mathfrak h$, hence is semisimple.

We come to the proof of \eqref{Killingrestriction}: if $X$ is an $s$-regular element such that $\mathfrak h$ is the generalized nilspace of $X$, let $\mathfrak g = \bigoplus_\lambda \mathfrak g_\lambda$ be a decomposition of $\mathfrak g$ into generalized $\text{ad}(X)$-eigenspaces. As we saw in the proof of Proposition \ref{proposition-Jordan-derivations}, $[\mathfrak g_\lambda,\mathfrak g_\mu]\subset \mathfrak g_{\lambda+\mu}$, which implies that $\mathfrak g_\lambda \perp \mathfrak g_\mu$ (under the Killing form), unless $\lambda+\mu=0$. Therefore, the decomposition:
$$ \mathfrak g = \mathfrak g_0 \oplus \bigoplus (\mathfrak g_{\lambda}\oplus \mathfrak g_{-\lambda})$$
is orthogonal, and since $B$ is nondegenerate, it has to be non-degenerate on each of the summands, in particular on $\mathfrak h=\mathfrak g_0$.
\end{proof}




\subsection{The root system of a semisimple Lie algebra}
\label{subsection-root-systems}

Let $\mathfrak g$ be a semisimple Lie algebra over an algebraically closed field $k$ in characteristic zero. Fix $\mathfrak h\subset \mathfrak g$ a Cartan subalgebra. All constructions that follow depend, a priori, on $\mathfrak h$. In Section \ref{section-Borel-Cartan} we will see that all Cartan subalgebras are conjugate, and this will establish independence of the root system of $\mathfrak g$ from the choice of $\mathfrak h$. Recall that, by Proposition \ref{proposition-CSA-semisimple}, $\mathfrak h$ is abelian. It


By Proposition \ref{proposition-CSA-semisimple}, the restriction of the adjoint representation to a Cartan subalgebra $\mathfrak h$ reads:
\begin{equation}
 \label{equation-root-decomposition}\mathfrak g = \mathfrak h \oplus \bigoplus_{\alpha}  \mathfrak g_\alpha,
\end{equation}
where the $\mathfrak g_\alpha$'s are eigenspaces with \emph{nonzero} eigencharacter $\alpha \in \mathfrak h^*$.


\begin{definition}
 \label{definition-roots}
The set $\Phi$ of nonzero elements $\alpha \in \mathfrak h^*$ such that $\mathfrak g_\alpha\ne 0$ in the decomposition \eqref{equation-root-decomposition} is called the set of {\it roots} of $\mathfrak g$.
\end{definition}

\begin{theorem}
 \label{theorem-root-system}
The following hold for the set of roots $\Phi$ of a semisimple Lie algebra $\mathfrak g$: 
\begin{enumerate}
 \item $\Phi$ spans $\mathfrak h^*$.
 \item If $\alpha\in \Phi$, then $-\alpha\in \Phi$.
 \item If $\alpha\in\Phi$, let $\mathfrak t_\alpha \in \mathfrak h$ be the image of $\alpha$ under the isomorphism: $\mathfrak h^*\to\mathfrak h$ defined by a non-degenerate invariant symmetric form $(\,,\,)$ on $\mathfrak g$. Then, for all $X\in \mathfrak g_\alpha, Y\in\mathfrak g_{-\alpha}$ we have: $[X,Y] = (X,Y) t_\alpha$. 
 \item $(t_\alpha,t_\alpha)\ne 0$.
 \item The sum $\mathfrak h_\alpha+ \mathfrak g_\alpha + \mathfrak g_{-\alpha}$ is a subalgebra isomorphic to $\mathfrak{sl}_2$; denote it by $\mathfrak{sl}_{2,\alpha}$.
 \item  If $\alpha, c\alpha\in \Phi$ then $c = \pm 1$.
 \item For any $\alpha, \beta\in \Phi$ and non-proportional, the $\mathfrak{sl}_{2,\alpha}$-stable subspace $\mathfrak g_{\beta + \mathbb Z \alpha}$ is an irreducible representation of $\mathfrak{sl}_{2,\alpha}$.
 \item For any $\alpha\in \Phi$, let $w_\alpha$ be the linear transformation $\lambda\mapsto \lambda - \left< \lambda, h_\alpha\right>$ on $\mathfrak h^*$. Then, $w_\alpha$ fixes $\Phi$.
\end{enumerate}
\end{theorem}

\begin{remark}
 \label{remark-indep-of-form}
For the last statement of Theorem \ref{theorem-root-system}, we could have used any positive definite invariant inner product; indeed, on the simple summands of $\mathfrak g$ (see Proposition \ref{proposition-sum-of-simple}) any two of them are equal up to a scalar, and the different summands are orthogonal, so the reflections do not depend on the choice of invariant inner product. 
\end{remark}


\begin{proof}

\begin{enumerate}
 \item Any $x\in \mathfrak h$ in the kernel of $\Phi$ is central in $\mathfrak g$, hence zero since $\mathfrak g$ is semisimple.
 \item Choose a non-degenerate invariant symmetric form $(\,,\,)$. For $\alpha$, $\beta$ in $\Phi$ (or zero),  $x \in \mathfrak g_\alpha$, $y\in \mathfrak g_\beta$ and any $z\in \mathfrak h$, by invariance we have 
 $$ \alpha(z) (x,y) = ([z,x],y) = - (x, [z,y]) = -\beta(z) (x,y).$$
 Thus, $(x,y)=0$ unless $\alpha+\beta=0$. Since the form is nondegenerate, for every $x$ there must be a $y$ with $(x,y)\ne 0$, thus if $\alpha\in\Phi$, so is $-\alpha$. 
 \item Notice first that $[\mathfrak g_\alpha,\mathfrak g_\beta]\subset \mathfrak g_{\alpha+\beta}$, so $[x,y]$ must belong to $\mathfrak h$. For all $z\in \mathfrak h$, $x\in \mathfrak g_\alpha, y\in\mathfrak g_{-\alpha}$ we have: $(z,[x,y]) = ([z,x],y) = \alpha(z) (x,y) = (z, (x,y) t_\alpha)$. Since the form is nondegenerate on $\mathfrak h$, by Proposition \ref{proposition-CSA-semisimple}, we deduce that $[x,y] = (x,y) t_\alpha$. 
 \item Notice that the pairing $(\,,\,)$ between $\mathfrak g_\alpha$ and $\mathfrak g_{-\alpha}$ is nonzero because otherwise it would be degenerate on $\mathfrak g$. It follows that $\mathfrak h_\alpha:= [\mathfrak g_\alpha,\mathfrak g_{-\alpha}]$ is one-dimensional, spanned by the element $t_\alpha$. If $(t_\alpha, t_\alpha)=0$ then $(t_\alpha, [x,y])=0$ (for $x,y$ as before), which implies that $[t_\alpha, x]=[t_\alpha,y]=0$, and the elements $x, y, t_\alpha$ span a solvable Lie algebra. Thus, its image under the adjoint representation stabilizes a full flag, and since $t_\alpha$ is in its commutator, $\text{ad}(t_\alpha)$ is nilpotent. But by Proposition \ref{proposition-CSA-semisimple}, $\text{ad}(t_\alpha)$ is also semisimple, so it has to be zero, which means that $t_\alpha$ is a central element in $\mathfrak g$, a contradiction.
 \item Let $h_\alpha \in\mathfrak h_\alpha$ be the element characterized by $\alpha(h_\alpha)=2$, that is, $h_\alpha = \frac{2}{(t_\alpha,t_\alpha)} t_\alpha$. Choose any nonzero element $x=e \in \mathfrak g_\alpha$, and then choose $y=f\in\mathfrak g_{-\alpha}$ with $(e,f) = \frac{2}{(t_\alpha,t_\alpha)}$. Then, $(h,e,f)$ is an $\mathfrak{sl}_2$-triple, and we denote its span by $\mathfrak{sl}_{2,\alpha}$. The subspace
 $$ \mathfrak m = \mathfrak h_\alpha \oplus \bigoplus_{n\in \mathbb Z, n \ne 0} \mathfrak g_{n\alpha}$$ decomposes, as an $\mathfrak{sl}_{2,\alpha}$-module, into finite-dimensional irreducible representations with even weights (for $h_\alpha$). Since the zero weight space is one-dimensional, this implies (from the classification of irreducible, finite-dimensional representations of $\mathfrak{sl}_2$) that it is irreducible. It contains the adjoint representation of $\mathfrak{sl}_2$, therefore $\mathfrak m = \mathfrak{sl}_{2,\alpha}$. 
 \item The previous point proves that there are no integral multiples of $\alpha$ in $\Phi$, other than $\pm \alpha$. Similarly, again by the classification of irreducible, finite-dimensional representations of $\mathfrak{sl}_2$, the only other multiples are half-integral, and if one of them appears, then $\frac{\alpha}{2}$ must appear; indeed, the weights for $h_\alpha$ have to be integers, and if an odd integer appears, then so must the weight $1$. But, repeating this argument with $\frac{\alpha}{2}$ in place of $\alpha$, we get that $2\frac{\alpha}{2}$ cannot appear, a contradiction. Hence, $\frac{\alpha}{2}\notin \Phi$.
 \item  For any $\beta\in \Phi$ which is non-proportional to $\alpha$, consider the subspace
 $$\mathfrak n = \mathfrak g_{\beta + \mathbb Z \alpha}.$$
 It is a $\mathfrak{sl}_{2,\alpha}$-stable subspace with weights (for $h_\alpha$) of the same parity, and each nonzero-weight space is one-dimensional, therefore it is an irreducible representation of $\mathfrak{sl}_{2,\alpha}$.
 \item By the classification of irreducible representation of $\mathfrak{sl}_2$, the subspace $\mathfrak n$
 must include a range of weights differing by $2$; therefore, 
 $$\Phi \cap (\beta + \mathbb Z \alpha) = \left\{\beta+ n\alpha\right\}_{n=-r}^q$$
 for some nonnegative integers $r, q$. This has $r+q+1$ weights, therefore the lowest weight must be $-(r+q)$, the heighest weight must be $(r+q)$. Therefore, 
\begin{equation}
 \label{equation-pairing-roots}
\left< \beta, h_\alpha\right> = r-q,
\end{equation}
and we get 
 $$ w_\alpha(\beta) = \beta - \left< \beta, h_\alpha\right> \alpha = \beta - (r-q)\alpha \in \Phi.$$
\end{enumerate}
\end{proof}


\begin{definition}
 \label{definition-root-system}
A (crystallographic) {\it root system} is a triple $(E,\Phi, W)$, where 
\begin{itemize} \item $E$ be a finite-dimensional real vector space;
 \item $\Phi$ is a finite subset of $E$ not containing zero;
 \item $W \subset \text{GL}(E)$ is a (necessarily finite) group of automorphisms preserving $\Phi$,
 generated by elements $w_\alpha$, $\alpha\in \Phi$, which fix a hyperplane and send the root $\alpha$ to $-\alpha$. 
\end{itemize}

The group $W$ is called the {\it Weyl group} of the root system.

The root system is said to be {\it reduced} if $\Phi\cap \mathbb R\alpha = \{\pm \alpha\}$. 
\end{definition}

\begin{definition}
 \label{definition-rootsystem-ofLiealgebra}
The {\it root system of a semisimple Lie algebra} $\mathfrak g$, with respect to a Cartan subalgebra $\mathfrak h$, is the triple $(E,\Phi,W)$, where $\Phi\subset \mathfrak h^*$, $E$ is the $\mathbb R$-span of $\Phi$, and $W$ is the group generated by the reflections $w_\alpha$, $\alpha\in \Phi$.
\end{definition}


\begin{remark}
 \label{remark-definition-rootsystem}
In many references, a root system is defined with $W$ replaced by an inner product on $E$, such that the elements $w_\alpha$ are orthogonal reflections on the hyperplanes perpendicular to the roots. Clearly, such an inner product determines the Weyl group $W$; vice versa, any finite-dimensional representation of a finite group is unitarizable, so for any root system in the sense of Definition \ref{definition-root-system}, there is an inner product with respect to which the $w_\alpha$'s are orthogonal reflections. Moreover, up to the obvious freedom of rescaling the inner product on each \emph{irreducible} summand of the root system (i.e., a summand that cannot be further decomposed as a direct sum of two root systems), the inner product is unique.

The following proposition shows a way to produce such an inner product for a given Lie algebra.
\end{remark}

\begin{lemma}
\label{lemma-Killing-positivedefinite} 
Let $(\, , \,)$ be the Killing form, and use it to identify $\mathfrak h^*=\mathfrak h$. Let $E$ be the $\mathbb R$-span of the roots. Then, the Killing form is positive definite on the span of roots.
\end{lemma}

\begin{proof}
Let $t_\lambda\in \mathfrak h$ be the element that corresponds to $\lambda\in \mathfrak h^*$ under the identification. We compute:
$$(\lambda,\lambda)=(t_\lambda,t_\lambda) = \text{tr}((\text{ad}(t_\lambda))^2) = \sum_{\alpha\in\Phi} \alpha(t_\lambda)^2.$$ 
If we can show that $(\alpha,\beta)=\alpha(t_\beta)\in \mathbb R$ for every root $\beta$, that would imply positivity (since we already know, from Theorem \ref{theorem-root-system}, that $\alpha(t_\alpha) = (t_\alpha, t_\alpha)\ne 0$.

From \eqref{equation-pairing-roots}, we have that $(\alpha,\beta) =  \alpha(t_\beta) = \frac{\alpha(h_\beta)}{2} (\beta,\beta) \in \mathbb Q\cdot (\beta,\beta)$, and therefore
$$(\beta,\beta) = \sum_{\alpha\in\Phi} (\alpha,\beta)^2 \in \mathbb Q\cdot (\beta,\beta)^2,$$
therefore $(\beta,\beta) \in \mathbb Q$ and $(\alpha,\beta)\in \mathbb Q$.
\end{proof}



\begin{definition}
 \label{definition-coroots}
Given a Cartan algebra $\mathfrak h\subset \mathfrak g$, the element $h_\alpha\in\mathfrak h$ of any $\mathfrak{sl}_2$-triple $(h_\alpha, e, f)$ with $e\in\mathfrak g_\alpha$, $f\in\mathfrak g_{-\alpha}$ is called the {\it coroot} associated to the root $\alpha$, and denoted by $\check\alpha$. 
\end{definition}

Notice that $\mathfrak h_\alpha$ does not depend on the choice of $e$ and $f$. We will denote the set of coroots by $\check\Phi$. Hence, the simple reflection $w_\alpha$ on $\mathfrak h^*$ associated to the root $\alpha$ can be written:
\begin{equation}
 \label{equation-reflection-coroot}
 w_\alpha(x) = x - \left< x, \check\alpha\right> \alpha.
\end{equation}

\begin{lemma}
 \label{lemma-dualrootsystem}
If $(E,\Phi, W)$ is a root system, then $(E^*,\check\Phi, W)$ is also a root system, where $W$ acts on $E^*$ by the dual representation to $E$.
\end{lemma}

\begin{proof}
 Obvious.
\end{proof}


\begin{definition}
 \label{definition-dual-rootsystem}
If $(E,\Phi, W)$ is a root system, the {\it dual root system} is the triple $(E^*,\check\Phi, W)$ of Lemma \ref{lemma-dualrootsystem}.
\end{definition}

We will need the classification of root systems of rank two, and a corollary of that.

\begin{proposition}
\label{proposition-ranktwo}
 The only root systems of rank two are the root systems $A_1\times A_1$, $A_2$, $B_2$ and $G_2$. If $\alpha,\beta$ are two non-proportional roots in a root system $\Phi$ with $\left< \alpha, \check\beta\right> < 0$, then 
$\alpha+\beta \in \Phi$.
\end{proposition}

\begin{proof}

[Definitions and proofs for the first statement to be added later---easy to look up!]

If $\alpha,\beta$ are non-proportional roots in a root system, the intersection of the set of roots with their linear span, together with the subgroup of the Weyl group generated by the reflections $w_\alpha$, $w_\beta$, form a root system of rank two. The classification shows that if $\left<\alpha, \check\beta\right> <0$, then $\alpha+\beta$ is also a root. 

\end{proof}



\section{Parabolic subalgebras}
\label{section-parabolic-subalgebras}

\begin{definition}
\label{definition-based-root-system}
 A {\it based root system} is a quadruple $(E,\Phi \supset \Phi^+, W)$ consisting of a root system, and a subset $\Phi^+$ which consisting of the elements of $\Phi$ on one side of a hyperplane not meeting $\Phi$ (that is, $\Phi^+ = \{\alpha\in\Phi| t(\alpha)>0\}$ for some linear functional $t\in E^*$ such that $\ker(t)$ does not contain any roots).
 
 The {\it simple roots} of a based root system are those elements of $\Phi^+$ which cannot be written (non-trivially) as a nonnegative integral linear combination of other elements of $\Phi^+$. The set $\Delta$ of simple roots is called a {\it basis} of the root system.
\end{definition}

The name is due to the following:

\begin{proposition}
\label{proposition-basis-rootsystem}
Given a based root system $(E,\Phi \supset \Phi^+, W)$ with set of simple roots $\Delta$,
the \emph{root lattice} $R=\left< \Phi \right>_{\mathbb Z}$ (the subgroup of $E$ generated by $\Phi$) is freely generated by $\Delta$; in particular, the elements of $\Delta$ are linearly independent.
\end{proposition}

\begin{proof}
Choose an inner product $(\, , \, )$ with respect to which the elements of $W$ are orthogonal. 

By Proposition \ref{proposition-ranktwo}, we have $(\alpha,\beta)\le 0$ for all $\alpha,\beta\in\Delta$, because otherwise $\alpha-\beta$ or $\beta-\alpha$ would belong to $\Phi^+$, contradicting the fact that they are indecomposable.

Consider a nontrivial zero linear combination
$$ \sum_{\alpha\in \Delta} c_\alpha \alpha = 0.$$
 Since all elements of $\Delta$ belong to the same open half-plane, some of the coefficients are positive and some are negative, so we can write
 $$ \lambda:= \sum_{\alpha\in \Delta, c_\alpha>0} c_\alpha \alpha = \sum_{\alpha\in \Delta, c_\alpha< 0} (-c_\alpha)\alpha,$$
 with none of the two sums being empty. Then, 
 $$(\lambda,\lambda) = \left(\sum_{\alpha\in \Delta, c_\alpha>0} c_\alpha \alpha, \sum_{\alpha\in \Delta, c_\alpha< 0} (-c_\alpha)\alpha\right) \le 0,$$
contradicting the positivity of the inner product. 

Thus, the elements of $\Delta$ are linearly independent, and since by definition every other element of $\Phi^+$ belongs to their $\mathbb Z$-span, they are a free basis for the root lattice.
\end{proof}





\begin{definition}
\label{definition-Borel-parabolic}
 A {\it Borel subalgebra} of a Lie algebra is a maximal solvable subalgebra. A {\it parabolic subalgebra} is a subalgebra containing a Borel subalgebra.
\end{definition}

Obviously, every Cartan subalgebra is contained in a Borel subalgebra. The following will be useful for the results that follow:

\begin{lemma}
\label{lemma-closed-subset}
Any Lie subalgebra of $\mathfrak g$ containing the Cartan subalgebra $\mathfrak h$ is of the form  
$$ \mathfrak g = \mathfrak h \oplus \bigoplus_{\alpha\in P} \mathfrak g_\alpha,$$
for some \emph{closed} subset $P\subset \Phi$, in the sense that if $\alpha,\beta\in P$ and $\alpha+\beta\in \Phi$, then $\alpha+\beta\in P$.
\end{lemma}

\begin{proof}
Any Lie subalgebra containing $\mathfrak h$ is an $\mathfrak h$-submodule, therefore a sum of $\mathfrak h$ with some of the (one-dimensional) root spaces.

The fact that the subset $P$ of roots appearing is closed follows from Theorem \ref{theorem-root-system}: for $\alpha$, $\beta$ non-proportional, the subspace $\mathfrak g_{\beta+\mathbb Z\alpha}$ is an irreducible $\mathfrak{sl}_{2,\alpha}$-representation; therefore, a nonzero element $e\in \mathfrak g_\alpha$ does not kill $\mathfrak g_\beta$, unless this is the highest weight space, that is, unless $\alpha+\beta\notin \Phi$. 
\end{proof}


\begin{proposition}
\label{proposition-roots-parabolics}
 Given a Cartan subalgebra $\mathfrak h$ in a semisimple Lie algebra $\mathfrak g$, the set of Borel subalgebras containing $\mathfrak h$ is in bijection with the set of bases on the root system $(E, \Phi,W)$ associated to $\mathfrak h$, where a choice $\Phi^+\subset \Phi$ of positive roots corresponds to the Borel subalgebra
 $$ \mathfrak b = \mathfrak h + \bigoplus_{\alpha\in\Phi^+} \mathfrak g_\alpha.$$
 The parabolic subalgebras containing this Borel subalgebra are determined by subsets of the set $\Delta$ of simple roots, with $I\subset\Delta$ corresponding to the parabolic subalgebra
 $$ \mathfrak p_I = \mathfrak b + \bigoplus_{\alpha\in \Phi_I^+} \mathfrak g_{-\alpha},$$
 where $\Phi_I^+$ is the set of elements of $\Phi^+$ in the span of $I$.
\end{proposition}

\begin{proof}
 Any Lie subalgebra containing $\mathfrak h$ must be a sum of root spaces, and if it is solvable it cannot contain $\mathfrak g_\alpha$ and $\mathfrak g_{-\alpha}$ at the same time, because then it would contain a copy of $\mathfrak{sl}_2$. Thus, if $P$ is the set of roots whose root spaces are contained in $\mathfrak b$, we have $P\cap (-P)=\emptyset$. We will prove that this implies that $P$ lies in a half-space. 
 
 We claim that no nontrivial sum $\alpha_1+\dots+\alpha_n$ of elements of $P$ is zero; indeed, if this is the case, then $(\alpha_1, \alpha_j) <0$ for some $j$ (for a chosen invariant inner product), therefore $\alpha_1+\alpha_j\in \Phi$ by Proposition \ref{proposition-ranktwo}, and therefore $\alpha_1+\alpha_j\in P$, by Lemma \ref{lemma-closed-subset}. This reduces the claim to a sum of $n-1$ elements, and the claim follows by induction. 
 
 Now we claim that there exists an $\beta\in P$ with $(\alpha,\beta)\ge 0$ for all $\alpha\in P$. If not, we would be able to choose an infinite sequence $\alpha_\bullet: \mathbb N \to P$ with $\beta_n=\alpha_1 + \alpha_2+\dots+\alpha_n \in P$ for all $n$; indeed, having chosen the first $n$ elements of this sequence, by assumption $(\alpha,\beta_n)$ is not $\ge 0$ for all $\alpha\in P$, but then choosing $\alpha_{n+1}$ with $(\alpha_{n+1},\beta_n)<0$, again by Proposition \ref{proposition-ranktwo} and Lemma \ref{lemma-closed-subset}, we would get that $\beta_n+\alpha_{n+1} \in P$. Now, the finiteness of $P$ implies that $\beta_i = \beta_j$ for some $i< j$, implying that $\alpha_{i+1} + \dots + \alpha_j=0$, a contradiction. 
 
 This proves that $P$ lies in a half-space (open, since no opposite elements of $\Phi$ are in $P$), and it is clear that a Lie algebra of the form $\mathfrak h + \bigoplus_{\alpha\in\Phi^+} \mathfrak g_\alpha$ is solvable, therefore a maximal solvable Lie algebra containing $\mathfrak h$ has to be of this form.
 
 For a parabolic subalgebra $\mathfrak p$ properly containing $\mathfrak b$, if now $P$ denotes the set of roots in the weight decomposition of $\mathfrak p$, if $-\beta\in P$ for some positive root $\beta$, and if $\beta = \alpha_1+\dots+\alpha_n$ is its decomposition as a sum of elements of $\Delta$, we will prove by induction on $n$ that all $-\alpha_i \in P$. We have $(\beta,\beta)>0$, therefore $(-\beta, \alpha_i)<0$ for some $i$, hence $\gamma:=-\beta+\alpha_i \in P$ (or is zero), by the same argument as before. If $\gamma\ne 0$, then $-\gamma \in P$, and again by Lemma \ref{lemma-closed-subset}, $-\alpha_i = -\beta +(-\gamma)\in P$.  By the induction hypothesis, for all elements $\alpha\in \Delta$ in the decomposition of $-\gamma$, $-\alpha\in P$, and the claim is proven.
 
 Vice versa, if $I= \Delta \cap (-P)$, and $\beta\in \Phi^+$ is in the linear span of $I$, then $\beta$ can be written as a sum $\alpha_1+\dots+\alpha_n$ of elements of $I$, and  we will prove by induction on $n$ that $-\beta\in P$. Again, $(-\beta,\alpha_i)<0$ for some $i$, so $-\beta+\alpha_1$, if nonzero, is in $P$, by the induction hypothesis. Since $-\alpha_1\in P$, by Lemma \ref{lemma-closed-subset}, $-\beta\in P$, as well.
\end{proof}




\section{Conjugacy of Borel and Cartan subalgebras}
\label{section-Borel-Cartan}


\section{Jacobson--Morosov}
\label{section-Jacobson-Morosov}

\section{Ado's theorem}
\label{section-Ado}




%***************************************************************************




\input{chapters}


\bibliography{my}
\bibliographystyle{amsalpha}

\end{document}
